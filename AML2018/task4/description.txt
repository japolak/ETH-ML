For this task we started working with the provided code by Teaching Assistant. 
However we also transformed the videos to have equal length.
This was done so to make the implementation of Neural Network easier for us and
it would equalise the videos since the frame rates ranged from 22 to 209.
Therefore after the transformation all videos had length 209 with approximately the same number or heartbeats.
Then we created a Convolutional Neural Network into which we would feed the whole videos.
This method worked much better then feeding it individually frame by frame.
The architecture of the Convolutional Neural Network was following:
First was convolutional layer with "ReLu" activation and 32 filters.
Second pooling layer of pool size 2. This structure was again repeated and followed by a 3 dense layers.
Finally a logits layer to obtain probabilities.
We were feeding the network in batches of 2 videos when mostly they were of different classes.
This ensured a better balance in the model while training due to unsufficient number of training data.
We were also trying to introduce some noise to the training data to increase the sample but this approach haven't worked well for us.
