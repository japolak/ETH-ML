In this classification task, we first fitted several different models in an attempt to span the space and to obtain an insight which model does well predicting which class and which model does well in general. We have discovered that Support Vector Classifier, Linear Discriminant Analysis and Multinomial Logistic Regression approaches do well in general. They we able to perform individually around hard benchmark when fine tuned (SVC: using 3rd degree polynomial kernel and one-vs-one decision function, LOG: multinomial with stochastic average gradient solver, LDA: least squares solution with 0.9 shrinkage. All methods had class weights adjusted according to observed class occurrences). Then, we created a majority voting ensemble model of these 3. We used probability estimates for the three classes and pick as our prediction the class where this sum is highest. Furthermore, adding weak but diverse classifier learners did not improve the ensemble prediction. 
Also stacking, creating a level 1 model, on the predictions from these models using Logistic Regression or Trees did not outperformed the weighted voting model although showed to be promising.
