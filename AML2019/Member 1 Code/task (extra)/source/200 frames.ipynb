{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "from tf_utils import input_fn_from_dataset,input_fn_frame_from_dataset,save_tf_record,prob_positive_class_from_prediction\n",
    "from get_data import get_videos_from_folder,get_target_from_csv\n",
    "from utils import save_solution\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "                                        MaxPooling2D)\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AUC for a binary classifier\n",
    "def auc(y_true, y_pred):\n",
    "    ptas = tf.stack([binary_PTA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.stack([binary_PFA(y_true,y_pred,k) for k in np.linspace(0, 1, 1000)],axis=0)\n",
    "    pfas = tf.concat([tf.ones((1,)) ,pfas],axis=0)\n",
    "    binSizes = -(pfas[1:]-pfas[:-1])\n",
    "    s = ptas*binSizes\n",
    "    return K.sum(s, axis=0)\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# PFA, prob false alert for binary classifier\n",
    "def binary_PFA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # N = total number of negative labels\n",
    "    N = K.sum(1 - y_true)\n",
    "    # FP = total number of false alerts, alerts from the negative class labels\n",
    "    FP = K.sum(y_pred - y_pred * y_true)\n",
    "    return FP/N\n",
    "#-----------------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# P_TA prob true alerts for binary classifier\n",
    "def binary_PTA(y_true, y_pred, threshold=K.variable(value=0.5)):\n",
    "    y_pred = K.cast(y_pred >= threshold, 'float32')\n",
    "    # P = total number of positive labels\n",
    "    P = K.sum(y_true)\n",
    "    # TP = total number of correct alerts, alerts from the positive class labels\n",
    "    TP = K.sum(y_pred * y_true)\n",
    "    return TP/P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = os.path.join(\"../train/\")\n",
    "test_folder = os.path.join(\"../test/\")\n",
    "\n",
    "train_target = os.path.join('../train_target.csv')\n",
    "my_solution_file = os.path.join('../solution.csv')\n",
    "\n",
    "x_train = get_videos_from_folder(train_folder)\n",
    "y_train = get_target_from_csv(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum number of frames used as input\n",
    "pframe=200 #max([len(x) for x in x_train])\n",
    "X = np.zeros((x_train.shape[0], pframe, 100, 100,1))\n",
    "for i in range(x_train.shape[0]):\n",
    "    if x_train[i].shape[0] >= pframe:\n",
    "        X[i,: pframe,:x_train[i].shape[1],:x_train[i].shape[2],0] = x_train[i][: pframe,:x_train[i].shape[1],:x_train[i].shape[2]]\n",
    "    else:\n",
    "        # repeated padding\n",
    "        frames, height, width = x_train[i].shape[0], x_train[i].shape[1], x_train[i].shape[2]\n",
    "        pos = 0\n",
    "        while pos + frames <= pframe:\n",
    "            X[i,pos:(pos+frames),:height,:width,0] = x_train[i][:frames,:height,:width]\n",
    "            pos += frames\n",
    "        if pos < pframe:\n",
    "            X[i,pos:pframe,:height,:width,0] = x_train[i][:(pframe-pos),:height,:width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 0]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array([0,1] if y_train[0] else [1,0])\n",
    "for l in y_train[1:]:\n",
    "    if l == 1:\n",
    "        y = np.vstack([y, [0,1]])\n",
    "    else:\n",
    "        y = np.vstack([y, [1,0]])\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "time_distributed_225 (TimeDi (None, 200, 50, 50, 32)   1600      \n",
      "_________________________________________________________________\n",
      "time_distributed_226 (TimeDi (None, 200, 48, 48, 32)   9248      \n",
      "_________________________________________________________________\n",
      "time_distributed_227 (TimeDi (None, 200, 24, 24, 32)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_228 (TimeDi (None, 200, 24, 24, 64)   18496     \n",
      "_________________________________________________________________\n",
      "time_distributed_229 (TimeDi (None, 200, 24, 24, 64)   36928     \n",
      "_________________________________________________________________\n",
      "time_distributed_230 (TimeDi (None, 200, 12, 12, 64)   0         \n",
      "_________________________________________________________________\n",
      "time_distributed_231 (TimeDi (None, 200, 12, 12, 128)  73856     \n",
      "_________________________________________________________________\n",
      "time_distributed_232 (TimeDi (None, 200, 12, 12, 128)  147584    \n",
      "_________________________________________________________________\n",
      "time_distributed_233 (TimeDi (None, 200, 6, 6, 128)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_234 (TimeDi (None, 200, 6, 6, 256)    295168    \n",
      "_________________________________________________________________\n",
      "time_distributed_235 (TimeDi (None, 200, 6, 6, 256)    590080    \n",
      "_________________________________________________________________\n",
      "time_distributed_236 (TimeDi (None, 200, 3, 3, 256)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_237 (TimeDi (None, 200, 3, 3, 512)    1180160   \n",
      "_________________________________________________________________\n",
      "time_distributed_238 (TimeDi (None, 200, 3, 3, 512)    2359808   \n",
      "_________________________________________________________________\n",
      "time_distributed_239 (TimeDi (None, 200, 1, 1, 512)    0         \n",
      "_________________________________________________________________\n",
      "time_distributed_240 (TimeDi (None, 200, 512)          0         \n",
      "_________________________________________________________________\n",
      "dropout_15 (Dropout)         (None, 200, 512)          0         \n",
      "_________________________________________________________________\n",
      "lstm_15 (LSTM)               (None, 1024)              6295552   \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 2)                 2050      \n",
      "=================================================================\n",
      "Total params: 11,010,530\n",
      "Trainable params: 11,010,530\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nb_epoch=25\n",
    "checkpointer = ModelCheckpoint( filepath=os.path.join('data', 'checkpoints', 'lcrn' + '-' + \\\n",
    "            '.{epoch:03d}-{val_loss:.3f}.hdf5'),\n",
    "        verbose=1,\n",
    "        save_best_only=True)\n",
    "\n",
    "    \n",
    "tb = TensorBoard(log_dir=os.path.join('data', 'logs', 'lcrn'))\n",
    "early_stopper = EarlyStopping(patience=15)\n",
    "timestamp = time.time()\n",
    "csv_logger = CSVLogger(os.path.join('data', 'logs', 'lcrn' + '-' + 'training-' + str(timestamp) + '.log'))\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, (7, 7), strides=(2, 2),activation='relu',padding='same'), input_shape=( pframe, 100, 100,1)))\n",
    "model.add(TimeDistributed(Conv2D(32, (3,3),\n",
    "kernel_initializer=\"he_normal\", activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(64, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(64, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(128, (3,3), padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(128, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(256, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(256, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Conv2D(512, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(Conv2D(512, (3,3),padding='same', activation='relu')))\n",
    "model.add(TimeDistributed(MaxPooling2D((2, 2), strides=(2, 2))))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(LSTM(1024, return_sequences=False, dropout=0.5))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 126 samples, validate on 32 samples\n",
      "Epoch 1/25\n",
      "126/126 [==============================] - 259s 2s/step - loss: 0.7091 - auc: 0.4840 - acc: 0.4603 - val_loss: 0.7173 - val_auc: 0.4170 - val_acc: 0.4062\n",
      "Epoch 2/25\n",
      "126/126 [==============================] - 241s 2s/step - loss: 0.6826 - auc: 0.5642 - acc: 0.5238 - val_loss: 0.7309 - val_auc: 0.4697 - val_acc: 0.4062\n",
      "Epoch 3/25\n",
      "126/126 [==============================] - 258s 2s/step - loss: 0.6970 - auc: 0.5435 - acc: 0.5556 - val_loss: 0.7291 - val_auc: 0.4736 - val_acc: 0.4062\n",
      "Epoch 4/25\n",
      "126/126 [==============================] - 252s 2s/step - loss: 0.6972 - auc: 0.5309 - acc: 0.5238 - val_loss: 0.7052 - val_auc: 0.4482 - val_acc: 0.4062\n",
      "Epoch 5/25\n",
      "126/126 [==============================] - 257s 2s/step - loss: 0.6902 - auc: 0.5608 - acc: 0.5238 - val_loss: 0.6930 - val_auc: 0.4629 - val_acc: 0.3750\n",
      "Epoch 6/25\n",
      "126/126 [==============================] - 264s 2s/step - loss: 0.6958 - auc: 0.5159 - acc: 0.4921 - val_loss: 0.6981 - val_auc: 0.4658 - val_acc: 0.4062\n",
      "Epoch 7/25\n",
      "126/126 [==============================] - 266s 2s/step - loss: 0.6837 - auc: 0.5581 - acc: 0.5476 - val_loss: 0.6983 - val_auc: 0.4717 - val_acc: 0.4062\n",
      "Epoch 8/25\n",
      "126/126 [==============================] - 262s 2s/step - loss: 0.6565 - auc: 0.6884 - acc: 0.6587 - val_loss: 0.7007 - val_auc: 0.4834 - val_acc: 0.4062\n",
      "Epoch 9/25\n",
      "126/126 [==============================] - 255s 2s/step - loss: 0.6814 - auc: 0.5860 - acc: 0.5714 - val_loss: 0.6943 - val_auc: 0.4785 - val_acc: 0.4375\n",
      "Epoch 10/25\n",
      "126/126 [==============================] - 251s 2s/step - loss: 0.6659 - auc: 0.6350 - acc: 0.5952 - val_loss: 0.6941 - val_auc: 0.4814 - val_acc: 0.4375\n",
      "Epoch 11/25\n",
      "126/126 [==============================] - 253s 2s/step - loss: 0.6583 - auc: 0.6519 - acc: 0.6190 - val_loss: 0.6903 - val_auc: 0.4951 - val_acc: 0.4688\n",
      "Epoch 12/25\n",
      "126/126 [==============================] - 251s 2s/step - loss: 0.6587 - auc: 0.6465 - acc: 0.5873 - val_loss: 0.6875 - val_auc: 0.5156 - val_acc: 0.5000\n",
      "Epoch 13/25\n",
      "126/126 [==============================] - 253s 2s/step - loss: 0.6514 - auc: 0.7051 - acc: 0.6825 - val_loss: 0.6832 - val_auc: 0.5811 - val_acc: 0.4688\n",
      "Epoch 14/25\n",
      "126/126 [==============================] - 257s 2s/step - loss: 0.6488 - auc: 0.6917 - acc: 0.6429 - val_loss: 0.6890 - val_auc: 0.5186 - val_acc: 0.4688\n",
      "Epoch 15/25\n",
      "126/126 [==============================] - 251s 2s/step - loss: 0.6411 - auc: 0.6929 - acc: 0.6349 - val_loss: 0.6888 - val_auc: 0.5283 - val_acc: 0.5000\n",
      "Epoch 16/25\n"
     ]
    }
   ],
   "source": [
    "metrics = [auc, 'accuracy']\n",
    "optimizer = Adam(lr=1e-5, decay=1e-6)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                       metrics=metrics)\n",
    "model.fit(X, y, batch_size=32, validation_split=0.2, verbose=1,callbacks=[tb, early_stopper, csv_logger], epochs=nb_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = get_videos_from_folder(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((x_test.shape[0],  pframe, 100, 100,1))\n",
    "for i in range(x_test.shape[0]):\n",
    "    if x_test[i].shape[0]>= pframe:\n",
    "        X_test[i,: pframe,:x_test[i].shape[1],:x_test[i].shape[2],0] = x_test[i][: pframe,:x_test[i].shape[1],:x_test[i].shape[2]]\n",
    "    else:\n",
    "        # repeated padding\n",
    "        frames, height, width = x_test[i].shape[0], x_test[i].shape[1], x_test[i].shape[2]\n",
    "        pos = 0\n",
    "        while pos + frames <= pframe:\n",
    "            X_test[i,pos:(pos+frames),:height,:width,0] = x_test[i][:frames,:height,:width]\n",
    "            pos += frames\n",
    "        if pos < pframe:\n",
    "            X_test[i,pos:pframe,:height,:width,0] = x_test[i][:(pframe-pos),:height,:width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions = model.predict(X_test) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_solution = np.array([p[1] for p in train_predictions])\n",
    "save_solution(my_solution_file,dummy_solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
