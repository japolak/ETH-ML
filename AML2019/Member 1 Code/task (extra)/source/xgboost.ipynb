{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightbgm\n",
      "\u001b[31m  Could not find a version that satisfies the requirement lightbgm (from versions: )\u001b[0m\n",
      "\u001b[31mNo matching distribution found for lightbgm\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install lightbgm\n",
    "#!conda install scikit-learn\n",
    "import os\n",
    "import tensorflow as tf\t\n",
    "import numpy as np\n",
    "import time\n",
    "from tf_utils import input_fn_from_dataset,input_fn_frame_from_dataset,save_tf_record,prob_positive_class_from_prediction\n",
    "from get_data import get_videos_from_folder,get_target_from_csv\n",
    "from utils import save_solution\n",
    "from keras.layers import Dense, Flatten, Dropout, ZeroPadding3D\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers.convolutional import (Conv2D, MaxPooling3D, Conv3D,\n",
    "                                        MaxPooling2D)\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint, EarlyStopping, CSVLogger\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "from sklearn.utils.validation import check_array\n",
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pframe=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = os.path.join(\"../train/\")\n",
    "test_folder = os.path.join(\"../test/\")\n",
    "\n",
    "train_target = os.path.join('../train_target.csv')\n",
    "my_solution_file = os.path.join('../solution.csv')\n",
    "\n",
    "tf_record_dir = os.path.join('..','tf_records')\n",
    "os.makedirs(tf_record_dir, exist_ok=True)\n",
    "\n",
    "tf_record_train = os.path.join(tf_record_dir, 'train' + '.tfrecords')\n",
    "tf_record_test = os.path.join(tf_record_dir, 'test' + '.tfrecords')\n",
    "x_train = get_videos_from_folder(train_folder)\n",
    "y_train = get_target_from_csv(train_target)\n",
    "X = np.zeros((x_train.shape[0], pframe, 100, 100,1))\n",
    "\n",
    "for i in range(x_train.shape[0]):\n",
    "    if x_train[i].shape[0] >= pframe:\n",
    "        X[i,: pframe,:x_train[i].shape[1],:x_train[i].shape[2],0] = x_train[i][: pframe,:x_train[i].shape[1],:x_train[i].shape[2]]\n",
    "    else:\n",
    "        # repeated padding\n",
    "        frames, height, width = x_train[i].shape[0], x_train[i].shape[1], x_train[i].shape[2]\n",
    "        pos = 0\n",
    "        while pos + frames <= pframe:\n",
    "            X[i,pos:(pos+frames),:height,:width,0] = x_train[i][:frames,:height,:width]\n",
    "            pos += frames\n",
    "        if pos < pframe:\n",
    "            X[i,pos:pframe,:height,:width,0] = x_train[i][:(pframe-pos),:height,:width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = get_target_from_csv(train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validate( split_size=5):\n",
    "    results = []\n",
    "    kf = KFold(n_splits=split_size)\n",
    "    for train_idx, val_idx in kf.split(X, y_train):\n",
    "        train_x = X[train_idx]\n",
    "        train_y = y_train[train_idx]\n",
    "        val_x = X[val_idx]\n",
    "        val_y = y_train[val_idx]\n",
    "        His=model.fit(train_x, train_y, batch_size=32, validation_data=(val_x,val_y),verbose=1,callbacks=[tb, early_stopper, csv_logger], epochs=nb_epoch)\n",
    "        results.append(His,history)\n",
    "    return results\n",
    "results=cross_validate(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = get_videos_from_folder(test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.zeros((x_test.shape[0],  pframe, 100, 100,1))\n",
    "for i in range(x_test.shape[0]):\n",
    "    if x_test[i].shape[0]>= pframe:\n",
    "        X_test[i,: pframe,:x_test[i].shape[1],:x_test[i].shape[2],0] = x_test[i][: pframe,:x_test[i].shape[1],:x_test[i].shape[2]]\n",
    "    else:\n",
    "        # repeated padding\n",
    "        frames, height, width = x_test[i].shape[0], x_test[i].shape[1], x_test[i].shape[2]\n",
    "        pos = 0\n",
    "        while pos + frames <= pframe:\n",
    "            X_test[i,pos:(pos+frames),:height,:width,0] = x_test[i][:frames,:height,:width]\n",
    "            pos += frames\n",
    "        if pos < pframe:\n",
    "            X_test[i,pos:pframe,:height,:width,0] = x_test[i][:(pframe-pos),:height,:width]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cell_edges = np.linspace(0,40,4,dtype=int)\n",
    "y_cell_edges = np.linspace(0,100,9,dtype=int)\n",
    "z_cell_edges = np.linspace(0,100,9,dtype=int)\n",
    "\n",
    "        # histograms\n",
    "histogram_train = np.zeros((X.shape[0], 3,8,8, 45))\n",
    "histogram_test = np.zeros((X_test.shape[0], 3,8,8, 45))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, X.shape[0]):\n",
    "    image_3D = X[i, :, :, :,0]\n",
    "\n",
    "    for xi in range(0, x_cell_edges.size - 1):\n",
    "        for yi in range(0, y_cell_edges.size - 1):\n",
    "            for zi in range(0, z_cell_edges.size - 1):\n",
    "\n",
    "                        # image block for histogram\n",
    "                image_block = image_3D[\n",
    "                                      x_cell_edges[xi]:x_cell_edges[xi+1],\n",
    "                                      y_cell_edges[yi]:y_cell_edges[yi+1],\n",
    "                                      z_cell_edges[zi]:z_cell_edges[zi+1]]\n",
    "\n",
    "                        # histogram\n",
    "                histogram_train[i, xi, yi, zi, :], bins = \\\n",
    "                            np.histogram(image_block,\n",
    "                                         bins=np.linspace(0,\n",
    "                                                          4500,\n",
    "                                                          45 + 1))\n",
    "\n",
    "X_new = np.reshape(histogram_train, (X.shape[0], -1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0, X_test.shape[0]):\n",
    "    image_3D = X_test[i, :, :, :,0]\n",
    "\n",
    "    for xi in range(0, x_cell_edges.size - 1):\n",
    "        for yi in range(0, y_cell_edges.size - 1):\n",
    "            for zi in range(0, z_cell_edges.size - 1):\n",
    "\n",
    "                        # image block for histogram\n",
    "                image_block = image_3D[\n",
    "                                      x_cell_edges[xi]:x_cell_edges[xi+1],\n",
    "                                      y_cell_edges[yi]:y_cell_edges[yi+1],\n",
    "                                      z_cell_edges[zi]:z_cell_edges[zi+1]]\n",
    "\n",
    "                        # histogram\n",
    "                histogram_test[i, xi, yi, zi, :], bins = \\\n",
    "                            np.histogram(image_block,\n",
    "                                         bins=np.linspace(0,\n",
    "                                                          4500,\n",
    "                                                          45 + 1))\n",
    "\n",
    "X_test_new = np.reshape(histogram_test, (X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_new, y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[1]\ttraining's binary_logloss: 0.675043\ttraining's r2: 0.813382\tvalid_0's binary_logloss: 0.690081\tvalid_0's r2: 0.566667\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's binary_logloss: 0.662861\ttraining's r2: 0.873236\tvalid_0's binary_logloss: 0.6883\tvalid_0's r2: 0.539216\n",
      "[3]\ttraining's binary_logloss: 0.643978\ttraining's r2: 0.927293\tvalid_0's binary_logloss: 0.689716\tvalid_0's r2: 0.564706\n",
      "[4]\ttraining's binary_logloss: 0.627704\ttraining's r2: 0.927923\tvalid_0's binary_logloss: 0.689808\tvalid_0's r2: 0.578431\n",
      "[5]\ttraining's binary_logloss: 0.612605\ttraining's r2: 0.948085\tvalid_0's binary_logloss: 0.695268\tvalid_0's r2: 0.509804\n",
      "[6]\ttraining's binary_logloss: 0.597785\ttraining's r2: 0.957157\tvalid_0's binary_logloss: 0.689259\tvalid_0's r2: 0.556863\n",
      "[7]\ttraining's binary_logloss: 0.584658\ttraining's r2: 0.959425\tvalid_0's binary_logloss: 0.690354\tvalid_0's r2: 0.533333\n",
      "[8]\ttraining's binary_logloss: 0.56708\ttraining's r2: 0.962954\tvalid_0's binary_logloss: 0.690365\tvalid_0's r2: 0.498039\n",
      "[9]\ttraining's binary_logloss: 0.554224\ttraining's r2: 0.964214\tvalid_0's binary_logloss: 0.685015\tvalid_0's r2: 0.560784\n",
      "[10]\ttraining's binary_logloss: 0.540438\ttraining's r2: 0.960938\tvalid_0's binary_logloss: 0.685486\tvalid_0's r2: 0.54902\n",
      "[11]\ttraining's binary_logloss: 0.530446\ttraining's r2: 0.965726\tvalid_0's binary_logloss: 0.676057\tvalid_0's r2: 0.611765\n",
      "[12]\ttraining's binary_logloss: 0.519961\ttraining's r2: 0.966482\tvalid_0's binary_logloss: 0.669203\tvalid_0's r2: 0.623529\n",
      "[13]\ttraining's binary_logloss: 0.508362\ttraining's r2: 0.972026\tvalid_0's binary_logloss: 0.66812\tvalid_0's r2: 0.627451\n",
      "[14]\ttraining's binary_logloss: 0.500139\ttraining's r2: 0.970766\tvalid_0's binary_logloss: 0.669214\tvalid_0's r2: 0.623529\n",
      "[15]\ttraining's binary_logloss: 0.489514\ttraining's r2: 0.97127\tvalid_0's binary_logloss: 0.669767\tvalid_0's r2: 0.631373\n",
      "[16]\ttraining's binary_logloss: 0.481222\ttraining's r2: 0.969758\tvalid_0's binary_logloss: 0.671165\tvalid_0's r2: 0.619608\n",
      "[17]\ttraining's binary_logloss: 0.472932\ttraining's r2: 0.971774\tvalid_0's binary_logloss: 0.669727\tvalid_0's r2: 0.615686\n",
      "[18]\ttraining's binary_logloss: 0.463539\ttraining's r2: 0.973034\tvalid_0's binary_logloss: 0.672027\tvalid_0's r2: 0.611765\n",
      "[19]\ttraining's binary_logloss: 0.453974\ttraining's r2: 0.977319\tvalid_0's binary_logloss: 0.664524\tvalid_0's r2: 0.623529\n",
      "[20]\ttraining's binary_logloss: 0.445982\ttraining's r2: 0.977319\tvalid_0's binary_logloss: 0.66243\tvalid_0's r2: 0.619608\n",
      "[21]\ttraining's binary_logloss: 0.438745\ttraining's r2: 0.979335\tvalid_0's binary_logloss: 0.655313\tvalid_0's r2: 0.647059\n",
      "[22]\ttraining's binary_logloss: 0.432437\ttraining's r2: 0.981855\tvalid_0's binary_logloss: 0.648997\tvalid_0's r2: 0.658824\n",
      "[23]\ttraining's binary_logloss: 0.423585\ttraining's r2: 0.984879\tvalid_0's binary_logloss: 0.644641\tvalid_0's r2: 0.670588\n",
      "[24]\ttraining's binary_logloss: 0.414422\ttraining's r2: 0.986139\tvalid_0's binary_logloss: 0.641413\tvalid_0's r2: 0.690196\n",
      "[25]\ttraining's binary_logloss: 0.405183\ttraining's r2: 0.987399\tvalid_0's binary_logloss: 0.637227\tvalid_0's r2: 0.705882\n",
      "[26]\ttraining's binary_logloss: 0.395984\ttraining's r2: 0.991431\tvalid_0's binary_logloss: 0.636203\tvalid_0's r2: 0.701961\n",
      "[27]\ttraining's binary_logloss: 0.388832\ttraining's r2: 0.991935\tvalid_0's binary_logloss: 0.642707\tvalid_0's r2: 0.670588\n",
      "[28]\ttraining's binary_logloss: 0.381604\ttraining's r2: 0.992692\tvalid_0's binary_logloss: 0.629571\tvalid_0's r2: 0.729412\n",
      "[29]\ttraining's binary_logloss: 0.374065\ttraining's r2: 0.992692\tvalid_0's binary_logloss: 0.636608\tvalid_0's r2: 0.705882\n",
      "[30]\ttraining's binary_logloss: 0.366353\ttraining's r2: 0.993196\tvalid_0's binary_logloss: 0.633692\tvalid_0's r2: 0.698039\n",
      "[31]\ttraining's binary_logloss: 0.35901\ttraining's r2: 0.994456\tvalid_0's binary_logloss: 0.627306\tvalid_0's r2: 0.701961\n",
      "[32]\ttraining's binary_logloss: 0.353051\ttraining's r2: 0.995716\tvalid_0's binary_logloss: 0.620479\tvalid_0's r2: 0.717647\n",
      "[33]\ttraining's binary_logloss: 0.346251\ttraining's r2: 0.995968\tvalid_0's binary_logloss: 0.617942\tvalid_0's r2: 0.721569\n",
      "[34]\ttraining's binary_logloss: 0.339132\ttraining's r2: 0.99748\tvalid_0's binary_logloss: 0.615687\tvalid_0's r2: 0.721569\n",
      "[35]\ttraining's binary_logloss: 0.333448\ttraining's r2: 0.99748\tvalid_0's binary_logloss: 0.610853\tvalid_0's r2: 0.72549\n",
      "[36]\ttraining's binary_logloss: 0.327933\ttraining's r2: 0.997732\tvalid_0's binary_logloss: 0.60638\tvalid_0's r2: 0.733333\n",
      "[37]\ttraining's binary_logloss: 0.322124\ttraining's r2: 0.99748\tvalid_0's binary_logloss: 0.606813\tvalid_0's r2: 0.713725\n",
      "[38]\ttraining's binary_logloss: 0.31514\ttraining's r2: 0.997732\tvalid_0's binary_logloss: 0.603339\tvalid_0's r2: 0.733333\n",
      "[39]\ttraining's binary_logloss: 0.308859\ttraining's r2: 0.998236\tvalid_0's binary_logloss: 0.60746\tvalid_0's r2: 0.701961\n",
      "[40]\ttraining's binary_logloss: 0.302554\ttraining's r2: 0.998236\tvalid_0's binary_logloss: 0.601882\tvalid_0's r2: 0.741176\n",
      "[41]\ttraining's binary_logloss: 0.295605\ttraining's r2: 0.998488\tvalid_0's binary_logloss: 0.598452\tvalid_0's r2: 0.745098\n",
      "[42]\ttraining's binary_logloss: 0.289222\ttraining's r2: 0.998488\tvalid_0's binary_logloss: 0.59458\tvalid_0's r2: 0.764706\n",
      "[43]\ttraining's binary_logloss: 0.283639\ttraining's r2: 0.998992\tvalid_0's binary_logloss: 0.593169\tvalid_0's r2: 0.764706\n",
      "[44]\ttraining's binary_logloss: 0.279505\ttraining's r2: 0.998992\tvalid_0's binary_logloss: 0.589717\tvalid_0's r2: 0.768627\n",
      "[45]\ttraining's binary_logloss: 0.273765\ttraining's r2: 0.999244\tvalid_0's binary_logloss: 0.594606\tvalid_0's r2: 0.752941\n",
      "[46]\ttraining's binary_logloss: 0.26841\ttraining's r2: 0.999244\tvalid_0's binary_logloss: 0.593957\tvalid_0's r2: 0.760784\n",
      "[47]\ttraining's binary_logloss: 0.265285\ttraining's r2: 0.999496\tvalid_0's binary_logloss: 0.589686\tvalid_0's r2: 0.776471\n",
      "[48]\ttraining's binary_logloss: 0.25969\ttraining's r2: 0.999496\tvalid_0's binary_logloss: 0.5874\tvalid_0's r2: 0.776471\n",
      "[49]\ttraining's binary_logloss: 0.254854\ttraining's r2: 0.999748\tvalid_0's binary_logloss: 0.580805\tvalid_0's r2: 0.788235\n",
      "[50]\ttraining's binary_logloss: 0.249379\ttraining's r2: 1\tvalid_0's binary_logloss: 0.579284\tvalid_0's r2: 0.784314\n",
      "[51]\ttraining's binary_logloss: 0.243937\ttraining's r2: 1\tvalid_0's binary_logloss: 0.580864\tvalid_0's r2: 0.784314\n",
      "[52]\ttraining's binary_logloss: 0.238588\ttraining's r2: 1\tvalid_0's binary_logloss: 0.583691\tvalid_0's r2: 0.776471\n",
      "[53]\ttraining's binary_logloss: 0.233787\ttraining's r2: 1\tvalid_0's binary_logloss: 0.582563\tvalid_0's r2: 0.768627\n",
      "[54]\ttraining's binary_logloss: 0.229869\ttraining's r2: 1\tvalid_0's binary_logloss: 0.583219\tvalid_0's r2: 0.768627\n",
      "[55]\ttraining's binary_logloss: 0.225444\ttraining's r2: 1\tvalid_0's binary_logloss: 0.574627\tvalid_0's r2: 0.780392\n",
      "[56]\ttraining's binary_logloss: 0.222154\ttraining's r2: 1\tvalid_0's binary_logloss: 0.577251\tvalid_0's r2: 0.780392\n",
      "[57]\ttraining's binary_logloss: 0.217951\ttraining's r2: 1\tvalid_0's binary_logloss: 0.576029\tvalid_0's r2: 0.776471\n",
      "[58]\ttraining's binary_logloss: 0.214888\ttraining's r2: 1\tvalid_0's binary_logloss: 0.571376\tvalid_0's r2: 0.784314\n",
      "[59]\ttraining's binary_logloss: 0.212224\ttraining's r2: 1\tvalid_0's binary_logloss: 0.574203\tvalid_0's r2: 0.772549\n",
      "[60]\ttraining's binary_logloss: 0.208728\ttraining's r2: 1\tvalid_0's binary_logloss: 0.570468\tvalid_0's r2: 0.788235\n",
      "[61]\ttraining's binary_logloss: 0.205167\ttraining's r2: 1\tvalid_0's binary_logloss: 0.570958\tvalid_0's r2: 0.792157\n",
      "[62]\ttraining's binary_logloss: 0.20142\ttraining's r2: 1\tvalid_0's binary_logloss: 0.566313\tvalid_0's r2: 0.788235\n",
      "[63]\ttraining's binary_logloss: 0.197616\ttraining's r2: 1\tvalid_0's binary_logloss: 0.567953\tvalid_0's r2: 0.788235\n",
      "[64]\ttraining's binary_logloss: 0.194921\ttraining's r2: 1\tvalid_0's binary_logloss: 0.573937\tvalid_0's r2: 0.772549\n",
      "[65]\ttraining's binary_logloss: 0.192533\ttraining's r2: 1\tvalid_0's binary_logloss: 0.578725\tvalid_0's r2: 0.768627\n",
      "[66]\ttraining's binary_logloss: 0.189721\ttraining's r2: 1\tvalid_0's binary_logloss: 0.584272\tvalid_0's r2: 0.752941\n",
      "[67]\ttraining's binary_logloss: 0.185999\ttraining's r2: 1\tvalid_0's binary_logloss: 0.585186\tvalid_0's r2: 0.768627\n",
      "[68]\ttraining's binary_logloss: 0.183971\ttraining's r2: 1\tvalid_0's binary_logloss: 0.585236\tvalid_0's r2: 0.764706\n",
      "[69]\ttraining's binary_logloss: 0.180435\ttraining's r2: 1\tvalid_0's binary_logloss: 0.58363\tvalid_0's r2: 0.768627\n",
      "[70]\ttraining's binary_logloss: 0.178241\ttraining's r2: 1\tvalid_0's binary_logloss: 0.583758\tvalid_0's r2: 0.780392\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's binary_logloss: 0.249379\ttraining's r2: 1\tvalid_0's binary_logloss: 0.579284\tvalid_0's r2: 0.784314\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "def custom_r2(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'r2', roc_auc_score(labels, preds), True\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=500,\n",
    "                feval=custom_r2,\n",
    "                valid_sets={lgb_train, lgb_eval},\n",
    "                early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_test_new , num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25903254, 0.59793162, 0.65680447, 0.34189803, 0.78482993,\n",
       "       0.30130879, 0.42660575, 0.77075514, 0.48404168, 0.39917007,\n",
       "       0.72659622, 0.7021133 , 0.71013712, 0.15650399, 0.57215112,\n",
       "       0.89444514, 0.3893225 , 0.54156065, 0.31918314, 0.50008797,\n",
       "       0.63596871, 0.52178557, 0.29357271, 0.55076175, 0.74802448,\n",
       "       0.26942731, 0.63659147, 0.81836689, 0.47553788, 0.71587711,\n",
       "       0.74324246, 0.76630422, 0.31501518, 0.30960262, 0.626478  ,\n",
       "       0.73396337, 0.3028767 , 0.57810541, 0.49543682, 0.54136336,\n",
       "       0.81386465, 0.26456912, 0.39173781, 0.39678107, 0.50662276,\n",
       "       0.36140976, 0.40656055, 0.47698813, 0.71849709, 0.75300414,\n",
       "       0.83624386, 0.54306591, 0.27417854, 0.33596898, 0.71457679,\n",
       "       0.10769183, 0.63705773, 0.53474473, 0.71813742, 0.72851383,\n",
       "       0.24575929, 0.43223122, 0.67152991, 0.33443419, 0.58845098,\n",
       "       0.51091206, 0.70624123, 0.45325788, 0.8018234 ])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"submission.csv\", \"w\")\n",
    "f.write(\"id,y\\n\")\n",
    "for i,x in enumerate(y_pred):\n",
    "    f.write(\"{},{}\\n\".format(i,x))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cell_number=4\n",
    "y_cell_number=8\n",
    "z_cell_number=8\n",
    "theta_bin_number=18\n",
    "phi_bin_number=9\n",
    "IMAGE_DIM_X = 176\n",
    "IMAGE_DIM_Y = 208\n",
    "IMAGE_DIM_Z = 176\n",
    "IMAGE_VALUE_MAX = 4500\n",
    "IMAGE_FULL_FEATURE = 6443008"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_edges = np.linspace(0, 100,x_cell_number + 1,dtype=int)\n",
    "\n",
    "y_edges = np.linspace(0,100,x_cell_number + 1,dtype=int)\n",
    "z_edges = np.linspace(0,100,z_cell_number + 1,dtype=int)\n",
    "\n",
    "\n",
    "histogram_train = np.zeros((X.shape[0],x_cell_number,y_cell_number,z_cell_number,theta_bin_number,phi_bin_number))\n",
    "histogram_test = np.zeros((X_test.shape[0],x_cell_number,y_cell_number,z_cell_number,theta_bin_number,phi_bin_number))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/numpy/linalg/linalg.py:2390: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return sqrt(add.reduce(s, axis=axis, keepdims=keepdims))\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  import sys\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, X.shape[0]):\n",
    "    image_3D = X[i, :, :, :,0]\n",
    "    gradient = np.gradient(image_3D.astype('float32'))\n",
    "\n",
    "            # normalize\n",
    "    norm = np.linalg.norm(gradient, axis=0)\n",
    "    gradient = [np.where(norm == 0, 0, i / norm) for i in gradient]\n",
    "\n",
    "    for xi in range(0, x_edges.size - 1):\n",
    "        for yi in range(0, y_edges.size - 1):\n",
    "            for zi in range(0, z_edges.size - 1):\n",
    "\n",
    "                block_x = gradient[0][\n",
    "                                  x_edges[xi]:x_edges[xi+1],\n",
    "                                  y_edges[yi]:y_edges[yi+1],\n",
    "                                  z_edges[zi]:z_edges[zi+1]]\n",
    "                block_y = gradient[1][\n",
    "                                  x_edges[xi]:x_edges[xi+1],\n",
    "                                  y_edges[yi]:y_edges[yi+1],\n",
    "                                  z_edges[zi]:z_edges[zi+1]]\n",
    "                block_z = gradient[2][\n",
    "                                  x_edges[xi]:x_edges[xi+1],\n",
    "                                  y_edges[yi]:y_edges[yi+1],\n",
    "                                  z_edges[zi]:z_edges[zi+1]]\n",
    "                block_mag = norm[\n",
    "                                    x_edges[xi]:x_edges[xi+1],\n",
    "                                    y_edges[yi]:y_edges[yi+1],\n",
    "                                    z_edges[zi]:z_edges[zi+1]]\n",
    "\n",
    "                block_x = block_x.flatten()\n",
    "                block_y = block_y.flatten()\n",
    "                block_z = block_z.flatten()\n",
    "                block_mag = block_mag.flatten()\n",
    "\n",
    "                block_x = block_x[block_mag > 0.8]\n",
    "                block_y = block_y[block_mag > 0.8]\n",
    "                block_z = block_z[block_mag > 0.8]\n",
    "\n",
    "                        # theta and phi\n",
    "                theta_block = np.arctan2(block_y,\n",
    "                                                 block_x) * 180.0 / np.pi\n",
    "                phi_block = np.arccos(block_z) * 180.0 / np.pi\n",
    "\n",
    "                bins = (np.linspace(-180, 180,\n",
    "                                            theta_bin_number + 1),\n",
    "                                np.linspace(0, 180,\n",
    "                                            phi_bin_number + 1))\n",
    "\n",
    "                        # histogram\n",
    "                histogram_train[i, xi, yi, zi, :, :], theta_edge, phi_edge = \\\n",
    "                            np.histogram2d(theta_block, phi_block, bins=bins)\n",
    "\n",
    "    X_new = np.reshape(histogram_train, (X.shape[0], -1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  import sys\n",
      "/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in true_divide\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, X_test.shape[0]):\n",
    "    image_3D = X_test[i, :, :, :,0]\n",
    "    gradient = np.gradient(image_3D.astype('float32'))\n",
    "\n",
    "            # normalize\n",
    "    norm = np.linalg.norm(gradient, axis=0)\n",
    "    gradient = [np.where(norm == 0, 0, i / norm) for i in gradient]\n",
    "\n",
    "    for xi in range(0, x_edges.size - 1):\n",
    "        for yi in range(0, y_edges.size - 1):\n",
    "            for zi in range(0, z_edges.size - 1):\n",
    "\n",
    "                block_x = gradient[0][\n",
    "                                  x_edges[xi]:x_edges[xi+1],\n",
    "                                  y_edges[yi]:y_edges[yi+1],\n",
    "                                  z_edges[zi]:z_edges[zi+1]]\n",
    "                block_y = gradient[1][\n",
    "                                  x_edges[xi]:x_edges[xi+1],\n",
    "                                  y_edges[yi]:y_edges[yi+1],\n",
    "                                  z_edges[zi]:z_edges[zi+1]]\n",
    "                block_z = gradient[2][\n",
    "                                  x_edges[xi]:x_edges[xi+1],\n",
    "                                  y_edges[yi]:y_edges[yi+1],\n",
    "                                  z_edges[zi]:z_edges[zi+1]]\n",
    "                block_mag = norm[\n",
    "                                    x_edges[xi]:x_edges[xi+1],\n",
    "                                    y_edges[yi]:y_edges[yi+1],\n",
    "                                    z_edges[zi]:z_edges[zi+1]]\n",
    "\n",
    "                block_x = block_x.flatten()\n",
    "                block_y = block_y.flatten()\n",
    "                block_z = block_z.flatten()\n",
    "                block_mag = block_mag.flatten()\n",
    "\n",
    "                block_x = block_x[block_mag > 0.8]\n",
    "                block_y = block_y[block_mag > 0.8]\n",
    "                block_z = block_z[block_mag > 0.8]\n",
    "\n",
    "                        # theta and phi\n",
    "                theta_block = np.arctan2(block_y,\n",
    "                                                 block_x) * 180.0 / np.pi\n",
    "                phi_block = np.arccos(block_z) * 180.0 / np.pi\n",
    "\n",
    "                bins = (np.linspace(-180, 180,\n",
    "                                            theta_bin_number + 1),\n",
    "                                np.linspace(0, 180,\n",
    "                                            phi_bin_number + 1))\n",
    "\n",
    "                        # histogram\n",
    "                histogram_test[i, xi, yi, zi, :, :], theta_edge, phi_edge = \\\n",
    "                            np.histogram2d(theta_block, phi_block, bins=bins)\n",
    "\n",
    "    X_test_new = np.reshape(histogram_test, (X_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_new, y_train, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "def custom_r2(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'r2', roc_auc_score(labels, preds), True\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=500,\n",
    "                feval=custom_r2,\n",
    "                valid_sets={lgb_train, lgb_eval},\n",
    "                early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_test_new , num_iteration=gbm.best_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"submission.csv\", \"w\")\n",
    "f.write(\"id,y\\n\")\n",
    "for i,x in enumerate(y_pred):\n",
    "    f.write(\"{},{}\\n\".format(i,x))\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
