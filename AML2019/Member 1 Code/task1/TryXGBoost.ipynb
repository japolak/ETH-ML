{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:45: FutureWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS will be built by the Apple Clang compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you won't need to install the gcc compiler anymore.\n",
      "Instead of that, you'll need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "import pandas as pd\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load training data...\n"
     ]
    }
   ],
   "source": [
    "print('Load training data...')\n",
    "df_x_train = pd.read_csv('X_train.csv', header=0, index_col = 0)\n",
    "df_y_train = pd.read_csv('y_train.csv', header=0, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x877</th>\n",
       "      <th>x878</th>\n",
       "      <th>x879</th>\n",
       "      <th>x880</th>\n",
       "      <th>x881</th>\n",
       "      <th>x882</th>\n",
       "      <th>x883</th>\n",
       "      <th>x884</th>\n",
       "      <th>x885</th>\n",
       "      <th>x886</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>7077.537454</td>\n",
       "      <td>9.266811e+05</td>\n",
       "      <td>1.076365e+06</td>\n",
       "      <td>1029.624479</td>\n",
       "      <td>105.877440</td>\n",
       "      <td>180486.413011</td>\n",
       "      <td>1084.604810</td>\n",
       "      <td>296933.955135</td>\n",
       "      <td>104840.111208</td>\n",
       "      <td>10736.380544</td>\n",
       "      <td>...</td>\n",
       "      <td>3.921803e+11</td>\n",
       "      <td>1.040522e+06</td>\n",
       "      <td>-437724.358877</td>\n",
       "      <td>957.470031</td>\n",
       "      <td>9.888772e+05</td>\n",
       "      <td>3830.501971</td>\n",
       "      <td>98.622927</td>\n",
       "      <td>1771.079992</td>\n",
       "      <td>10008.297422</td>\n",
       "      <td>65052.593208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>4406.423818</td>\n",
       "      <td>1.172821e+06</td>\n",
       "      <td>1.052467e+06</td>\n",
       "      <td>1000.548328</td>\n",
       "      <td>106.827932</td>\n",
       "      <td>154325.607476</td>\n",
       "      <td>1034.480237</td>\n",
       "      <td>337446.411077</td>\n",
       "      <td>107789.409140</td>\n",
       "      <td>10502.289317</td>\n",
       "      <td>...</td>\n",
       "      <td>3.646601e+10</td>\n",
       "      <td>8.996629e+05</td>\n",
       "      <td>-486231.980813</td>\n",
       "      <td>1127.268384</td>\n",
       "      <td>8.374596e+05</td>\n",
       "      <td>1981.239448</td>\n",
       "      <td>97.369765</td>\n",
       "      <td>843.078502</td>\n",
       "      <td>10046.004997</td>\n",
       "      <td>65052.623467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>4460.878690</td>\n",
       "      <td>9.383663e+05</td>\n",
       "      <td>1.040878e+06</td>\n",
       "      <td>1096.946907</td>\n",
       "      <td>104.058397</td>\n",
       "      <td>197813.871177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>373983.030405</td>\n",
       "      <td>109480.853246</td>\n",
       "      <td>10531.423706</td>\n",
       "      <td>...</td>\n",
       "      <td>9.147176e+10</td>\n",
       "      <td>9.575649e+05</td>\n",
       "      <td>NaN</td>\n",
       "      <td>976.904261</td>\n",
       "      <td>9.210706e+05</td>\n",
       "      <td>2334.782218</td>\n",
       "      <td>113.751711</td>\n",
       "      <td>1134.021199</td>\n",
       "      <td>10307.683079</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>7152.388016</td>\n",
       "      <td>9.231857e+05</td>\n",
       "      <td>1.009414e+06</td>\n",
       "      <td>1044.520384</td>\n",
       "      <td>101.089811</td>\n",
       "      <td>182569.308398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>339951.730003</td>\n",
       "      <td>106597.409809</td>\n",
       "      <td>10070.560056</td>\n",
       "      <td>...</td>\n",
       "      <td>2.428226e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-497230.891433</td>\n",
       "      <td>912.933479</td>\n",
       "      <td>1.117182e+06</td>\n",
       "      <td>3711.834265</td>\n",
       "      <td>98.080257</td>\n",
       "      <td>1553.015493</td>\n",
       "      <td>10952.963586</td>\n",
       "      <td>65052.576387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>6531.930242</td>\n",
       "      <td>1.133718e+06</td>\n",
       "      <td>1.032579e+06</td>\n",
       "      <td>1032.803345</td>\n",
       "      <td>102.608707</td>\n",
       "      <td>200161.011648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>332425.590129</td>\n",
       "      <td>107815.955426</td>\n",
       "      <td>10889.035954</td>\n",
       "      <td>...</td>\n",
       "      <td>1.273734e+11</td>\n",
       "      <td>1.059684e+06</td>\n",
       "      <td>-485361.519459</td>\n",
       "      <td>1001.804829</td>\n",
       "      <td>9.523764e+05</td>\n",
       "      <td>3153.167755</td>\n",
       "      <td>100.671564</td>\n",
       "      <td>1271.047509</td>\n",
       "      <td>10048.902807</td>\n",
       "      <td>65052.535207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 887 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              x0            x1            x2           x3          x4  \\\n",
       "id                                                                      \n",
       "0.0  7077.537454  9.266811e+05  1.076365e+06  1029.624479  105.877440   \n",
       "1.0  4406.423818  1.172821e+06  1.052467e+06  1000.548328  106.827932   \n",
       "2.0  4460.878690  9.383663e+05  1.040878e+06  1096.946907  104.058397   \n",
       "3.0  7152.388016  9.231857e+05  1.009414e+06  1044.520384  101.089811   \n",
       "4.0  6531.930242  1.133718e+06  1.032579e+06  1032.803345  102.608707   \n",
       "\n",
       "                x5           x6             x7             x8            x9  \\\n",
       "id                                                                            \n",
       "0.0  180486.413011  1084.604810  296933.955135  104840.111208  10736.380544   \n",
       "1.0  154325.607476  1034.480237  337446.411077  107789.409140  10502.289317   \n",
       "2.0  197813.871177          NaN  373983.030405  109480.853246  10531.423706   \n",
       "3.0  182569.308398          NaN  339951.730003  106597.409809  10070.560056   \n",
       "4.0  200161.011648          NaN  332425.590129  107815.955426  10889.035954   \n",
       "\n",
       "         ...               x877          x878           x879         x880  \\\n",
       "id       ...                                                                \n",
       "0.0      ...       3.921803e+11  1.040522e+06 -437724.358877   957.470031   \n",
       "1.0      ...       3.646601e+10  8.996629e+05 -486231.980813  1127.268384   \n",
       "2.0      ...       9.147176e+10  9.575649e+05            NaN   976.904261   \n",
       "3.0      ...       2.428226e+11           NaN -497230.891433   912.933479   \n",
       "4.0      ...       1.273734e+11  1.059684e+06 -485361.519459  1001.804829   \n",
       "\n",
       "             x881         x882        x883         x884          x885  \\\n",
       "id                                                                      \n",
       "0.0  9.888772e+05  3830.501971   98.622927  1771.079992  10008.297422   \n",
       "1.0  8.374596e+05  1981.239448   97.369765   843.078502  10046.004997   \n",
       "2.0  9.210706e+05  2334.782218  113.751711  1134.021199  10307.683079   \n",
       "3.0  1.117182e+06  3711.834265   98.080257  1553.015493  10952.963586   \n",
       "4.0  9.523764e+05  3153.167755  100.671564  1271.047509  10048.902807   \n",
       "\n",
       "             x886  \n",
       "id                 \n",
       "0.0  65052.593208  \n",
       "1.0  65052.623467  \n",
       "2.0           NaN  \n",
       "3.0  65052.576387  \n",
       "4.0  65052.535207  \n",
       "\n",
       "[5 rows x 887 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "These columns are dummy!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x493</th>\n",
       "      <th>x523</th>\n",
       "      <th>x731</th>\n",
       "      <th>x772</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1182.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1184.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1185.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1186.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1187.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1188.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1191.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1197.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1198.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1199.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1200.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1201.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202.0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1203.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1204.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1205.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1206.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1207.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1209.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1211.0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1212 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        x493  x523  x731  x772\n",
       "id                            \n",
       "0.0      0.0   0.0   0.0   0.0\n",
       "1.0      0.0   0.0   0.0   0.0\n",
       "2.0      0.0   0.0   0.0   0.0\n",
       "3.0      0.0   0.0   0.0   0.0\n",
       "4.0      0.0   NaN   0.0   0.0\n",
       "5.0      0.0   0.0   0.0   0.0\n",
       "6.0      0.0   0.0   0.0   0.0\n",
       "7.0      0.0   0.0   0.0   0.0\n",
       "8.0      0.0   0.0   0.0   0.0\n",
       "9.0      0.0   0.0   0.0   0.0\n",
       "10.0     0.0   0.0   0.0   0.0\n",
       "11.0     0.0   0.0   0.0   0.0\n",
       "12.0     NaN   0.0   0.0   0.0\n",
       "13.0     0.0   0.0   0.0   0.0\n",
       "14.0     NaN   0.0   0.0   0.0\n",
       "15.0     0.0   0.0   0.0   0.0\n",
       "16.0     0.0   NaN   0.0   0.0\n",
       "17.0     0.0   0.0   0.0   0.0\n",
       "18.0     0.0   0.0   0.0   0.0\n",
       "19.0     0.0   0.0   0.0   0.0\n",
       "20.0     0.0   0.0   0.0   0.0\n",
       "21.0     0.0   NaN   0.0   0.0\n",
       "22.0     0.0   0.0   0.0   0.0\n",
       "23.0     0.0   0.0   0.0   0.0\n",
       "24.0     0.0   0.0   0.0   0.0\n",
       "25.0     0.0   0.0   0.0   0.0\n",
       "26.0     0.0   0.0   0.0   0.0\n",
       "27.0     0.0   0.0   0.0   0.0\n",
       "28.0     0.0   0.0   0.0   0.0\n",
       "29.0     0.0   0.0   0.0   0.0\n",
       "...      ...   ...   ...   ...\n",
       "1182.0   0.0   0.0   0.0   0.0\n",
       "1183.0   0.0   0.0   0.0   0.0\n",
       "1184.0   0.0   0.0   0.0   0.0\n",
       "1185.0   0.0   NaN   0.0   0.0\n",
       "1186.0   0.0   0.0   0.0   0.0\n",
       "1187.0   0.0   0.0   0.0   0.0\n",
       "1188.0   0.0   0.0   0.0   0.0\n",
       "1189.0   0.0   0.0   0.0   0.0\n",
       "1190.0   0.0   0.0   0.0   0.0\n",
       "1191.0   0.0   0.0   0.0   0.0\n",
       "1192.0   0.0   0.0   0.0   0.0\n",
       "1193.0   0.0   0.0   0.0   0.0\n",
       "1194.0   NaN   0.0   0.0   0.0\n",
       "1195.0   0.0   NaN   0.0   0.0\n",
       "1196.0   0.0   0.0   0.0   0.0\n",
       "1197.0   0.0   0.0   0.0   0.0\n",
       "1198.0   0.0   0.0   0.0   0.0\n",
       "1199.0   0.0   0.0   0.0   NaN\n",
       "1200.0   0.0   0.0   0.0   0.0\n",
       "1201.0   0.0   0.0   NaN   0.0\n",
       "1202.0   NaN   0.0   0.0   0.0\n",
       "1203.0   0.0   0.0   0.0   0.0\n",
       "1204.0   0.0   0.0   0.0   0.0\n",
       "1205.0   0.0   0.0   0.0   0.0\n",
       "1206.0   0.0   0.0   0.0   0.0\n",
       "1207.0   0.0   0.0   0.0   0.0\n",
       "1208.0   0.0   0.0   0.0   0.0\n",
       "1209.0   0.0   NaN   0.0   0.0\n",
       "1210.0   0.0   0.0   0.0   0.0\n",
       "1211.0   0.0   0.0   0.0   0.0\n",
       "\n",
       "[1212 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"These columns are dummy!\")\n",
    "df_x_train[[\"x493\", \"x523\", \"x731\", \"x772\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y\n",
       "id       \n",
       "0.0  75.0\n",
       "1.0  76.0\n",
       "2.0  74.0\n",
       "3.0  70.0\n",
       "4.0  74.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nan's in each column:\n",
      "x0 90\n",
      "x1 72\n",
      "x2 80\n",
      "x3 89\n",
      "x4 79\n",
      "x5 86\n",
      "x6 71\n",
      "x7 90\n",
      "x8 90\n",
      "x9 93\n",
      "x10 85\n",
      "x11 93\n",
      "x12 78\n",
      "x13 100\n",
      "x14 92\n",
      "x15 94\n",
      "x16 77\n",
      "x17 75\n",
      "x18 91\n",
      "x19 82\n",
      "x20 89\n",
      "x21 99\n",
      "x22 96\n",
      "x23 79\n",
      "x24 85\n",
      "x25 86\n",
      "x26 82\n",
      "x27 96\n",
      "x28 87\n",
      "x29 98\n",
      "x30 95\n",
      "x31 88\n",
      "x32 78\n",
      "x33 83\n",
      "x34 91\n",
      "x35 83\n",
      "x36 104\n",
      "x37 80\n",
      "x38 77\n",
      "x39 92\n",
      "x40 92\n",
      "x41 79\n",
      "x42 79\n",
      "x43 91\n",
      "x44 79\n",
      "x45 96\n",
      "x46 90\n",
      "x47 77\n",
      "x48 72\n",
      "x49 85\n",
      "x50 98\n",
      "x51 78\n",
      "x52 82\n",
      "x53 68\n",
      "x54 78\n",
      "x55 83\n",
      "x56 78\n",
      "x57 102\n",
      "x58 69\n",
      "x59 97\n",
      "x60 76\n",
      "x61 97\n",
      "x62 84\n",
      "x63 96\n",
      "x64 97\n",
      "x65 92\n",
      "x66 72\n",
      "x67 93\n",
      "x68 95\n",
      "x69 83\n",
      "x70 76\n",
      "x71 90\n",
      "x72 83\n",
      "x73 102\n",
      "x74 91\n",
      "x75 92\n",
      "x76 100\n",
      "x77 106\n",
      "x78 81\n",
      "x79 103\n",
      "x80 93\n",
      "x81 78\n",
      "x82 85\n",
      "x83 94\n",
      "x84 82\n",
      "x85 93\n",
      "x86 98\n",
      "x87 98\n",
      "x88 86\n",
      "x89 86\n",
      "x90 85\n",
      "x91 74\n",
      "x92 80\n",
      "x93 90\n",
      "x94 66\n",
      "x95 96\n",
      "x96 83\n",
      "x97 104\n",
      "x98 87\n",
      "x99 88\n",
      "x100 76\n",
      "x101 88\n",
      "x102 84\n",
      "x103 78\n",
      "x104 79\n",
      "x105 80\n",
      "x106 81\n",
      "x107 95\n",
      "x108 98\n",
      "x109 78\n",
      "x110 89\n",
      "x111 82\n",
      "x112 85\n",
      "x113 81\n",
      "x114 113\n",
      "x115 98\n",
      "x116 92\n",
      "x117 80\n",
      "x118 89\n",
      "x119 86\n",
      "x120 77\n",
      "x121 78\n",
      "x122 100\n",
      "x123 91\n",
      "x124 90\n",
      "x125 67\n",
      "x126 83\n",
      "x127 84\n",
      "x128 93\n",
      "x129 92\n",
      "x130 83\n",
      "x131 75\n",
      "x132 101\n",
      "x133 78\n",
      "x134 86\n",
      "x135 95\n",
      "x136 75\n",
      "x137 79\n",
      "x138 88\n",
      "x139 91\n",
      "x140 93\n",
      "x141 91\n",
      "x142 94\n",
      "x143 71\n",
      "x144 92\n",
      "x145 76\n",
      "x146 91\n",
      "x147 89\n",
      "x148 82\n",
      "x149 91\n",
      "x150 94\n",
      "x151 88\n",
      "x152 83\n",
      "x153 88\n",
      "x154 80\n",
      "x155 89\n",
      "x156 65\n",
      "x157 92\n",
      "x158 98\n",
      "x159 89\n",
      "x160 101\n",
      "x161 91\n",
      "x162 95\n",
      "x163 74\n",
      "x164 77\n",
      "x165 76\n",
      "x166 98\n",
      "x167 88\n",
      "x168 90\n",
      "x169 88\n",
      "x170 82\n",
      "x171 91\n",
      "x172 96\n",
      "x173 101\n",
      "x174 74\n",
      "x175 82\n",
      "x176 92\n",
      "x177 98\n",
      "x178 81\n",
      "x179 93\n",
      "x180 95\n",
      "x181 79\n",
      "x182 84\n",
      "x183 97\n",
      "x184 81\n",
      "x185 103\n",
      "x186 94\n",
      "x187 87\n",
      "x188 97\n",
      "x189 105\n",
      "x190 91\n",
      "x191 69\n",
      "x192 86\n",
      "x193 96\n",
      "x194 96\n",
      "x195 77\n",
      "x196 92\n",
      "x197 81\n",
      "x198 78\n",
      "x199 82\n",
      "x200 88\n",
      "x201 85\n",
      "x202 99\n",
      "x203 81\n",
      "x204 84\n",
      "x205 84\n",
      "x206 73\n",
      "x207 80\n",
      "x208 92\n",
      "x209 94\n",
      "x210 75\n",
      "x211 80\n",
      "x212 84\n",
      "x213 81\n",
      "x214 89\n",
      "x215 90\n",
      "x216 92\n",
      "x217 93\n",
      "x218 79\n",
      "x219 92\n",
      "x220 72\n",
      "x221 83\n",
      "x222 98\n",
      "x223 86\n",
      "x224 96\n",
      "x225 80\n",
      "x226 68\n",
      "x227 77\n",
      "x228 86\n",
      "x229 100\n",
      "x230 77\n",
      "x231 92\n",
      "x232 82\n",
      "x233 98\n",
      "x234 88\n",
      "x235 107\n",
      "x236 78\n",
      "x237 88\n",
      "x238 90\n",
      "x239 92\n",
      "x240 85\n",
      "x241 91\n",
      "x242 83\n",
      "x243 80\n",
      "x244 96\n",
      "x245 77\n",
      "x246 79\n",
      "x247 88\n",
      "x248 74\n",
      "x249 93\n",
      "x250 71\n",
      "x251 79\n",
      "x252 80\n",
      "x253 87\n",
      "x254 98\n",
      "x255 83\n",
      "x256 99\n",
      "x257 79\n",
      "x258 89\n",
      "x259 97\n",
      "x260 86\n",
      "x261 94\n",
      "x262 105\n",
      "x263 73\n",
      "x264 81\n",
      "x265 78\n",
      "x266 99\n",
      "x267 81\n",
      "x268 76\n",
      "x269 77\n",
      "x270 95\n",
      "x271 83\n",
      "x272 81\n",
      "x273 97\n",
      "x274 84\n",
      "x275 85\n",
      "x276 77\n",
      "x277 85\n",
      "x278 92\n",
      "x279 83\n",
      "x280 94\n",
      "x281 81\n",
      "x282 107\n",
      "x283 72\n",
      "x284 110\n",
      "x285 86\n",
      "x286 93\n",
      "x287 85\n",
      "x288 92\n",
      "x289 75\n",
      "x290 92\n",
      "x291 76\n",
      "x292 79\n",
      "x293 95\n",
      "x294 96\n",
      "x295 80\n",
      "x296 77\n",
      "x297 92\n",
      "x298 78\n",
      "x299 85\n",
      "x300 108\n",
      "x301 88\n",
      "x302 89\n",
      "x303 73\n",
      "x304 80\n",
      "x305 86\n",
      "x306 73\n",
      "x307 65\n",
      "x308 91\n",
      "x309 82\n",
      "x310 86\n",
      "x311 84\n",
      "x312 99\n",
      "x313 80\n",
      "x314 88\n",
      "x315 102\n",
      "x316 85\n",
      "x317 92\n",
      "x318 71\n",
      "x319 88\n",
      "x320 80\n",
      "x321 80\n",
      "x322 87\n",
      "x323 94\n",
      "x324 101\n",
      "x325 85\n",
      "x326 99\n",
      "x327 89\n",
      "x328 77\n",
      "x329 74\n",
      "x330 90\n",
      "x331 77\n",
      "x332 92\n",
      "x333 64\n",
      "x334 89\n",
      "x335 87\n",
      "x336 84\n",
      "x337 100\n",
      "x338 79\n",
      "x339 84\n",
      "x340 85\n",
      "x341 84\n",
      "x342 87\n",
      "x343 82\n",
      "x344 79\n",
      "x345 78\n",
      "x346 85\n",
      "x347 95\n",
      "x348 81\n",
      "x349 85\n",
      "x350 89\n",
      "x351 86\n",
      "x352 93\n",
      "x353 84\n",
      "x354 82\n",
      "x355 81\n",
      "x356 105\n",
      "x357 83\n",
      "x358 84\n",
      "x359 81\n",
      "x360 87\n",
      "x361 78\n",
      "x362 87\n",
      "x363 92\n",
      "x364 94\n",
      "x365 91\n",
      "x366 71\n",
      "x367 76\n",
      "x368 93\n",
      "x369 90\n",
      "x370 103\n",
      "x371 93\n",
      "x372 95\n",
      "x373 83\n",
      "x374 77\n",
      "x375 98\n",
      "x376 84\n",
      "x377 95\n",
      "x378 81\n",
      "x379 83\n",
      "x380 98\n",
      "x381 94\n",
      "x382 79\n",
      "x383 69\n",
      "x384 92\n",
      "x385 95\n",
      "x386 88\n",
      "x387 78\n",
      "x388 85\n",
      "x389 88\n",
      "x390 76\n",
      "x391 68\n",
      "x392 79\n",
      "x393 79\n",
      "x394 92\n",
      "x395 97\n",
      "x396 83\n",
      "x397 95\n",
      "x398 94\n",
      "x399 82\n",
      "x400 94\n",
      "x401 85\n",
      "x402 101\n",
      "x403 100\n",
      "x404 89\n",
      "x405 93\n",
      "x406 84\n",
      "x407 77\n",
      "x408 85\n",
      "x409 97\n",
      "x410 97\n",
      "x411 63\n",
      "x412 85\n",
      "x413 75\n",
      "x414 83\n",
      "x415 90\n",
      "x416 97\n",
      "x417 79\n",
      "x418 83\n",
      "x419 91\n",
      "x420 92\n",
      "x421 88\n",
      "x422 97\n",
      "x423 95\n",
      "x424 91\n",
      "x425 84\n",
      "x426 87\n",
      "x427 90\n",
      "x428 105\n",
      "x429 90\n",
      "x430 78\n",
      "x431 100\n",
      "x432 65\n",
      "x433 91\n",
      "x434 73\n",
      "x435 82\n",
      "x436 75\n",
      "x437 82\n",
      "x438 82\n",
      "x439 100\n",
      "x440 85\n",
      "x441 91\n",
      "x442 97\n",
      "x443 91\n",
      "x444 94\n",
      "x445 111\n",
      "x446 88\n",
      "x447 83\n",
      "x448 83\n",
      "x449 83\n",
      "x450 79\n",
      "x451 82\n",
      "x452 94\n",
      "x453 84\n",
      "x454 82\n",
      "x455 93\n",
      "x456 84\n",
      "x457 91\n",
      "x458 97\n",
      "x459 80\n",
      "x460 87\n",
      "x461 98\n",
      "x462 84\n",
      "x463 95\n",
      "x464 92\n",
      "x465 93\n",
      "x466 82\n",
      "x467 90\n",
      "x468 90\n",
      "x469 92\n",
      "x470 96\n",
      "x471 91\n",
      "x472 74\n",
      "x473 89\n",
      "x474 85\n",
      "x475 72\n",
      "x476 85\n",
      "x477 72\n",
      "x478 102\n",
      "x479 91\n",
      "x480 83\n",
      "x481 88\n",
      "x482 91\n",
      "x483 98\n",
      "x484 91\n",
      "x485 79\n",
      "x486 77\n",
      "x487 88\n",
      "x488 87\n",
      "x489 80\n",
      "x490 84\n",
      "x491 86\n",
      "x492 89\n",
      "x493 85\n",
      "x494 98\n",
      "x495 91\n",
      "x496 97\n",
      "x497 81\n",
      "x498 83\n",
      "x499 95\n",
      "x500 91\n",
      "x501 81\n",
      "x502 85\n",
      "x503 88\n",
      "x504 97\n",
      "x505 90\n",
      "x506 76\n",
      "x507 82\n",
      "x508 96\n",
      "x509 91\n",
      "x510 84\n",
      "x511 89\n",
      "x512 97\n",
      "x513 94\n",
      "x514 89\n",
      "x515 97\n",
      "x516 75\n",
      "x517 83\n",
      "x518 80\n",
      "x519 96\n",
      "x520 77\n",
      "x521 95\n",
      "x522 84\n",
      "x523 78\n",
      "x524 86\n",
      "x525 75\n",
      "x526 85\n",
      "x527 86\n",
      "x528 75\n",
      "x529 84\n",
      "x530 69\n",
      "x531 77\n",
      "x532 90\n",
      "x533 99\n",
      "x534 97\n",
      "x535 82\n",
      "x536 80\n",
      "x537 103\n",
      "x538 107\n",
      "x539 91\n",
      "x540 89\n",
      "x541 66\n",
      "x542 80\n",
      "x543 78\n",
      "x544 104\n",
      "x545 75\n",
      "x546 78\n",
      "x547 86\n",
      "x548 73\n",
      "x549 79\n",
      "x550 89\n",
      "x551 95\n",
      "x552 86\n",
      "x553 80\n",
      "x554 83\n",
      "x555 80\n",
      "x556 84\n",
      "x557 95\n",
      "x558 89\n",
      "x559 80\n",
      "x560 73\n",
      "x561 76\n",
      "x562 91\n",
      "x563 82\n",
      "x564 91\n",
      "x565 82\n",
      "x566 82\n",
      "x567 79\n",
      "x568 99\n",
      "x569 94\n",
      "x570 98\n",
      "x571 81\n",
      "x572 91\n",
      "x573 84\n",
      "x574 78\n",
      "x575 71\n",
      "x576 96\n",
      "x577 102\n",
      "x578 98\n",
      "x579 99\n",
      "x580 76\n",
      "x581 73\n",
      "x582 99\n",
      "x583 96\n",
      "x584 92\n",
      "x585 94\n",
      "x586 79\n",
      "x587 93\n",
      "x588 96\n",
      "x589 106\n",
      "x590 101\n",
      "x591 89\n",
      "x592 97\n",
      "x593 82\n",
      "x594 93\n",
      "x595 96\n",
      "x596 97\n",
      "x597 98\n",
      "x598 94\n",
      "x599 95\n",
      "x600 83\n",
      "x601 82\n",
      "x602 93\n",
      "x603 78\n",
      "x604 84\n",
      "x605 97\n",
      "x606 91\n",
      "x607 91\n",
      "x608 89\n",
      "x609 104\n",
      "x610 85\n",
      "x611 93\n",
      "x612 93\n",
      "x613 93\n",
      "x614 94\n",
      "x615 90\n",
      "x616 82\n",
      "x617 89\n",
      "x618 82\n",
      "x619 84\n",
      "x620 71\n",
      "x621 96\n",
      "x622 85\n",
      "x623 100\n",
      "x624 82\n",
      "x625 88\n",
      "x626 98\n",
      "x627 86\n",
      "x628 100\n",
      "x629 74\n",
      "x630 86\n",
      "x631 91\n",
      "x632 84\n",
      "x633 82\n",
      "x634 67\n",
      "x635 83\n",
      "x636 94\n",
      "x637 85\n",
      "x638 90\n",
      "x639 82\n",
      "x640 86\n",
      "x641 89\n",
      "x642 87\n",
      "x643 98\n",
      "x644 88\n",
      "x645 98\n",
      "x646 88\n",
      "x647 94\n",
      "x648 81\n",
      "x649 82\n",
      "x650 87\n",
      "x651 89\n",
      "x652 84\n",
      "x653 96\n",
      "x654 115\n",
      "x655 94\n",
      "x656 83\n",
      "x657 95\n",
      "x658 74\n",
      "x659 77\n",
      "x660 74\n",
      "x661 93\n",
      "x662 82\n",
      "x663 88\n",
      "x664 89\n",
      "x665 89\n",
      "x666 92\n",
      "x667 91\n",
      "x668 75\n",
      "x669 71\n",
      "x670 81\n",
      "x671 96\n",
      "x672 89\n",
      "x673 91\n",
      "x674 82\n",
      "x675 86\n",
      "x676 72\n",
      "x677 86\n",
      "x678 82\n",
      "x679 82\n",
      "x680 104\n",
      "x681 96\n",
      "x682 67\n",
      "x683 68\n",
      "x684 93\n",
      "x685 98\n",
      "x686 95\n",
      "x687 94\n",
      "x688 101\n",
      "x689 87\n",
      "x690 76\n",
      "x691 89\n",
      "x692 78\n",
      "x693 75\n",
      "x694 85\n",
      "x695 87\n",
      "x696 84\n",
      "x697 101\n",
      "x698 91\n",
      "x699 85\n",
      "x700 112\n",
      "x701 92\n",
      "x702 89\n",
      "x703 92\n",
      "x704 90\n",
      "x705 83\n",
      "x706 83\n",
      "x707 70\n",
      "x708 88\n",
      "x709 85\n",
      "x710 82\n",
      "x711 89\n",
      "x712 95\n",
      "x713 91\n",
      "x714 85\n",
      "x715 87\n",
      "x716 85\n",
      "x717 74\n",
      "x718 86\n",
      "x719 98\n",
      "x720 93\n",
      "x721 88\n",
      "x722 83\n",
      "x723 87\n",
      "x724 89\n",
      "x725 75\n",
      "x726 101\n",
      "x727 100\n",
      "x728 89\n",
      "x729 73\n",
      "x730 91\n",
      "x731 71\n",
      "x732 95\n",
      "x733 101\n",
      "x734 95\n",
      "x735 74\n",
      "x736 79\n",
      "x737 73\n",
      "x738 87\n",
      "x739 80\n",
      "x740 96\n",
      "x741 97\n",
      "x742 81\n",
      "x743 82\n",
      "x744 84\n",
      "x745 95\n",
      "x746 97\n",
      "x747 109\n",
      "x748 77\n",
      "x749 89\n",
      "x750 100\n",
      "x751 76\n",
      "x752 75\n",
      "x753 83\n",
      "x754 88\n",
      "x755 85\n",
      "x756 91\n",
      "x757 77\n",
      "x758 87\n",
      "x759 70\n",
      "x760 85\n",
      "x761 88\n",
      "x762 97\n",
      "x763 78\n",
      "x764 85\n",
      "x765 81\n",
      "x766 90\n",
      "x767 88\n",
      "x768 87\n",
      "x769 87\n",
      "x770 84\n",
      "x771 88\n",
      "x772 78\n",
      "x773 97\n",
      "x774 87\n",
      "x775 88\n",
      "x776 93\n",
      "x777 96\n",
      "x778 105\n",
      "x779 105\n",
      "x780 99\n",
      "x781 91\n",
      "x782 89\n",
      "x783 99\n",
      "x784 97\n",
      "x785 73\n",
      "x786 93\n",
      "x787 96\n",
      "x788 81\n",
      "x789 92\n",
      "x790 104\n",
      "x791 75\n",
      "x792 85\n",
      "x793 96\n",
      "x794 96\n",
      "x795 73\n",
      "x796 93\n",
      "x797 74\n",
      "x798 82\n",
      "x799 89\n",
      "x800 94\n",
      "x801 102\n",
      "x802 89\n",
      "x803 83\n",
      "x804 88\n",
      "x805 75\n",
      "x806 102\n",
      "x807 85\n",
      "x808 79\n",
      "x809 85\n",
      "x810 66\n",
      "x811 78\n",
      "x812 95\n",
      "x813 87\n",
      "x814 70\n",
      "x815 91\n",
      "x816 84\n",
      "x817 101\n",
      "x818 94\n",
      "x819 91\n",
      "x820 82\n",
      "x821 94\n",
      "x822 71\n",
      "x823 79\n",
      "x824 77\n",
      "x825 95\n",
      "x826 79\n",
      "x827 93\n",
      "x828 94\n",
      "x829 95\n",
      "x830 69\n",
      "x831 82\n",
      "x832 91\n",
      "x833 95\n",
      "x834 85\n",
      "x835 90\n",
      "x836 88\n",
      "x837 88\n",
      "x838 89\n",
      "x839 88\n",
      "x840 71\n",
      "x841 76\n",
      "x842 83\n",
      "x843 75\n",
      "x844 95\n",
      "x845 105\n",
      "x846 87\n",
      "x847 89\n",
      "x848 75\n",
      "x849 103\n",
      "x850 77\n",
      "x851 98\n",
      "x852 72\n",
      "x853 92\n",
      "x854 80\n",
      "x855 82\n",
      "x856 71\n",
      "x857 94\n",
      "x858 94\n",
      "x859 85\n",
      "x860 80\n",
      "x861 69\n",
      "x862 94\n",
      "x863 81\n",
      "x864 89\n",
      "x865 80\n",
      "x866 87\n",
      "x867 80\n",
      "x868 100\n",
      "x869 84\n",
      "x870 93\n",
      "x871 92\n",
      "x872 85\n",
      "x873 92\n",
      "x874 88\n",
      "x875 76\n",
      "x876 76\n",
      "x877 85\n",
      "x878 85\n",
      "x879 80\n",
      "x880 85\n",
      "x881 87\n",
      "x882 85\n",
      "x883 64\n",
      "x884 86\n",
      "x885 89\n",
      "x886 101\n"
     ]
    }
   ],
   "source": [
    "from numpy import isnan\n",
    "def count_nan(l):\n",
    "    return len([1 for x in l.values if isnan(x[0])])\n",
    "print(\"number of nan's in each column:\")\n",
    "for col in df_x_train:\n",
    "    print(col, count_nan(df_x_train[[col]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlations of each feature against age\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:3010: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  r = r_num / r_den\n",
      "/usr/local/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:14: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x746</th>\n",
       "      <td>0.455891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x82</th>\n",
       "      <td>0.451206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x685</th>\n",
       "      <td>-0.450200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x333</th>\n",
       "      <td>0.436991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x391</th>\n",
       "      <td>0.432717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x722</th>\n",
       "      <td>0.432330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x882</th>\n",
       "      <td>-0.429216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x751</th>\n",
       "      <td>-0.415688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x291</th>\n",
       "      <td>-0.409631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x96</th>\n",
       "      <td>0.408898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x349</th>\n",
       "      <td>-0.405713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x730</th>\n",
       "      <td>-0.376985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x687</th>\n",
       "      <td>0.367135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x363</th>\n",
       "      <td>-0.366201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x673</th>\n",
       "      <td>-0.364621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x340</th>\n",
       "      <td>-0.362479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x664</th>\n",
       "      <td>0.357290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x604</th>\n",
       "      <td>-0.354561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x185</th>\n",
       "      <td>-0.353596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x838</th>\n",
       "      <td>-0.345133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x300</th>\n",
       "      <td>0.340913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x180</th>\n",
       "      <td>-0.340528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x309</th>\n",
       "      <td>-0.340073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x665</th>\n",
       "      <td>-0.339921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x686</th>\n",
       "      <td>-0.336776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x608</th>\n",
       "      <td>-0.333330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x744</th>\n",
       "      <td>-0.332995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x297</th>\n",
       "      <td>-0.332164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x345</th>\n",
       "      <td>-0.327100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x853</th>\n",
       "      <td>-0.324018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x870</th>\n",
       "      <td>-0.213791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x879</th>\n",
       "      <td>0.213640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x795</th>\n",
       "      <td>-0.212368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x66</th>\n",
       "      <td>-0.212000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x198</th>\n",
       "      <td>-0.211618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x32</th>\n",
       "      <td>-0.211301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x457</th>\n",
       "      <td>0.211032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x823</th>\n",
       "      <td>0.210943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x611</th>\n",
       "      <td>-0.210838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x151</th>\n",
       "      <td>-0.210741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x781</th>\n",
       "      <td>-0.209662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x450</th>\n",
       "      <td>-0.209141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x697</th>\n",
       "      <td>-0.208444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x269</th>\n",
       "      <td>0.208393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x277</th>\n",
       "      <td>0.207230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x599</th>\n",
       "      <td>-0.207052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x209</th>\n",
       "      <td>-0.206626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x479</th>\n",
       "      <td>0.206514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x844</th>\n",
       "      <td>-0.206421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x135</th>\n",
       "      <td>-0.206400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x374</th>\n",
       "      <td>-0.206000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x369</th>\n",
       "      <td>-0.203991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x336</th>\n",
       "      <td>0.202729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x166</th>\n",
       "      <td>-0.202164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x428</th>\n",
       "      <td>-0.201807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x20</th>\n",
       "      <td>-0.201729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x283</th>\n",
       "      <td>-0.201577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x410</th>\n",
       "      <td>-0.201315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x365</th>\n",
       "      <td>-0.201115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>x315</th>\n",
       "      <td>-0.201054</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>149 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      correlation\n",
       "x746     0.455891\n",
       "x82      0.451206\n",
       "x685    -0.450200\n",
       "x333     0.436991\n",
       "x391     0.432717\n",
       "x722     0.432330\n",
       "x882    -0.429216\n",
       "x751    -0.415688\n",
       "x291    -0.409631\n",
       "x96      0.408898\n",
       "x349    -0.405713\n",
       "x730    -0.376985\n",
       "x687     0.367135\n",
       "x363    -0.366201\n",
       "x673    -0.364621\n",
       "x340    -0.362479\n",
       "x664     0.357290\n",
       "x604    -0.354561\n",
       "x185    -0.353596\n",
       "x838    -0.345133\n",
       "x300     0.340913\n",
       "x180    -0.340528\n",
       "x309    -0.340073\n",
       "x665    -0.339921\n",
       "x686    -0.336776\n",
       "x608    -0.333330\n",
       "x744    -0.332995\n",
       "x297    -0.332164\n",
       "x345    -0.327100\n",
       "x853    -0.324018\n",
       "...           ...\n",
       "x870    -0.213791\n",
       "x879     0.213640\n",
       "x795    -0.212368\n",
       "x66     -0.212000\n",
       "x198    -0.211618\n",
       "x32     -0.211301\n",
       "x457     0.211032\n",
       "x823     0.210943\n",
       "x611    -0.210838\n",
       "x151    -0.210741\n",
       "x781    -0.209662\n",
       "x450    -0.209141\n",
       "x697    -0.208444\n",
       "x269     0.208393\n",
       "x277     0.207230\n",
       "x599    -0.207052\n",
       "x209    -0.206626\n",
       "x479     0.206514\n",
       "x844    -0.206421\n",
       "x135    -0.206400\n",
       "x374    -0.206000\n",
       "x369    -0.203991\n",
       "x336     0.202729\n",
       "x166    -0.202164\n",
       "x428    -0.201807\n",
       "x20     -0.201729\n",
       "x283    -0.201577\n",
       "x410    -0.201315\n",
       "x365    -0.201115\n",
       "x315    -0.201054\n",
       "\n",
       "[149 rows x 1 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import pearsonr\n",
    "df_filled = df_x_train.fillna(df_x_train.mean()).copy()\n",
    "features = df_filled.iloc[:,1:].columns.tolist()\n",
    "labels = df_y_train[\"y\"].values\n",
    "correlations = {}\n",
    "for f in features:\n",
    "    data_temp = df_filled[[f]]\n",
    "    x1 = data_temp[f].values\n",
    "    key = f\n",
    "    correlations[key] = pearsonr(x1,labels)[0]\n",
    "print(\"Correlations of each feature against age\")\n",
    "data_correlations = pd.DataFrame(correlations, index=['correlation']).T\n",
    "indices_desc = data_correlations['correlation'].abs().sort_values(ascending=False).index\n",
    "data_correlations.loc[indices_desc][abs(data_correlations['correlation']) >= 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['x746', 'x82', 'x685', 'x333', 'x391', 'x722', 'x882', 'x751', 'x291',\n",
       "       'x96',\n",
       "       ...\n",
       "       'x361', 'x499', 'x416', 'x725', 'x15', 'x39', 'x747', 'x624', 'x829',\n",
       "       'x789'],\n",
       "      dtype='object', length=203)"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_features = data_correlations['correlation'].abs().sort_values(ascending=False).loc[abs(data_correlations['correlation']) >= 0.1].index\n",
    "selected_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.51043839e+03, 7.92533090e+02, 7.57225976e+04, ...,\n",
       "        2.58807884e+00,            nan, 1.40765036e+06],\n",
       "       [1.71367954e+03, 2.04384761e+03, 3.45676645e+04, ...,\n",
       "        2.05220010e+00, 1.40100578e+03, 1.51311443e+06],\n",
       "       [1.80266925e+03, 1.84017550e+03, 1.02509913e+05, ...,\n",
       "        2.17282790e+00, 2.23203176e+03, 1.56108941e+06],\n",
       "       ...,\n",
       "       [3.64095010e+03, 3.07020894e+03, 5.64951903e+04, ...,\n",
       "        2.61239274e+00, 2.29902917e+03, 1.63645417e+06],\n",
       "       [2.08526660e+03, 9.55972468e+02, 1.02771633e+05, ...,\n",
       "        2.58108680e+00, 2.85602196e+03, 1.63319893e+06],\n",
       "       [8.51175900e+02, 2.26047823e+02, 1.15412762e+05, ...,\n",
       "        2.10652134e+00,            nan, 1.40965347e+06]])"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_x_train[selected_features].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([75., 76., 74., ..., 78., 78., 56.])"
      ]
     },
     "execution_count": 324,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_y_train['y'].values\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting into training and validation dataset\n"
     ]
    }
   ],
   "source": [
    "print('Splitting into training and validation dataset')\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2) # , random_state = 19960503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training...\n",
      "[1]\ttraining's l2: 92.6531\ttraining's r2: 0.055962\tvalid_0's l2: 97.3166\tvalid_0's r2: 0.0381836\n",
      "Training until validation scores don't improve for 20 rounds.\n",
      "[2]\ttraining's l2: 87.4497\ttraining's r2: 0.108979\tvalid_0's l2: 93.1089\tvalid_0's r2: 0.0797694\n",
      "[3]\ttraining's l2: 82.6618\ttraining's r2: 0.157763\tvalid_0's l2: 89.6966\tvalid_0's r2: 0.113495\n",
      "[4]\ttraining's l2: 78.1701\ttraining's r2: 0.203529\tvalid_0's l2: 86.5238\tvalid_0's r2: 0.144853\n",
      "[5]\ttraining's l2: 74.126\ttraining's r2: 0.244734\tvalid_0's l2: 83.7886\tvalid_0's r2: 0.171886\n",
      "[6]\ttraining's l2: 70.3712\ttraining's r2: 0.282992\tvalid_0's l2: 80.9353\tvalid_0's r2: 0.200086\n",
      "[7]\ttraining's l2: 67.073\ttraining's r2: 0.316596\tvalid_0's l2: 78.1\tvalid_0's r2: 0.228109\n",
      "[8]\ttraining's l2: 63.8559\ttraining's r2: 0.349376\tvalid_0's l2: 76.0091\tvalid_0's r2: 0.248774\n",
      "[9]\ttraining's l2: 60.9439\ttraining's r2: 0.379045\tvalid_0's l2: 74.492\tvalid_0's r2: 0.263768\n",
      "[10]\ttraining's l2: 58.2648\ttraining's r2: 0.406344\tvalid_0's l2: 72.3414\tvalid_0's r2: 0.285023\n",
      "[11]\ttraining's l2: 55.5589\ttraining's r2: 0.433913\tvalid_0's l2: 70.2141\tvalid_0's r2: 0.306047\n",
      "[12]\ttraining's l2: 53.1674\ttraining's r2: 0.45828\tvalid_0's l2: 68.5878\tvalid_0's r2: 0.322121\n",
      "[13]\ttraining's l2: 50.8728\ttraining's r2: 0.481659\tvalid_0's l2: 67.2936\tvalid_0's r2: 0.334912\n",
      "[14]\ttraining's l2: 48.544\ttraining's r2: 0.505388\tvalid_0's l2: 65.7604\tvalid_0's r2: 0.350066\n",
      "[15]\ttraining's l2: 46.4697\ttraining's r2: 0.526522\tvalid_0's l2: 64.1512\tvalid_0's r2: 0.365969\n",
      "[16]\ttraining's l2: 44.4708\ttraining's r2: 0.546889\tvalid_0's l2: 63.1674\tvalid_0's r2: 0.375693\n",
      "[17]\ttraining's l2: 42.861\ttraining's r2: 0.563291\tvalid_0's l2: 62.1607\tvalid_0's r2: 0.385642\n",
      "[18]\ttraining's l2: 41.3483\ttraining's r2: 0.578704\tvalid_0's l2: 61.1736\tvalid_0's r2: 0.395398\n",
      "[19]\ttraining's l2: 39.8076\ttraining's r2: 0.594402\tvalid_0's l2: 60.2256\tvalid_0's r2: 0.404768\n",
      "[20]\ttraining's l2: 38.4159\ttraining's r2: 0.608583\tvalid_0's l2: 59.5073\tvalid_0's r2: 0.411867\n",
      "[21]\ttraining's l2: 36.9885\ttraining's r2: 0.623126\tvalid_0's l2: 58.711\tvalid_0's r2: 0.419737\n",
      "[22]\ttraining's l2: 35.4803\ttraining's r2: 0.638493\tvalid_0's l2: 57.8553\tvalid_0's r2: 0.428195\n",
      "[23]\ttraining's l2: 34.2727\ttraining's r2: 0.650797\tvalid_0's l2: 57.1443\tvalid_0's r2: 0.435222\n",
      "[24]\ttraining's l2: 33.1104\ttraining's r2: 0.66264\tvalid_0's l2: 56.2248\tvalid_0's r2: 0.444309\n",
      "[25]\ttraining's l2: 31.9602\ttraining's r2: 0.674359\tvalid_0's l2: 55.4333\tvalid_0's r2: 0.452131\n",
      "[26]\ttraining's l2: 30.8556\ttraining's r2: 0.685614\tvalid_0's l2: 54.6813\tvalid_0's r2: 0.459564\n",
      "[27]\ttraining's l2: 29.8931\ttraining's r2: 0.69542\tvalid_0's l2: 54.1468\tvalid_0's r2: 0.464847\n",
      "[28]\ttraining's l2: 28.9126\ttraining's r2: 0.705411\tvalid_0's l2: 53.836\tvalid_0's r2: 0.467919\n",
      "[29]\ttraining's l2: 27.9965\ttraining's r2: 0.714745\tvalid_0's l2: 53.4665\tvalid_0's r2: 0.47157\n",
      "[30]\ttraining's l2: 27.1245\ttraining's r2: 0.72363\tvalid_0's l2: 53.105\tvalid_0's r2: 0.475143\n",
      "[31]\ttraining's l2: 26.295\ttraining's r2: 0.732082\tvalid_0's l2: 52.3848\tvalid_0's r2: 0.482262\n",
      "[32]\ttraining's l2: 25.5465\ttraining's r2: 0.739708\tvalid_0's l2: 51.899\tvalid_0's r2: 0.487063\n",
      "[33]\ttraining's l2: 24.8248\ttraining's r2: 0.747062\tvalid_0's l2: 51.488\tvalid_0's r2: 0.491125\n",
      "[34]\ttraining's l2: 24.1626\ttraining's r2: 0.753808\tvalid_0's l2: 51.2673\tvalid_0's r2: 0.493306\n",
      "[35]\ttraining's l2: 23.4225\ttraining's r2: 0.76135\tvalid_0's l2: 50.8704\tvalid_0's r2: 0.497228\n",
      "[36]\ttraining's l2: 22.7528\ttraining's r2: 0.768173\tvalid_0's l2: 50.3535\tvalid_0's r2: 0.502338\n",
      "[37]\ttraining's l2: 22.104\ttraining's r2: 0.774783\tvalid_0's l2: 49.9168\tvalid_0's r2: 0.506653\n",
      "[38]\ttraining's l2: 21.4546\ttraining's r2: 0.7814\tvalid_0's l2: 49.5548\tvalid_0's r2: 0.510231\n",
      "[39]\ttraining's l2: 20.8359\ttraining's r2: 0.787704\tvalid_0's l2: 49.0393\tvalid_0's r2: 0.515326\n",
      "[40]\ttraining's l2: 20.2703\ttraining's r2: 0.793467\tvalid_0's l2: 48.5055\tvalid_0's r2: 0.520602\n",
      "[41]\ttraining's l2: 19.7266\ttraining's r2: 0.799007\tvalid_0's l2: 48.4079\tvalid_0's r2: 0.521566\n",
      "[42]\ttraining's l2: 19.1736\ttraining's r2: 0.804641\tvalid_0's l2: 48.1197\tvalid_0's r2: 0.524415\n",
      "[43]\ttraining's l2: 18.6951\ttraining's r2: 0.809517\tvalid_0's l2: 47.855\tvalid_0's r2: 0.527031\n",
      "[44]\ttraining's l2: 18.1865\ttraining's r2: 0.814699\tvalid_0's l2: 47.6671\tvalid_0's r2: 0.528888\n",
      "[45]\ttraining's l2: 17.7332\ttraining's r2: 0.819317\tvalid_0's l2: 47.4108\tvalid_0's r2: 0.531421\n",
      "[46]\ttraining's l2: 17.2821\ttraining's r2: 0.823914\tvalid_0's l2: 47.1583\tvalid_0's r2: 0.533917\n",
      "[47]\ttraining's l2: 16.8233\ttraining's r2: 0.828588\tvalid_0's l2: 46.9955\tvalid_0's r2: 0.535526\n",
      "[48]\ttraining's l2: 16.4274\ttraining's r2: 0.832623\tvalid_0's l2: 46.8583\tvalid_0's r2: 0.536882\n",
      "[49]\ttraining's l2: 16.0655\ttraining's r2: 0.83631\tvalid_0's l2: 46.6781\tvalid_0's r2: 0.538662\n",
      "[50]\ttraining's l2: 15.6745\ttraining's r2: 0.840293\tvalid_0's l2: 46.4263\tvalid_0's r2: 0.541151\n",
      "[51]\ttraining's l2: 15.3534\ttraining's r2: 0.843565\tvalid_0's l2: 46.2948\tvalid_0's r2: 0.542451\n",
      "[52]\ttraining's l2: 15.0403\ttraining's r2: 0.846755\tvalid_0's l2: 46.168\tvalid_0's r2: 0.543704\n",
      "[53]\ttraining's l2: 14.7168\ttraining's r2: 0.850051\tvalid_0's l2: 45.936\tvalid_0's r2: 0.545997\n",
      "[54]\ttraining's l2: 14.3657\ttraining's r2: 0.853629\tvalid_0's l2: 45.6886\tvalid_0's r2: 0.548443\n",
      "[55]\ttraining's l2: 14.095\ttraining's r2: 0.856386\tvalid_0's l2: 45.5613\tvalid_0's r2: 0.549701\n",
      "[56]\ttraining's l2: 13.805\ttraining's r2: 0.859341\tvalid_0's l2: 45.5857\tvalid_0's r2: 0.549459\n",
      "[57]\ttraining's l2: 13.5159\ttraining's r2: 0.862287\tvalid_0's l2: 45.5125\tvalid_0's r2: 0.550183\n",
      "[58]\ttraining's l2: 13.2567\ttraining's r2: 0.864928\tvalid_0's l2: 45.5302\tvalid_0's r2: 0.550008\n",
      "[59]\ttraining's l2: 13.0081\ttraining's r2: 0.867461\tvalid_0's l2: 45.5775\tvalid_0's r2: 0.54954\n",
      "[60]\ttraining's l2: 12.7761\ttraining's r2: 0.869825\tvalid_0's l2: 45.5272\tvalid_0's r2: 0.550038\n",
      "[61]\ttraining's l2: 12.5052\ttraining's r2: 0.872585\tvalid_0's l2: 45.4508\tvalid_0's r2: 0.550792\n",
      "[62]\ttraining's l2: 12.2349\ttraining's r2: 0.87534\tvalid_0's l2: 45.4182\tvalid_0's r2: 0.551115\n",
      "[63]\ttraining's l2: 11.9986\ttraining's r2: 0.877747\tvalid_0's l2: 45.3253\tvalid_0's r2: 0.552033\n",
      "[64]\ttraining's l2: 11.7633\ttraining's r2: 0.880145\tvalid_0's l2: 45.3222\tvalid_0's r2: 0.552064\n",
      "[65]\ttraining's l2: 11.5373\ttraining's r2: 0.882447\tvalid_0's l2: 45.229\tvalid_0's r2: 0.552985\n",
      "[66]\ttraining's l2: 11.2997\ttraining's r2: 0.884868\tvalid_0's l2: 45.1482\tvalid_0's r2: 0.553783\n",
      "[67]\ttraining's l2: 11.0776\ttraining's r2: 0.887131\tvalid_0's l2: 45.0518\tvalid_0's r2: 0.554736\n",
      "[68]\ttraining's l2: 10.854\ttraining's r2: 0.889409\tvalid_0's l2: 44.8734\tvalid_0's r2: 0.5565\n",
      "[69]\ttraining's l2: 10.6388\ttraining's r2: 0.891602\tvalid_0's l2: 44.6941\tvalid_0's r2: 0.558272\n",
      "[70]\ttraining's l2: 10.4686\ttraining's r2: 0.893336\tvalid_0's l2: 44.6784\tvalid_0's r2: 0.558426\n",
      "[71]\ttraining's l2: 10.2811\ttraining's r2: 0.895246\tvalid_0's l2: 44.6517\tvalid_0's r2: 0.55869\n",
      "[72]\ttraining's l2: 10.0975\ttraining's r2: 0.897117\tvalid_0's l2: 44.5448\tvalid_0's r2: 0.559747\n",
      "[73]\ttraining's l2: 9.92734\ttraining's r2: 0.898851\tvalid_0's l2: 44.3875\tvalid_0's r2: 0.561301\n",
      "[74]\ttraining's l2: 9.74722\ttraining's r2: 0.900686\tvalid_0's l2: 44.3608\tvalid_0's r2: 0.561566\n",
      "[75]\ttraining's l2: 9.59518\ttraining's r2: 0.902235\tvalid_0's l2: 44.3376\tvalid_0's r2: 0.561795\n",
      "[76]\ttraining's l2: 9.4269\ttraining's r2: 0.90395\tvalid_0's l2: 44.2223\tvalid_0's r2: 0.562935\n",
      "[77]\ttraining's l2: 9.25794\ttraining's r2: 0.905671\tvalid_0's l2: 44.1213\tvalid_0's r2: 0.563933\n",
      "[78]\ttraining's l2: 9.08853\ttraining's r2: 0.907397\tvalid_0's l2: 43.9799\tvalid_0's r2: 0.565331\n",
      "[79]\ttraining's l2: 8.94833\ttraining's r2: 0.908826\tvalid_0's l2: 43.7908\tvalid_0's r2: 0.567199\n",
      "[80]\ttraining's l2: 8.83021\ttraining's r2: 0.910029\tvalid_0's l2: 43.7059\tvalid_0's r2: 0.568038\n",
      "[81]\ttraining's l2: 8.6971\ttraining's r2: 0.911386\tvalid_0's l2: 43.8243\tvalid_0's r2: 0.566868\n",
      "[82]\ttraining's l2: 8.53596\ttraining's r2: 0.913028\tvalid_0's l2: 43.8411\tvalid_0's r2: 0.566702\n",
      "[83]\ttraining's l2: 8.38684\ttraining's r2: 0.914547\tvalid_0's l2: 43.8269\tvalid_0's r2: 0.566842\n",
      "[84]\ttraining's l2: 8.24306\ttraining's r2: 0.916012\tvalid_0's l2: 43.8132\tvalid_0's r2: 0.566977\n",
      "[85]\ttraining's l2: 8.12689\ttraining's r2: 0.917196\tvalid_0's l2: 43.9106\tvalid_0's r2: 0.566015\n",
      "[86]\ttraining's l2: 8.0116\ttraining's r2: 0.91837\tvalid_0's l2: 43.7933\tvalid_0's r2: 0.567175\n",
      "[87]\ttraining's l2: 7.91044\ttraining's r2: 0.919401\tvalid_0's l2: 43.6769\tvalid_0's r2: 0.568325\n",
      "[88]\ttraining's l2: 7.81364\ttraining's r2: 0.920387\tvalid_0's l2: 43.4921\tvalid_0's r2: 0.570151\n",
      "[89]\ttraining's l2: 7.71503\ttraining's r2: 0.921392\tvalid_0's l2: 43.3846\tvalid_0's r2: 0.571213\n",
      "[90]\ttraining's l2: 7.61976\ttraining's r2: 0.922363\tvalid_0's l2: 43.2659\tvalid_0's r2: 0.572387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91]\ttraining's l2: 7.50602\ttraining's r2: 0.923522\tvalid_0's l2: 43.2576\tvalid_0's r2: 0.572469\n",
      "[92]\ttraining's l2: 7.39312\ttraining's r2: 0.924672\tvalid_0's l2: 43.3311\tvalid_0's r2: 0.571743\n",
      "[93]\ttraining's l2: 7.28125\ttraining's r2: 0.925812\tvalid_0's l2: 43.406\tvalid_0's r2: 0.571002\n",
      "[94]\ttraining's l2: 7.17248\ttraining's r2: 0.92692\tvalid_0's l2: 43.3514\tvalid_0's r2: 0.571541\n",
      "[95]\ttraining's l2: 7.08328\ttraining's r2: 0.927829\tvalid_0's l2: 43.4466\tvalid_0's r2: 0.570601\n",
      "[96]\ttraining's l2: 6.99366\ttraining's r2: 0.928742\tvalid_0's l2: 43.42\tvalid_0's r2: 0.570864\n",
      "[97]\ttraining's l2: 6.89805\ttraining's r2: 0.929716\tvalid_0's l2: 43.3855\tvalid_0's r2: 0.571205\n",
      "[98]\ttraining's l2: 6.80529\ttraining's r2: 0.930661\tvalid_0's l2: 43.3933\tvalid_0's r2: 0.571128\n",
      "[99]\ttraining's l2: 6.73\ttraining's r2: 0.931428\tvalid_0's l2: 43.4157\tvalid_0's r2: 0.570906\n",
      "[100]\ttraining's l2: 6.67058\ttraining's r2: 0.932034\tvalid_0's l2: 43.3228\tvalid_0's r2: 0.571825\n",
      "[101]\ttraining's l2: 6.57019\ttraining's r2: 0.933057\tvalid_0's l2: 43.2942\tvalid_0's r2: 0.572107\n",
      "[102]\ttraining's l2: 6.4414\ttraining's r2: 0.934369\tvalid_0's l2: 43.2834\tvalid_0's r2: 0.572213\n",
      "[103]\ttraining's l2: 6.34653\ttraining's r2: 0.935336\tvalid_0's l2: 43.2084\tvalid_0's r2: 0.572955\n",
      "[104]\ttraining's l2: 6.26301\ttraining's r2: 0.936187\tvalid_0's l2: 43.2317\tvalid_0's r2: 0.572725\n",
      "[105]\ttraining's l2: 6.1687\ttraining's r2: 0.937147\tvalid_0's l2: 43.3149\tvalid_0's r2: 0.571902\n",
      "[106]\ttraining's l2: 6.06745\ttraining's r2: 0.938179\tvalid_0's l2: 43.4378\tvalid_0's r2: 0.570688\n",
      "[107]\ttraining's l2: 6.00527\ttraining's r2: 0.938813\tvalid_0's l2: 43.3373\tvalid_0's r2: 0.571681\n",
      "[108]\ttraining's l2: 5.9308\ttraining's r2: 0.939571\tvalid_0's l2: 43.2545\tvalid_0's r2: 0.5725\n",
      "[109]\ttraining's l2: 5.87551\ttraining's r2: 0.940135\tvalid_0's l2: 43.1511\tvalid_0's r2: 0.573522\n",
      "[110]\ttraining's l2: 5.80753\ttraining's r2: 0.940827\tvalid_0's l2: 43.1958\tvalid_0's r2: 0.57308\n",
      "[111]\ttraining's l2: 5.7425\ttraining's r2: 0.94149\tvalid_0's l2: 43.1463\tvalid_0's r2: 0.573569\n",
      "[112]\ttraining's l2: 5.67648\ttraining's r2: 0.942163\tvalid_0's l2: 43.2498\tvalid_0's r2: 0.572546\n",
      "[113]\ttraining's l2: 5.60806\ttraining's r2: 0.94286\tvalid_0's l2: 43.1577\tvalid_0's r2: 0.573456\n",
      "[114]\ttraining's l2: 5.54224\ttraining's r2: 0.94353\tvalid_0's l2: 43.1514\tvalid_0's r2: 0.573519\n",
      "[115]\ttraining's l2: 5.47657\ttraining's r2: 0.944199\tvalid_0's l2: 43.3145\tvalid_0's r2: 0.571907\n",
      "[116]\ttraining's l2: 5.38979\ttraining's r2: 0.945084\tvalid_0's l2: 43.2852\tvalid_0's r2: 0.572197\n",
      "[117]\ttraining's l2: 5.33255\ttraining's r2: 0.945667\tvalid_0's l2: 43.3179\tvalid_0's r2: 0.571873\n",
      "[118]\ttraining's l2: 5.27223\ttraining's r2: 0.946282\tvalid_0's l2: 43.3124\tvalid_0's r2: 0.571927\n",
      "[119]\ttraining's l2: 5.22149\ttraining's r2: 0.946799\tvalid_0's l2: 43.3807\tvalid_0's r2: 0.571252\n",
      "[120]\ttraining's l2: 5.15541\ttraining's r2: 0.947472\tvalid_0's l2: 43.3699\tvalid_0's r2: 0.571359\n",
      "[121]\ttraining's l2: 5.10581\ttraining's r2: 0.947977\tvalid_0's l2: 43.461\tvalid_0's r2: 0.570459\n",
      "[122]\ttraining's l2: 5.05251\ttraining's r2: 0.94852\tvalid_0's l2: 43.5293\tvalid_0's r2: 0.569784\n",
      "[123]\ttraining's l2: 4.98654\ttraining's r2: 0.949192\tvalid_0's l2: 43.4958\tvalid_0's r2: 0.570115\n",
      "[124]\ttraining's l2: 4.9366\ttraining's r2: 0.949701\tvalid_0's l2: 43.5633\tvalid_0's r2: 0.569447\n",
      "[125]\ttraining's l2: 4.89442\ttraining's r2: 0.950131\tvalid_0's l2: 43.6138\tvalid_0's r2: 0.568948\n",
      "[126]\ttraining's l2: 4.84007\ttraining's r2: 0.950685\tvalid_0's l2: 43.5083\tvalid_0's r2: 0.569991\n",
      "[127]\ttraining's l2: 4.79104\ttraining's r2: 0.951184\tvalid_0's l2: 43.4873\tvalid_0's r2: 0.570199\n",
      "[128]\ttraining's l2: 4.7388\ttraining's r2: 0.951717\tvalid_0's l2: 43.5058\tvalid_0's r2: 0.570016\n",
      "[129]\ttraining's l2: 4.69033\ttraining's r2: 0.95221\tvalid_0's l2: 43.383\tvalid_0's r2: 0.571229\n",
      "[130]\ttraining's l2: 4.63065\ttraining's r2: 0.952819\tvalid_0's l2: 43.32\tvalid_0's r2: 0.571852\n",
      "[131]\ttraining's l2: 4.56792\ttraining's r2: 0.953458\tvalid_0's l2: 43.3366\tvalid_0's r2: 0.571688\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's l2: 5.7425\ttraining's r2: 0.94149\tvalid_0's l2: 43.1463\tvalid_0's r2: 0.573569\n"
     ]
    }
   ],
   "source": [
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    #'metric': {'l1', 'l2'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.5,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0\n",
    "}\n",
    "\n",
    "def custom_r2(preds, train_data):\n",
    "    labels = train_data.get_label()\n",
    "    return 'r2', r2_score(labels, preds), True\n",
    "\n",
    "print('Start training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=500,\n",
    "                feval=custom_r2,\n",
    "                valid_sets={lgb_train, lgb_eval},\n",
    "                early_stopping_rounds=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and output submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load testing data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([73.95905989, 71.07851743, 73.50576307, 58.14165241, 73.408844  ,\n",
       "       65.78543127, 78.56009763, 66.40367125, 74.74709526, 64.69820868,\n",
       "       77.29132841, 61.57130182, 69.83793383, 72.25170893, 75.64706206,\n",
       "       74.04871991, 61.23418049, 74.0606731 , 72.03516297, 68.31445902,\n",
       "       64.36151674, 63.57373242, 78.22729283, 72.39271542, 69.7098291 ,\n",
       "       66.08867651, 60.89273874, 79.70099579, 77.67479169, 74.21764574,\n",
       "       53.59425283, 72.01649804, 62.68205172, 63.72751212, 65.15659754,\n",
       "       66.98520607, 77.62733706, 58.79106664, 66.9327608 , 71.54270884,\n",
       "       76.25857437, 76.54439783, 62.94351222, 70.44438894, 69.00643244,\n",
       "       63.89062846, 80.09141316, 75.74538033, 76.38627439, 77.57410333,\n",
       "       63.38218739, 61.33966117, 59.32463539, 63.08320001, 56.46820588,\n",
       "       65.22223101, 82.31690896, 57.13400309, 54.06622226, 75.2455487 ,\n",
       "       76.00242895, 75.1337097 , 75.88531324, 61.46634293, 67.25121429,\n",
       "       68.45077976, 78.41629315, 77.47698102, 60.41465375, 61.40767376,\n",
       "       77.36885593, 66.46757545, 76.81448767, 76.38178298, 62.89844115,\n",
       "       65.7050666 , 70.50960912, 70.44679871, 75.32168065, 64.76321338,\n",
       "       70.29571414, 71.50719094, 76.23651324, 59.49362102, 67.19816704,\n",
       "       77.45633543, 74.76927711, 82.49467269, 73.0741012 , 66.30386104,\n",
       "       81.00076269, 68.45975815, 78.01408377, 67.61294753, 77.32491898,\n",
       "       65.39201674, 78.28752993, 73.01751648, 59.72427985, 62.3198976 ,\n",
       "       74.04463051, 76.96753552, 79.10681167, 72.66056372, 73.52790793,\n",
       "       70.65145251, 77.87980035, 78.13414722, 79.2669168 , 80.9173007 ,\n",
       "       64.8670633 , 73.60720986, 66.29693304, 76.47349113, 65.30880826,\n",
       "       67.87363755, 78.50118134, 65.23469865, 64.94198693, 77.14401015,\n",
       "       71.59053034, 64.67416598, 70.71596386, 75.14568237, 62.66796788,\n",
       "       65.24173001, 57.82497196, 77.26940643, 62.40394596, 76.5856524 ,\n",
       "       73.77345159, 70.76012771, 68.90469939, 61.89082902, 66.68906363,\n",
       "       69.90399527, 70.02651271, 65.623535  , 57.04553018, 70.75547536,\n",
       "       58.15577616, 69.03892383, 65.27790012, 78.99170674, 79.19094789,\n",
       "       74.61822884, 73.48367293, 75.49839325, 67.96162845, 69.53349195,\n",
       "       68.68298076, 67.4751511 , 66.10093636, 65.06884608, 72.11587543,\n",
       "       73.84617182, 69.21076151, 81.45557636, 62.41010265, 74.15068173,\n",
       "       65.09473136, 64.23338906, 71.98094485, 58.04432981, 59.753496  ,\n",
       "       63.51156581, 71.10983133, 65.05044414, 75.31317861, 74.53856246,\n",
       "       70.89311358, 75.09412383, 65.17923148, 58.39790556, 71.36740485,\n",
       "       59.82272302, 73.69101951, 73.41061567, 61.57614367, 73.28233893,\n",
       "       76.04686244, 77.61866523, 81.19619709, 81.01466728, 79.69933228,\n",
       "       74.02903875, 66.2452169 , 60.79543088, 65.68472185, 58.23101769,\n",
       "       71.20915107, 72.19153475, 76.01262265, 61.68746321, 70.32763038,\n",
       "       80.85548339, 72.81374834, 73.65409451, 79.63006997, 77.92258878,\n",
       "       57.48328476, 72.96062133, 72.848792  , 71.25082775, 71.13550642,\n",
       "       72.7942304 , 78.08620975, 58.37760645, 57.37815434, 60.09855219,\n",
       "       71.30216683, 70.81683019, 68.83650827, 75.17620313, 60.19964202,\n",
       "       56.30644991, 69.65667739, 71.55400666, 59.2997236 , 80.69325254,\n",
       "       75.78250589, 73.01479929, 56.24624131, 61.21221105, 74.30960624,\n",
       "       78.40571404, 77.02501291, 75.30926951, 74.71193732, 76.66476622,\n",
       "       67.12945438, 73.64283537, 61.29802053, 74.23129676, 55.23073948,\n",
       "       73.81906066, 69.23917227, 57.12286885, 74.04251604, 69.20883553,\n",
       "       69.9310476 , 60.97767009, 72.12293159, 76.92674151, 63.58400871,\n",
       "       52.74745919, 73.22358653, 78.38637339, 77.04013257, 64.62622318,\n",
       "       66.50680861, 66.78941873, 75.2084211 , 60.82351244, 66.87622589,\n",
       "       77.37889286, 81.72242191, 75.95440608, 64.69312193, 74.74918137,\n",
       "       65.54558439, 79.93506315, 62.56922491, 66.11135465, 74.12107561,\n",
       "       69.11225985, 86.10709064, 71.94108136, 69.90336458, 73.22765679,\n",
       "       71.64332862, 61.02470227, 66.83282008, 60.87035616, 72.24790274,\n",
       "       69.30743669, 75.14972989, 77.57269879, 78.28684601, 74.29433157,\n",
       "       76.15459465, 78.98302722, 70.23219226, 70.63621724, 66.79834677,\n",
       "       82.77247958, 82.86459415, 76.64454496, 74.39748746, 70.72834616,\n",
       "       62.16408029, 67.61715626, 70.08696333, 77.97236438, 67.24492402,\n",
       "       67.71958466, 62.33565875, 63.18518121, 62.41800539, 67.45896134,\n",
       "       71.90975254, 70.76050207, 74.71078427, 73.07726581, 78.70300035,\n",
       "       62.47404525, 72.38770671, 53.27911337, 69.69147997, 77.01504916,\n",
       "       63.3786427 , 70.40297916, 76.39895976, 77.63987311, 77.30316988,\n",
       "       58.52066441, 59.49081743, 78.72867823, 58.79812527, 69.81265413,\n",
       "       64.49757887, 74.72580806, 67.38639498, 75.25200352, 79.56608976,\n",
       "       69.75838291, 77.63746646, 79.2968854 , 63.99765092, 72.16135956,\n",
       "       80.10353258, 56.0851307 , 76.5385172 , 76.42331719, 79.31631086,\n",
       "       61.32233956, 68.14621472, 70.84055887, 68.27923874, 75.07587731,\n",
       "       68.85358988, 71.61752555, 68.7388065 , 68.56417061, 72.53412497,\n",
       "       59.75383278, 73.59672022, 65.23325763, 54.3314123 , 65.6718066 ,\n",
       "       66.28435771, 72.44742768, 69.95659505, 75.89761962, 66.40822405,\n",
       "       79.43718875, 72.12864498, 61.67271929, 78.95415292, 79.47156764,\n",
       "       66.64757861, 69.10151211, 64.32095751, 67.02314722, 78.84411634,\n",
       "       53.21856144, 67.17585468, 56.6024218 , 66.8215929 , 76.18145743,\n",
       "       63.55170541, 69.01642604, 76.86361938, 72.13907316, 78.44669904,\n",
       "       59.27575194, 79.40048342, 72.04250386, 75.78412186, 71.19960687,\n",
       "       68.0199268 , 77.30874824, 77.51680338, 73.2060686 , 73.7378768 ,\n",
       "       80.78820736, 65.12864233, 70.15065158, 61.12047156, 76.90102009,\n",
       "       74.09128929, 55.66129453, 77.52048705, 63.06809907, 76.79737991,\n",
       "       65.55673184, 68.47425386, 83.21957597, 61.30386724, 81.00070871,\n",
       "       76.56028985, 60.26729246, 67.08230632, 73.5725685 , 77.40671547,\n",
       "       68.16019519, 63.3561635 , 73.31013803, 68.58140313, 82.18567606,\n",
       "       75.24872402, 64.39385079, 67.35674813, 82.68480889, 59.01611538,\n",
       "       69.59298803, 73.67455846, 72.8437272 , 73.4280921 , 50.88349905,\n",
       "       80.02256805, 64.01109272, 63.59252842, 69.40991259, 74.55836995,\n",
       "       76.64309482, 66.88616238, 81.26333122, 75.30060362, 82.65699819,\n",
       "       62.22665384, 64.74179299, 76.44266163, 67.59768899, 69.35378649,\n",
       "       70.42391272, 74.72784629, 61.21517045, 79.01587115, 76.48973906,\n",
       "       59.1657708 , 65.57227501, 64.15844577, 67.57715681, 61.37369852,\n",
       "       73.44147783, 75.8045337 , 76.36969562, 78.30267493, 65.94469248,\n",
       "       64.70949429, 64.3451613 , 68.33462874, 68.84110096, 71.63095104,\n",
       "       55.26478944, 62.89613684, 73.54084641, 76.6906363 , 71.5066542 ,\n",
       "       70.41673812, 65.99899639, 65.43518021, 79.55738487, 70.13898874,\n",
       "       78.14331026, 69.6227344 , 61.87809891, 59.79972182, 78.94238382,\n",
       "       71.04107978, 63.99148633, 77.86856309, 73.98582928, 74.80126193,\n",
       "       61.65765025, 72.68929817, 67.49022601, 73.19270893, 66.46277247,\n",
       "       67.10106696, 65.82229857, 71.27250966, 61.3165905 , 70.01291841,\n",
       "       73.76664779, 68.64226268, 72.78586897, 65.61018052, 72.38413219,\n",
       "       77.10070691, 77.34754782, 86.42823236, 66.85834748, 72.46009614,\n",
       "       62.04962941, 64.31859375, 63.18291934, 72.20658047, 70.7088208 ,\n",
       "       68.34727531, 71.04441269, 71.5140464 , 73.58658573, 73.20777858,\n",
       "       77.14874103, 74.94643045, 77.07306909, 75.34438277, 68.17706354,\n",
       "       69.90673615, 67.92388574, 59.89208787, 63.37882996, 77.02734804,\n",
       "       72.21999837, 69.92954526, 75.19854891, 63.37313051, 60.61635501,\n",
       "       77.15695544, 63.63802803, 67.6065081 , 69.79769701, 62.28021555,\n",
       "       75.28077137, 64.43693396, 69.48348548, 64.2791709 , 66.21444084,\n",
       "       81.95310867, 63.71128454, 61.23014668, 74.77289462, 63.33364371,\n",
       "       61.54274511, 73.68992086, 72.26482327, 73.44230232, 65.2186802 ,\n",
       "       60.65800605, 86.84453249, 64.81788776, 70.02344131, 69.79025402,\n",
       "       63.71651186, 78.77010371, 72.3001312 , 70.57462377, 70.20973318,\n",
       "       77.10944646, 66.55227732, 62.08436891, 58.20778506, 67.6412249 ,\n",
       "       71.29038605, 71.15301   , 64.4186064 , 56.76681381, 75.04989607,\n",
       "       68.99125153, 80.25621878, 67.41074774, 67.67117421, 70.8899699 ,\n",
       "       78.421352  , 80.13178516, 61.29987612, 73.34264318, 69.61848198,\n",
       "       71.4134094 , 66.85377925, 77.92042172, 74.14357108, 57.89417269,\n",
       "       72.26746439, 64.780529  , 75.99006395, 77.14737089, 58.28635616,\n",
       "       79.12854106, 56.76642262, 73.37503632, 73.72276294, 80.65702259,\n",
       "       72.19420958, 62.1833398 , 78.48469062, 66.24593854, 74.73738923,\n",
       "       69.41260893, 77.15211027, 79.73935007, 75.55316543, 64.66512461,\n",
       "       66.15429881, 64.63696179, 76.28132995, 80.4996355 , 79.50296308,\n",
       "       63.47682408, 78.19729903, 55.11735543, 65.15163013, 54.81827872,\n",
       "       63.0679684 , 71.30923823, 78.94165555, 78.49265173, 65.24392651,\n",
       "       58.151694  , 79.06814718, 77.91751862, 58.85158181, 80.07982028,\n",
       "       61.48931963, 58.9773942 , 55.08243547, 64.52303366, 66.44992237,\n",
       "       73.04015159, 55.65425206, 81.23939063, 71.78257228, 67.53876742,\n",
       "       63.45556086, 73.96140702, 72.65085907, 72.18466891, 73.20453212,\n",
       "       75.39075616, 71.00092117, 73.67367141, 63.33776856, 74.8818538 ,\n",
       "       79.06278699, 60.81963393, 78.95796463, 73.85571027, 60.15917115,\n",
       "       81.06222598, 71.99608628, 65.10565927, 60.36820982, 66.94777105,\n",
       "       78.03354779, 77.70576725, 64.66099792, 67.64121248, 60.10796385,\n",
       "       73.54023755, 70.12841553, 76.09803379, 65.60367944, 66.29245792,\n",
       "       63.74262279, 67.16152412, 61.90754258, 78.34401469, 73.2985364 ,\n",
       "       62.47365301, 65.67007124, 58.81319608, 80.26983924, 65.21427704,\n",
       "       73.3915751 , 68.45092355, 79.37940657, 70.59973393, 64.14836991,\n",
       "       57.85004115, 78.44605011, 59.60048299, 54.08505733, 71.54823253,\n",
       "       62.32153202, 75.9076687 , 59.31448572, 67.89528054, 63.14140583,\n",
       "       63.53222259, 63.72678353, 78.21268894, 75.30621544, 65.61200362,\n",
       "       70.63701486, 77.33014158, 54.73698073, 68.76394604, 78.64219132,\n",
       "       66.86321253, 71.22109567, 62.5922557 , 81.01140328, 74.75138687,\n",
       "       60.32783329, 72.26582454, 60.88025476, 79.9320708 , 73.83116426,\n",
       "       70.58296461, 72.16945605, 60.04925028, 64.42971384, 73.32278442,\n",
       "       74.20794431, 68.69045391, 64.49893592, 69.61732676, 64.58711409,\n",
       "       74.75312022, 74.68710359, 56.64364145, 70.38758441, 66.64294247,\n",
       "       72.80473349, 65.90321788, 67.78629063, 67.16573634, 74.39013025,\n",
       "       68.10262678, 82.45454359, 62.78791947, 75.42188728, 69.95645993,\n",
       "       69.11644521, 66.58798426, 59.68537621, 67.14192099, 58.29456015,\n",
       "       70.81070738, 68.12720809, 77.45034605, 65.2559574 , 79.89487693,\n",
       "       66.91072507, 71.86628007, 69.13959608, 73.86194263, 79.37540234,\n",
       "       62.74255536, 60.72442765, 74.89166393, 52.90625845, 73.32216141,\n",
       "       63.63159139, 61.44061183, 68.30870428, 66.49798175, 70.2075541 ,\n",
       "       72.1173271 , 64.55319159, 60.85807074, 70.44059603, 66.34979691,\n",
       "       81.61919927, 69.96652249, 79.4473747 , 61.01497575, 62.34115312,\n",
       "       75.88125006, 71.48089777, 65.46872862, 56.09251437, 79.24777232,\n",
       "       69.4380332 , 76.61182381, 74.39240411, 70.5963055 , 61.59384934,\n",
       "       81.44093619, 64.22313614, 64.92600616, 81.67279591, 70.63797034,\n",
       "       69.06882938])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Load testing data...')\n",
    "df_x_test = pd.read_csv('X_test.csv', header=0, index_col = 0)\n",
    "X_test = df_x_test[selected_features].values\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"submission.csv\", \"w\")\n",
    "f.write(\"id,y\\n\")\n",
    "for i,x in enumerate(y_pred):\n",
    "    f.write(\"{},{}\\n\".format(i,x))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Randomly find best result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = 0\n",
    "for i in range(100):\n",
    "    print('Splitting into training and validation dataset')\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.15) # , random_state = 19960503)\n",
    "    # create dataset for lightgbm\n",
    "    lgb_train = lgb.Dataset(X_train, y_train)\n",
    "    lgb_eval = lgb.Dataset(X_val, y_val, reference=lgb_train)\n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        #'metric': {'l1', 'l2'},\n",
    "        'num_leaves': 31,\n",
    "        'learning_rate': 0.05,\n",
    "        'feature_fraction': 0.5,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    def custom_r2(preds, train_data):\n",
    "        labels = train_data.get_label()\n",
    "        return 'r2', r2_score(labels, preds), True\n",
    "\n",
    "    print('Start training...')\n",
    "    # train\n",
    "    gbm = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=500,\n",
    "                    feval=custom_r2,\n",
    "                    valid_sets={lgb_train, lgb_eval},\n",
    "                    early_stopping_rounds=20)\n",
    "    y_val_p = gbm.predict(X_val, num_iteration=gbm.best_iteration)\n",
    "    \n",
    "    result = r2_score(y_val, y_val_p)\n",
    "    if result > best:\n",
    "        print(\"New Best {}\".format(result))\n",
    "        best = result\n",
    "        y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "        f = open(\"submission{0:.4f}.csv\".format(best), \"w\")\n",
    "        f.write(\"id,y\\n\")\n",
    "        for i,x in enumerate(y_pred):\n",
    "            f.write(\"{},{}\\n\".format(i,x))\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
