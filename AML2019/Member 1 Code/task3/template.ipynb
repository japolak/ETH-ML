{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biosppy.signals.ecg as ecg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals = []\n",
    "with open(\"data/X_train.csv\") as f_train:\n",
    "    for line in f_train.readlines()[1:]:\n",
    "        signals.append(list(map(int, line.split(',')[1:])))\n",
    "y = []\n",
    "with open(\"data/y_train.csv\") as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        y.append(int(line.split(',')[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ecg.ecg(signals[5], 300.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = ecg.ecg(signals[0], 300.0)\n",
    "len(r[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r[4][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(r[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type0 = [signals[i] for i in range(len(y)) if y[i] == 0]\n",
    "type1 = [signals[i] for i in range(len(y)) if y[i] == 1]\n",
    "type2 = [signals[i] for i in range(len(y)) if y[i] == 2]\n",
    "type3 = [signals[i] for i in range(len(y)) if y[i] == 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for s in type1[:20]:\n",
    "    print(len(ecg.ecg(s, 300.0)[4][0]))\n",
    "    # rpeaks = ecg.ssf_segmenter(s, 300.0)[0]\n",
    "    # print(len(ecg.extract_heartbeats(s, rpeaks, 300.0)[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def template(s):\n",
    "    # print(s)\n",
    "    # rpeaks = ecg.christov_segmenter(signal=s, sampling_rate=300.0)[0]\n",
    "    # print(rpeaks)\n",
    "    # return ecg.extract_heartbeats(s, rpeaks=rpeaks, sampling_rate=300.0)[0]\n",
    "    return ecg.ecg(s, sampling_rate=300.0, show=False)[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "cnt = 0\n",
    "for s in signals:\n",
    "    print(cnt)\n",
    "    cnt += 1\n",
    "    beats = template(s)\n",
    "    temp = [0 for i in range(len(beats[0]))]\n",
    "    for beat in beats:\n",
    "        for i, val in enumerate(beat):\n",
    "            temp[i] += val\n",
    "    for i, val in enumerate(temp):\n",
    "        temp[i] = val / len(beats)\n",
    "    X.append(temp)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"template.csv\", \"w\") as f:\n",
    "    s = \"Id\"\n",
    "    for i in range(150):\n",
    "        s += \",x%d\"%i\n",
    "    s += \"\\n\"\n",
    "    f.write(s)\n",
    "    for x in X:\n",
    "        s = ','.join(map(str,x)) + \"\\n\"\n",
    "        f.write(s)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_X = np.array(X[:int(len(X)*0.7)])\n",
    "# train_Y = np.array(y[:int(len(X)*0.7)])\n",
    "# eval_X = np.array(X[int(len(X)*0.7):])\n",
    "# eval_Y = np.array(y[int(len(X)*0.7):])\n",
    "train_X, eval_X, train_Y, eval_Y = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "xg_train = xgb.DMatrix(train_X, label=train_Y)\n",
    "xg_eval = xgb.DMatrix(eval_X, label=eval_Y)\n",
    "\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.2\n",
    "param['gamma'] = 1.0\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['subsample'] = 0.8\n",
    "param['colsample_bytree'] = 0.9\n",
    "param['min_child_weight'] = 20\n",
    "param['num_class'] = 4\n",
    "\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_eval, 'eval')]\n",
    "num_round = 60\n",
    "bst = xgb.train(param, \n",
    "                xg_train, \n",
    "                num_round, \n",
    "                watchlist, \n",
    "                feval=lambda y,t: (\"f1\", f1_score(y, t.get_label(), average='micro')))\n",
    "\n",
    "# get prediction\n",
    "pred = bst.predict(xg_eval)\n",
    "# error_rate = np.sum(pred != test_Y) / test_Y.shape[0]\n",
    "F1 = f1_score(eval_Y, pred, average='micro')\n",
    "print('Test error using softmax = {}'.format(F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testsignals = []\n",
    "with open(\"data/X_test.csv\") as f_test:\n",
    "    for line in f_test.readlines()[1:]:\n",
    "        testsignals.append(list(map(int, line.split(',')[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = []\n",
    "cnt = 0\n",
    "for s in testsignals:\n",
    "    print(cnt)\n",
    "    cnt += 1\n",
    "    beats = template(s)\n",
    "    temp = [0 for i in range(len(beats[0]))]\n",
    "    for beat in beats:\n",
    "        for i, val in enumerate(beat):\n",
    "            temp[i] += val\n",
    "    for i, val in enumerate(temp):\n",
    "        temp[i] = val / len(beats)\n",
    "    test_X.append(temp)\n",
    "test_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_test = xgb.DMatrix(test_X)\n",
    "y_pred = bst.predict(xg_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"submission.csv\", \"w\")\n",
    "f.write(\"id,y\\n\")\n",
    "for i,x in enumerate(y_pred):\n",
    "    f.write(\"{},{}\\n\".format(i,y_pred[i]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
