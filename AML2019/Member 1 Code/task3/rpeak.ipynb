{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.6/site-packages/lightgbm/__init__.py:45: FutureWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS will be built by the Apple Clang compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you won't need to install the gcc compiler anymore.\n",
      "Instead of that, you'll need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import biosppy.signals.ecg as ecg\n",
    "import lightgbm as lgb\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_add = np.loadtxt('data/otherfeature_complete.csv', delimiter=',', skiprows=1, usecols=range(1,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.loadtxt('data/rpeakfeature.csv', delimiter=',', skiprows=1, usecols=range(1,9))\n",
    "y = np.loadtxt('data/y_train.csv', delimiter=',', skiprows=1, usecols=range(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "newX = []\n",
    "for i in range(len(X)):\n",
    "     newX.append(np.concatenate([X[i], X_add[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-merror:0.294049\teval-merror:0.330965\ttrain-f1:0.705951\teval-f1:0.669035\n",
      "[1]\ttrain-merror:0.248833\teval-merror:0.290705\ttrain-f1:0.751167\teval-f1:0.709295\n",
      "[2]\ttrain-merror:0.237165\teval-merror:0.294849\ttrain-f1:0.762835\teval-f1:0.705151\n",
      "[3]\ttrain-merror:0.226663\teval-merror:0.280639\ttrain-f1:0.773337\teval-f1:0.719361\n",
      "[4]\ttrain-merror:0.217328\teval-merror:0.271166\ttrain-f1:0.782672\teval-f1:0.728834\n",
      "[5]\ttrain-merror:0.214702\teval-merror:0.271758\ttrain-f1:0.785298\teval-f1:0.728242\n",
      "[6]\ttrain-merror:0.209452\teval-merror:0.261693\ttrain-f1:0.790548\teval-f1:0.738307\n",
      "[7]\ttrain-merror:0.205076\teval-merror:0.262877\ttrain-f1:0.794924\teval-f1:0.737123\n",
      "[8]\ttrain-merror:0.204492\teval-merror:0.259325\ttrain-f1:0.795508\teval-f1:0.740675\n",
      "[9]\ttrain-merror:0.196908\teval-merror:0.256365\ttrain-f1:0.803092\teval-f1:0.743635\n",
      "[10]\ttrain-merror:0.187573\teval-merror:0.25222\ttrain-f1:0.812427\teval-f1:0.74778\n",
      "[11]\ttrain-merror:0.186406\teval-merror:0.251036\ttrain-f1:0.813594\teval-f1:0.748964\n",
      "[12]\ttrain-merror:0.184656\teval-merror:0.251036\ttrain-f1:0.815344\teval-f1:0.748964\n",
      "[13]\ttrain-merror:0.18203\teval-merror:0.248076\ttrain-f1:0.81797\teval-f1:0.751924\n",
      "[14]\ttrain-merror:0.180572\teval-merror:0.2463\ttrain-f1:0.819428\teval-f1:0.7537\n",
      "[15]\ttrain-merror:0.17853\teval-merror:0.248668\ttrain-f1:0.82147\teval-f1:0.751332\n",
      "[16]\ttrain-merror:0.177363\teval-merror:0.242747\ttrain-f1:0.822637\teval-f1:0.757253\n",
      "[17]\ttrain-merror:0.172987\teval-merror:0.245708\ttrain-f1:0.827013\teval-f1:0.754292\n",
      "[18]\ttrain-merror:0.168611\teval-merror:0.244523\ttrain-f1:0.831389\teval-f1:0.755477\n",
      "[19]\ttrain-merror:0.166278\teval-merror:0.245708\ttrain-f1:0.833722\teval-f1:0.754292\n",
      "[20]\ttrain-merror:0.162777\teval-merror:0.242747\ttrain-f1:0.837223\teval-f1:0.757253\n",
      "[21]\ttrain-merror:0.164236\teval-merror:0.242747\ttrain-f1:0.835764\teval-f1:0.757253\n",
      "[22]\ttrain-merror:0.161319\teval-merror:0.242747\ttrain-f1:0.838681\teval-f1:0.757253\n",
      "[23]\ttrain-merror:0.160152\teval-merror:0.242747\ttrain-f1:0.839848\teval-f1:0.757253\n",
      "[24]\ttrain-merror:0.155193\teval-merror:0.243931\ttrain-f1:0.844807\teval-f1:0.756069\n",
      "[25]\ttrain-merror:0.154901\teval-merror:0.245115\ttrain-f1:0.845099\teval-f1:0.754885\n",
      "[26]\ttrain-merror:0.152859\teval-merror:0.243339\ttrain-f1:0.847141\teval-f1:0.756661\n",
      "[27]\ttrain-merror:0.152275\teval-merror:0.242747\ttrain-f1:0.847725\teval-f1:0.757253\n",
      "[28]\ttrain-merror:0.149067\teval-merror:0.241563\ttrain-f1:0.850933\teval-f1:0.758437\n",
      "[29]\ttrain-merror:0.147024\teval-merror:0.243339\ttrain-f1:0.852975\teval-f1:0.756661\n",
      "[30]\ttrain-merror:0.144983\teval-merror:0.241563\ttrain-f1:0.855018\teval-f1:0.758437\n",
      "[31]\ttrain-merror:0.144107\teval-merror:0.239195\ttrain-f1:0.855893\teval-f1:0.760805\n",
      "[32]\ttrain-merror:0.140607\teval-merror:0.239195\ttrain-f1:0.859393\teval-f1:0.760805\n",
      "[33]\ttrain-merror:0.14119\teval-merror:0.243339\ttrain-f1:0.85881\teval-f1:0.756661\n",
      "[34]\ttrain-merror:0.138273\teval-merror:0.242747\ttrain-f1:0.861727\teval-f1:0.757253\n",
      "[35]\ttrain-merror:0.136231\teval-merror:0.239195\ttrain-f1:0.863769\teval-f1:0.760805\n",
      "[36]\ttrain-merror:0.133314\teval-merror:0.236234\ttrain-f1:0.866686\teval-f1:0.763766\n",
      "[37]\ttrain-merror:0.130688\teval-merror:0.239195\ttrain-f1:0.869312\teval-f1:0.760805\n",
      "[38]\ttrain-merror:0.128646\teval-merror:0.239787\ttrain-f1:0.871354\teval-f1:0.760213\n",
      "[39]\ttrain-merror:0.125729\teval-merror:0.239195\ttrain-f1:0.874271\teval-f1:0.760805\n",
      "[40]\ttrain-merror:0.123687\teval-merror:0.243931\ttrain-f1:0.876313\teval-f1:0.756069\n",
      "[41]\ttrain-merror:0.122812\teval-merror:0.240971\ttrain-f1:0.877188\teval-f1:0.759029\n",
      "[42]\ttrain-merror:0.122812\teval-merror:0.239195\ttrain-f1:0.877188\teval-f1:0.760805\n",
      "[43]\ttrain-merror:0.12077\teval-merror:0.241563\ttrain-f1:0.87923\teval-f1:0.758437\n",
      "[44]\ttrain-merror:0.116978\teval-merror:0.239787\ttrain-f1:0.883022\teval-f1:0.760213\n",
      "[45]\ttrain-merror:0.114936\teval-merror:0.239195\ttrain-f1:0.885064\teval-f1:0.760805\n",
      "[46]\ttrain-merror:0.114936\teval-merror:0.239787\ttrain-f1:0.885064\teval-f1:0.760213\n",
      "[47]\ttrain-merror:0.111727\teval-merror:0.244523\ttrain-f1:0.888273\teval-f1:0.755477\n",
      "[48]\ttrain-merror:0.109685\teval-merror:0.242155\ttrain-f1:0.890315\teval-f1:0.757845\n",
      "[49]\ttrain-merror:0.110268\teval-merror:0.239787\ttrain-f1:0.889732\teval-f1:0.760213\n",
      "[50]\ttrain-merror:0.106768\teval-merror:0.243931\ttrain-f1:0.893232\teval-f1:0.756069\n",
      "[51]\ttrain-merror:0.104142\teval-merror:0.241563\ttrain-f1:0.895858\teval-f1:0.758437\n",
      "[52]\ttrain-merror:0.105018\teval-merror:0.242155\ttrain-f1:0.894982\teval-f1:0.757845\n",
      "[53]\ttrain-merror:0.104726\teval-merror:0.240971\ttrain-f1:0.895274\teval-f1:0.759029\n",
      "[54]\ttrain-merror:0.103559\teval-merror:0.241563\ttrain-f1:0.896441\teval-f1:0.758437\n",
      "[55]\ttrain-merror:0.099183\teval-merror:0.242155\ttrain-f1:0.900817\teval-f1:0.757845\n",
      "[56]\ttrain-merror:0.099183\teval-merror:0.243339\ttrain-f1:0.900817\teval-f1:0.756661\n",
      "[57]\ttrain-merror:0.0986\teval-merror:0.243339\ttrain-f1:0.9014\teval-f1:0.756661\n",
      "[58]\ttrain-merror:0.097141\teval-merror:0.242155\ttrain-f1:0.902859\teval-f1:0.757845\n",
      "[59]\ttrain-merror:0.095391\teval-merror:0.243931\ttrain-f1:0.904609\teval-f1:0.756069\n",
      "Test error using softmax = 0.7560686796921255\n"
     ]
    }
   ],
   "source": [
    "# train_X = np.array(X[:int(len(X)*0.7)])\n",
    "# train_Y = np.array(y[:int(len(X)*0.7)])\n",
    "# eval_X = np.array(X[int(len(X)*0.7):])\n",
    "# eval_Y = np.array(y[int(len(X)*0.7):])\n",
    "train_X, eval_X, train_Y, eval_Y = train_test_split(newX, y, test_size=0.33, random_state=42)\n",
    "xg_train = xgb.DMatrix(train_X, label=train_Y)\n",
    "xg_eval = xgb.DMatrix(eval_X, label=eval_Y)\n",
    "\n",
    "# setup parameters for xgboost\n",
    "param = {}\n",
    "# use softmax multi-class classification\n",
    "param['objective'] = 'multi:softmax'\n",
    "# scale weight of positive examples\n",
    "param['eta'] = 0.2\n",
    "param['gamma'] = 1.0\n",
    "param['max_depth'] = 6\n",
    "param['silent'] = 1\n",
    "param['subsample'] = 0.8\n",
    "param['colsample_bytree'] = 0.9\n",
    "param['min_child_weight'] = 20\n",
    "param['num_class'] = 4\n",
    "\n",
    "\n",
    "watchlist = [(xg_train, 'train'), (xg_eval, 'eval')]\n",
    "num_round = 60\n",
    "bst = xgb.train(param, \n",
    "                xg_train, \n",
    "                num_round, \n",
    "                watchlist, \n",
    "                feval=lambda y,t: (\"f1\", f1_score(y, t.get_label(), average='micro')))\n",
    "\n",
    "# get prediction\n",
    "pred = bst.predict(xg_eval)\n",
    "# error_rate = np.sum(pred != test_Y) / test_Y.shape[0]\n",
    "F1 = f1_score(eval_Y, pred, average='micro')\n",
    "print('Test error using softmax = {}'.format(F1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X = np.loadtxt('data/rpeakfeature_test.csv', delimiter=',', skiprows=1, usecols=range(1,9))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_add = np.loadtxt('data/test_otherfeature_complete.csv', delimiter=',', skiprows=1, usecols=range(1,21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_X_new = []\n",
    "for i in range(len(test_X)):\n",
    "     test_X_new.append(np.concatenate([test_X[i], test_X_add[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_test = xgb.DMatrix(test_X_new)\n",
    "y_pred = bst.predict(xg_test)\n",
    "f = open(\"submission.csv\", \"w\")\n",
    "f.write(\"id,y\\n\")\n",
    "for i,x in enumerate(y_pred):\n",
    "    f.write(\"{},{}\\n\".format(i,y_pred[i]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
