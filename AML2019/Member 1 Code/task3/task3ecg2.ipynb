{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[github ecg project](https://github.com/mondejar/ecg-classification)\n",
    "\n",
    "[physionet paper](https://physionet.nlm.nih.gov/challenge/2017/Clifford_et-al-challenge_2017_CinC_paper.pdf)\n",
    "\n",
    "[Beat_Classification code](https://github.com/citiususc/construe/blob/public/Beat_Classification.md)\n",
    "\n",
    "[resnet code](https://github.com/mist3rr0b0t/Resnet-for-AF-classification)\n",
    "\n",
    "[ecg knowledge](http://www.medicine-on-line.com/html/ecg/e0001ct_files/05.htm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import biosppy.signals.ecg as ecg\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "signals = []\n",
    "with open(\"data/X_train.csv\") as f_train:\n",
    "    for line in f_train.readlines()[1:]:\n",
    "        signals.append(list(map(int, line.split(',')[1:])))\n",
    "y = []\n",
    "with open(\"data/y_train.csv\") as f:\n",
    "    for line in f.readlines()[1:]:\n",
    "        y.append(int(line.split(',')[1]))\n",
    "# ecg.ecg(signals[5], 300.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of type0 is  3030\n",
      "The length of type1 is  443\n",
      "The length of type2 is  1474\n",
      "The length of type3 is  170\n"
     ]
    }
   ],
   "source": [
    "# Classify the data\n",
    "type0 = [signals[i] for i in range(len(y)) if y[i] == 0]\n",
    "type1 = [signals[i] for i in range(len(y)) if y[i] == 1]\n",
    "type2 = [signals[i] for i in range(len(y)) if y[i] == 2]\n",
    "type3 = [signals[i] for i in range(len(y)) if y[i] == 3]\n",
    "\n",
    "print(\"The length of type0 is \",len(type0))\n",
    "print(\"The length of type1 is \",len(type1))\n",
    "print(\"The length of type2 is \",len(type2))\n",
    "print(\"The length of type3 is \",len(type3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Have a basic impression of the four types\n",
    "r0 = ecg.ecg(type0[0], 300.0, show=True)\n",
    "r1 = ecg.ecg(type1[0], 300.0, show=True)\n",
    "r2 = ecg.ecg(type2[0], 300.0, show=True)\n",
    "r3 = ecg.ecg(type3[0], 300.0, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = ecg.ecg(type0[8], 300.0, show=True)\n",
    "r1 = ecg.ecg(type1[8], 300.0, show=True)\n",
    "r2 = ecg.ecg(type2[8], 300.0, show=True)\n",
    "r3 = ecg.ecg(type3[8], 300.0, show=True)\n",
    "\n",
    "r0 = ecg.ecg(type0[28], 300.0, show=True)\n",
    "r1 = ecg.ecg(type1[28], 300.0, show=True)\n",
    "r2 = ecg.ecg(type2[28], 300.0, show=True)\n",
    "r3 = ecg.ecg(type3[28], 300.0, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare in the same type\n",
    "## Type0\n",
    "r00 = ecg.ecg(type0[5], 300.0, show=True)\n",
    "r01 = ecg.ecg(type0[50], 300.0, show=True)\n",
    "r02 = ecg.ecg(type0[500], 300.0, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare in the same type\n",
    "## Type1\n",
    "r10 = ecg.ecg(type1[30], 300.0, show=True)\n",
    "r11 = ecg.ecg(type1[5], 200.0, show=True)\n",
    "r12 = ecg.ecg(type1[200], 300.0, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare in the same type\n",
    "## Type2\n",
    "r20 = ecg.ecg(type2[4], 300.0, show=True)\n",
    "r21 = ecg.ecg(type2[40], 300.0, show=True)\n",
    "r22 = ecg.ecg(type2[400], 300.0, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "r20_300 = ecg.ecg(type2[4], 300.0, show=True)\n",
    "r20_200 = ecg.ecg(type2[4], 200.0, show=True)\n",
    "r20_100 = ecg.ecg(type2[4], 100.0, show=True)\n",
    "var300 = np.var(r20_300['templates'])\n",
    "var200 = np.var(r20_200['templates'])\n",
    "var100 = np.var(r20_100['templates'])\n",
    "print(\"The var of 300 is \",var300, \"\\n The var 200 is \",var200,\"\\n The var 100 is \",var100)\n",
    "# variance(r20['templates'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare in the same type\n",
    "## Type3\n",
    "r30 = ecg.ecg(type3[4], 300.0, show=True)\n",
    "r31 = ecg.ecg(type3[40], 300.0, show=True)\n",
    "r32 = ecg.ecg(type3[107], 300.0, show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templates = []\n",
    "with open(\"data/template.csv\") as f_train:\n",
    "    for line in f_train.readlines()[1:]:\n",
    "        templates.append(list(line.split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(templates)\n",
    "len(templates[1])\n",
    "len(signals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explore a template\n",
    "one_temp = templates[4]\n",
    "max(one_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test R peak locations\n",
    "testcase = signals[5]\n",
    "rpeak_id_chris = ecg.christov_segmenter(testcase,300)['rpeaks']\n",
    "#rpeak_id_ecg = ecg.ecg(testcase,300)['rpeaks']\n",
    "#rpeak_id_eng = ecg.engzee_segmenter(testcase,300)['rpeaks']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rpeak_id_ecg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-82dc0d5d924c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Compare the results of several rpeaks segmenter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mrpeak_id_chris_rm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrpeak_id_chris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpeak_id_chris\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpeak_id_ecg\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrpeak_id_chris\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrpeak_id_eng\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mecg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompare_segmentation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrpeak_id_chris\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrpeak_id_eng\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rpeak_id_ecg' is not defined"
     ]
    }
   ],
   "source": [
    "# Compare the results of several rpeaks segmenter\n",
    "rpeak_id_chris_rm = rpeak_id_chris[1:(len(rpeak_id_chris)-1)]\n",
    "print(rpeak_id_ecg,\"\\n\",rpeak_id_chris,\"\\n\",rpeak_id_eng)\n",
    "\n",
    "ecg.compare_segmentation(rpeak_id_chris,rpeak_id_eng,300)\n",
    "#ecg.correct_rpeaks(testcase,rpeak_id_ecg['rpeaks'],300)\n",
    "#print(testcase[rpeak_id_ecg['rpeaks']],\"\\n\",testcase[rpeak_id_chris_rm])\n",
    "# testcase[3373]\n",
    "# find the chris and eng perform similarly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[133, 328, 214, 224, 294, 262, -6, 303, 230, 209, 254, 311, 140, 335, 355, 248, 323, 163, 235, 315, 198, 147, 272, 150, 321, 196, 267, 260, 287, 280]\n"
     ]
    }
   ],
   "source": [
    "rpeak_chris=[]\n",
    "for id in rpeak_id_chris:\n",
    "    #print(id)\n",
    "    rpeak_chris.append(int(testcase[id]))\n",
    "print(rpeak_chris)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241.6   77.0249310289\n",
      "0.36666666666666664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 1.,  0.,  0.,  1.,  4.,  3.,  4.,  7.,  5.,  5.]),\n",
       " array([  -6. ,   30.1,   66.2,  102.3,  138.4,  174.5,  210.6,  246.7,\n",
       "         282.8,  318.9,  355. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute some statistics about R-value\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "rpeak_mean = np.mean(rpeak_chris)\n",
    "rpeak_std = np.std(rpeak_chris)\n",
    "print(rpeak_mean,\" \",rpeak_std)\n",
    "\n",
    "disnormal_ones = [i for i in range(len(rpeak_chris)) if abs(rpeak_chris[i]-rpeak_mean)>rpeak_std]\n",
    "print(len(disnormal_ones)/len(rpeak_chris))\n",
    "plt.hist(rpeak_chris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[297, 300, 298, 237, 366, 330, 277, 301, 303, 304, 301, 320, 237, 342, 306, 300, 323, 278, 307, 307, 301, 301, 305, 309, 310, 305, 301, 307, 310]\n",
      "302.862068966   24.367479937\n",
      "0.2413793103448276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([  2.,   0.,   0.,   2.,   9.,  11.,   2.,   1.,   1.,   1.]),\n",
       " array([ 237. ,  249.9,  262.8,  275.7,  288.6,  301.5,  314.4,  327.3,\n",
       "         340.2,  353.1,  366. ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# view the distribution of the interval of R-peaks\n",
    "\n",
    "rpeak_interval=[]\n",
    "for i in range(len(rpeak_id_chris)-1):\n",
    "    rpeak_interval.append(rpeak_id_chris[i+1]-rpeak_id_chris[i])\n",
    "print(rpeak_interval)\n",
    "\n",
    "rpeak_id_mean = np.mean(rpeak_interval)\n",
    "rpeak_id_std = np.std(rpeak_interval)\n",
    "print(rpeak_id_mean,\" \",rpeak_id_std)\n",
    "\n",
    "disnormal_id_ones = [i for i in range(len(rpeak_interval)) if abs(rpeak_interval[i]-rpeak_id_mean)>rpeak_id_std]\n",
    "print(len(disnormal_id_ones)/len(rpeak_interval))\n",
    "plt.hist(rpeak_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[356,\n",
       " 356,\n",
       " 356,\n",
       " 356,\n",
       " 355,\n",
       " 354,\n",
       " 354,\n",
       " 352,\n",
       " 351,\n",
       " 350,\n",
       " 349,\n",
       " 347,\n",
       " 346,\n",
       " 345,\n",
       " 343,\n",
       " 342,\n",
       " 341,\n",
       " 340,\n",
       " 339]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "signals[0][1:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8776\n",
      "[425]\n"
     ]
    }
   ],
   "source": [
    "rpeak_id_chris = ecg.christov_segmenter(signals[3],300)['rpeaks']\n",
    "print(len(signals[3]))\n",
    "print(rpeak_id_chris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#signals_0 = []\n",
    "#with open(\"data/x_train_0.csv\") as f_train:\n",
    "#    for line in f_train.readlines()[1:]:\n",
    "#        signals_0.append(list(map(int, line.split(',')[1:])))\n",
    "x_test=[]\n",
    "with open(\"data/X_test.csv\") as f_train:\n",
    "    for line in f_train.readlines()[1:]:\n",
    "        x_test.append(list(map(int, line.split(',')[1:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def StatFeature(arrays, corrected = False):\n",
    "    mean = np.mean(arrays)\n",
    "    std = np.std(arrays)\n",
    "    disnormal_cnt = 0\n",
    "    new_array=[]\n",
    "    for a in arrays:\n",
    "        if abs(a-mean)>std:\n",
    "                disnormal_cnt = disnormal_cnt+1\n",
    "        else:\n",
    "            new_array.append(a)\n",
    "    disnormal_ratio = disnormal_cnt/len(arrays)\n",
    "    if(corrected):\n",
    "        c_mean = np.mean(new_array)\n",
    "        c_std = np.std(new_array)\n",
    "        return [mean,std,disnormal_ratio, c_mean,c_std ]\n",
    "    return [mean,std,disnormal_ratio]\n",
    "            \n",
    "def ExtractRPeakFeature(signals):\n",
    "    rpeak_int_stats=[]\n",
    "    rpeak_stats=[]\n",
    "    for i in range(len(signals)):\n",
    "        signal = signals[i]\n",
    "        if(i%50==0):\n",
    "            print(\"Processing the \",i/50,\" batch of 50 signals...\")\n",
    "\n",
    "        rpeak_id_chris = ecg.christov_segmenter(signal,300)['rpeaks']\n",
    "        rpeak_interval=[]\n",
    "        rpeaks=[]\n",
    "        \n",
    "        if(len(rpeak_id_chris)<4):\n",
    "            # the mean value, the standard error and the disnormal ratio of intervals\n",
    "            rpeak_int_stats.append([0,0,0])\n",
    "            # the mean value, the standard error, the disnormal ratio and the corrected mean value, the corrected standard error.\n",
    "            rpeak_stats.append([0,0,0,0,0])\n",
    "            continue\n",
    "            \n",
    "        for j in range(len(rpeak_id_chris)-1):\n",
    "            rpeak_interval.append(rpeak_id_chris[j+1]-rpeak_id_chris[j])\n",
    "            rpeaks.append(signal[int(rpeak_id_chris[j])])\n",
    "        \n",
    "        # Calculate the indices of rpeak_intervals\n",
    "        rpeak_int_stats.append(StatFeature(rpeak_interval))\n",
    "        # Calculate the indices of rpeaks\n",
    "        rpeak_stats.append(StatFeature(rpeaks,corrected=True))\n",
    "        \n",
    "    return rpeak_int_stats,rpeak_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the  0.0  batch of 50 signals...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-69192dcdbb0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Extract features about R-peak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# rpeakIntFeature,rpeakFeature = ExtractRPeakFeature(signals)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtest_rpeakIntFeature\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest_rpeakFeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExtractRPeakFeature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-25-b07cbef618f0>\u001b[0m in \u001b[0;36mExtractRPeakFeature\u001b[0;34m(signals)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Processing the \"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\" batch of 50 signals...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mrpeak_id_chris\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mecg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchristov_segmenter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msignal\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rpeaks'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mrpeak_interval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mrpeaks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/lib/python3.6/site-packages/biosppy/signals/ecg.py\u001b[0m in \u001b[0;36mchristov_segmenter\u001b[0;34m(signal, sampling_rate)\u001b[0m\n\u001b[1;32m    658\u001b[0m             \u001b[0mY_latest50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_sample\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv50ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrent_sample\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0mY_earliest50\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcurrent_sample\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv350ms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mcurrent_sample\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mv300ms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 660\u001b[0;31m             \u001b[0mF\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_latest50\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_earliest50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m1000.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    661\u001b[0m         \u001b[0;31m# Rm is the mean value of the buffer RR.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mRm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mRR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extract features about R-peak\n",
    "# rpeakIntFeature,rpeakFeature = ExtractRPeakFeature(signals)\n",
    "test_rpeakIntFeature,test_rpeakFeature = ExtractRPeakFeature(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save features about r-peak\n",
    "\n",
    "#f = open(\"rpeakfeature.csv\", \"w\")\n",
    "#f.write(\"id,rpeakIntMean,rpeakIntStd,rpeakIntOutlier,rpeakMean,rpeakStd,rpeakOutlier,rpeakCorrectedMean,rpeakCorrectedStd\\n\")\n",
    "#for i in range(len(rpeakIntFeature)):\n",
    "#    f.write(\"{},{},{},{},{},{},{},{},{}\\n\".format(i, rpeakIntFeature[i][0],rpeakIntFeature[i][1],rpeakIntFeature[i][2],\n",
    "#                                                  rpeakFeature[i][0],rpeakFeature[i][1],rpeakFeature[i][2],\n",
    "#                                                  rpeakFeature[i][3],rpeakFeature[i][4]))\n",
    "#f.close()\n",
    "\n",
    "f = open(\"rpeakfeature_test.csv\", \"w\")\n",
    "f.write(\"id,rpeakIntMean,rpeakIntStd,rpeakIntOutlier,rpeakMean,rpeakStd,rpeakOutlier,rpeakCorrectedMean,rpeakCorrectedStd\\n\")\n",
    "for i in range(len(test_rpeakFeature)):\n",
    "    f.write(\"{},{},{},{},{},{},{},{},{}\\n\".format(i, test_rpeakIntFeature[i][0],test_rpeakIntFeature[i][1],test_rpeakIntFeature[i][2],\n",
    "                                                  test_rpeakFeature[i][0],test_rpeakFeature[i][1],test_rpeakFeature[i][2],\n",
    "                                                  test_rpeakFeature[i][3],test_rpeakFeature[i][4]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 5\n"
     ]
    }
   ],
   "source": [
    "#len(y)\n",
    "print(len(test_rpeakIntFeature[3]),len(test_rpeakFeature[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting neurokit\n",
      "  Using cached https://files.pythonhosted.org/packages/6d/9e/09f441055856cfe1ddc3251d2709671eea3d8fc10233fd1ee1ee35124fe0/neurokit-0.2.0-py3-none-any.whl\n",
      "Requirement already satisfied: matplotlib in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from neurokit) (2.2.2)\n",
      "Requirement already satisfied: Pillow in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from neurokit) (5.1.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from neurokit) (1.14.3)\n",
      "Collecting cvxopt (from neurokit)\n",
      "  Using cached https://files.pythonhosted.org/packages/25/4b/0570f5c2349f609d969d6ee0a369f7accd67a3369fbf76fce06bfea8419e/cvxopt-1.2.2-cp36-cp36m-win_amd64.whl\n",
      "Requirement already satisfied: scipy in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from neurokit) (1.1.0)\n",
      "Requirement already satisfied: mne in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from neurokit) (0.16.2)\n",
      "Requirement already satisfied: nolds in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from neurokit) (0.5.1)\n",
      "Requirement already satisfied: biosppy in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from neurokit) (0.6.1)\n",
      "Requirement already satisfied: sklearn in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from neurokit) (0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from neurokit) (0.23.0)\n",
      "Requirement already satisfied: bioread in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from neurokit) (1.0.4)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->neurokit) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->neurokit) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->neurokit) (2.7.3)\n",
      "Requirement already satisfied: pytz in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->neurokit) (2018.4)\n",
      "Requirement already satisfied: six>=1.10 in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->neurokit) (1.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from matplotlib->neurokit) (1.0.1)\n",
      "Requirement already satisfied: mkl in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cvxopt->neurokit) (2019.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from nolds->neurokit) (39.1.0)\n",
      "Requirement already satisfied: future in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from nolds->neurokit) (0.17.0)\n",
      "Requirement already satisfied: bidict in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from biosppy->neurokit) (0.17.3)\n",
      "Requirement already satisfied: h5py in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from biosppy->neurokit) (2.7.1)\n",
      "Requirement already satisfied: shortuuid in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from biosppy->neurokit) (0.5.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from biosppy->neurokit) (0.19.1)\n",
      "Requirement already satisfied: intel-openmp in c:\\users\\fgr07\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from mkl->cvxopt->neurokit) (2019.0)\n",
      "Installing collected packages: cvxopt, neurokit\n",
      "Successfully installed cvxopt-1.2.2 neurokit-0.2.0\n"
     ]
    }
   ],
   "source": [
    "# Extract other features\n",
    "!pip install neurokit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['T_Waves', 'P_Waves', 'Q_Waves'])\n"
     ]
    }
   ],
   "source": [
    "import neurokit\n",
    "\n",
    "# This is a test case\n",
    "testcase = signals[0]\n",
    "rpeak_id_chris = ecg.christov_segmenter(testcase,300)['rpeaks']\n",
    "\n",
    "waves = neurokit.ecg_wave_detector(testcase,rpeak_id_chris)\n",
    "print(waves.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractWaveFeature(arrays,corrected=True):\n",
    "    p_waves_stat=[]\n",
    "    q_waves_stat=[]\n",
    "    t_waves_stat=[]\n",
    "    #rTot_stat=[]\n",
    "    whole_stat=[]\n",
    "    for j in range(len(arrays)):\n",
    "        signal = signals[j]\n",
    "        if(j%50==0):\n",
    "            print(\"Processing the \",j/50,\" batch of 50 signals...\")\n",
    "            \n",
    "        rpeak = ecg.christov_segmenter(signal,300)['rpeaks']\n",
    "        waves = neurokit.ecg_wave_detector(signal,rpeak)\n",
    "        t_waves_id = waves['T_Waves']\n",
    "        t_waves=[]\n",
    "        for id in t_waves_id:\n",
    "            t_waves.append(signal[int(id)])\n",
    "    \n",
    "        p_waves_id=waves[\"P_Waves\"]\n",
    "        p_waves = []\n",
    "        for id in p_waves_id:\n",
    "            p_waves.append(signal[int(id)])\n",
    "    \n",
    "        q_waves_id=waves[\"Q_Waves\"]\n",
    "        q_waves = []\n",
    "        for id in q_waves_id:\n",
    "            q_waves.append(signal[int(id)])\n",
    "        \n",
    "        #r_waves = []\n",
    "        #for id in rpeak_id_chris:\n",
    "        #    if()\n",
    "        #    r_waves.append(testcase[int(id)])\n",
    "        #\n",
    "        #print(\"r len:\",len(r_waves),\"\\t t len:\",len(t_waves),\"\\t p len:\",len(p_waves),\"\\t q len:\",len(q_waves))\n",
    "        #rTot=[]\n",
    "        #for i in range(len(t_waves)):\n",
    "        #    if(t_waves[i]==0):\n",
    "        #        continue\n",
    "        #    rTot.append(r_waves[i]/t_waves[i])\n",
    "        \n",
    "        #rTot_stat.append(StatFeature(rTot,corrected))\n",
    "        whole_stat.append(StatFeature(signal,corrected))\n",
    "        if(len(p_waves)==0):\n",
    "            if(corrected):\n",
    "                p_waves_stat.append([0,0,0,0,0])\n",
    "            else:\n",
    "                p_waves_stat.append([0,0,0])\n",
    "        else:\n",
    "            p_waves_stat.append(StatFeature(p_waves,corrected))\n",
    "            \n",
    "        if(len(q_waves)==0):\n",
    "            if(corrected):\n",
    "                q_waves_stat.append([0,0,0,0,0])\n",
    "            else:\n",
    "                q_waves_stat.append([0,0,0])\n",
    "        else:\n",
    "            q_waves_stat.append(StatFeature(q_waves,corrected))\n",
    "            \n",
    "        if(len(t_waves)==0):\n",
    "            if(corrected):\n",
    "                t_waves_stat.append([0,0,0,0,0])\n",
    "            else:\n",
    "                t_waves_stat.append([0,0,0])\n",
    "        else:\n",
    "            t_waves_stat.append(StatFeature(t_waves,corrected))\n",
    "        \n",
    "    features = {\"T_Waves_Stat\": t_waves_stat,\n",
    "                 \"P_Waves_Stat\": p_waves_stat,\n",
    "                 \"Q_Waves_Stat\": q_waves_stat,\n",
    "                 #\"rTot_Waves_Stat\": rTot_stat,\n",
    "                 \"whole_Stat\": whole_stat}\n",
    "    return features    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[859.38709677419354,\n",
       " 803.54029858272202,\n",
       " 0.3548387096774194,\n",
       " 1275.25,\n",
       " 377.44295926669503]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_extra_features['Q_Waves_Stat'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[859.38709677419354,\n",
       " 803.54029858272202,\n",
       " 0.3548387096774194,\n",
       " 1275.25,\n",
       " 377.44295926669503]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_extra_features['Q_Waves_Stat'][100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the  0.0  batch of 50 signals...\n",
      "Processing the  1.0  batch of 50 signals...\n",
      "Processing the  2.0  batch of 50 signals...\n",
      "Processing the  3.0  batch of 50 signals...\n",
      "Processing the  4.0  batch of 50 signals...\n",
      "Processing the  5.0  batch of 50 signals...\n",
      "Processing the  6.0  batch of 50 signals...\n",
      "Processing the  7.0  batch of 50 signals...\n",
      "Processing the  8.0  batch of 50 signals...\n",
      "Processing the  9.0  batch of 50 signals...\n",
      "Processing the  10.0  batch of 50 signals...\n",
      "Processing the  11.0  batch of 50 signals...\n",
      "Processing the  12.0  batch of 50 signals...\n",
      "Processing the  13.0  batch of 50 signals...\n",
      "Processing the  14.0  batch of 50 signals...\n",
      "Processing the  15.0  batch of 50 signals...\n",
      "Processing the  16.0  batch of 50 signals...\n",
      "Processing the  17.0  batch of 50 signals...\n",
      "Processing the  18.0  batch of 50 signals...\n",
      "Processing the  19.0  batch of 50 signals...\n",
      "Processing the  20.0  batch of 50 signals...\n",
      "Processing the  21.0  batch of 50 signals...\n",
      "Processing the  22.0  batch of 50 signals...\n",
      "Processing the  23.0  batch of 50 signals...\n",
      "Processing the  24.0  batch of 50 signals...\n",
      "Processing the  25.0  batch of 50 signals...\n",
      "Processing the  26.0  batch of 50 signals...\n",
      "Processing the  27.0  batch of 50 signals...\n",
      "Processing the  28.0  batch of 50 signals...\n",
      "Processing the  29.0  batch of 50 signals...\n",
      "Processing the  30.0  batch of 50 signals...\n",
      "Processing the  31.0  batch of 50 signals...\n",
      "Processing the  32.0  batch of 50 signals...\n",
      "Processing the  33.0  batch of 50 signals...\n",
      "Processing the  34.0  batch of 50 signals...\n",
      "Processing the  35.0  batch of 50 signals...\n",
      "Processing the  36.0  batch of 50 signals...\n",
      "Processing the  37.0  batch of 50 signals...\n",
      "Processing the  38.0  batch of 50 signals...\n",
      "Processing the  39.0  batch of 50 signals...\n",
      "Processing the  40.0  batch of 50 signals...\n",
      "Processing the  41.0  batch of 50 signals...\n",
      "Processing the  42.0  batch of 50 signals...\n",
      "Processing the  43.0  batch of 50 signals...\n",
      "Processing the  44.0  batch of 50 signals...\n",
      "Processing the  45.0  batch of 50 signals...\n",
      "Processing the  46.0  batch of 50 signals...\n",
      "Processing the  47.0  batch of 50 signals...\n",
      "Processing the  48.0  batch of 50 signals...\n",
      "Processing the  49.0  batch of 50 signals...\n",
      "Processing the  50.0  batch of 50 signals...\n",
      "Processing the  51.0  batch of 50 signals...\n",
      "Processing the  52.0  batch of 50 signals...\n",
      "Processing the  53.0  batch of 50 signals...\n",
      "Processing the  54.0  batch of 50 signals...\n",
      "Processing the  55.0  batch of 50 signals...\n",
      "Processing the  56.0  batch of 50 signals...\n",
      "Processing the  57.0  batch of 50 signals...\n",
      "Processing the  58.0  batch of 50 signals...\n",
      "Processing the  59.0  batch of 50 signals...\n",
      "Processing the  60.0  batch of 50 signals...\n",
      "Processing the  61.0  batch of 50 signals...\n",
      "Processing the  62.0  batch of 50 signals...\n",
      "Processing the  63.0  batch of 50 signals...\n",
      "Processing the  64.0  batch of 50 signals...\n",
      "Processing the  65.0  batch of 50 signals...\n",
      "Processing the  66.0  batch of 50 signals...\n",
      "Processing the  67.0  batch of 50 signals...\n",
      "Processing the  68.0  batch of 50 signals...\n",
      "Processing the  69.0  batch of 50 signals...\n",
      "Processing the  70.0  batch of 50 signals...\n",
      "Processing the  71.0  batch of 50 signals...\n",
      "Processing the  72.0  batch of 50 signals...\n",
      "Processing the  73.0  batch of 50 signals...\n",
      "Processing the  74.0  batch of 50 signals...\n",
      "Processing the  75.0  batch of 50 signals...\n",
      "Processing the  76.0  batch of 50 signals...\n",
      "Processing the  77.0  batch of 50 signals...\n",
      "Processing the  78.0  batch of 50 signals...\n",
      "Processing the  79.0  batch of 50 signals...\n",
      "Processing the  80.0  batch of 50 signals...\n",
      "Processing the  81.0  batch of 50 signals...\n",
      "Processing the  82.0  batch of 50 signals...\n",
      "Processing the  83.0  batch of 50 signals...\n",
      "Processing the  84.0  batch of 50 signals...\n",
      "Processing the  85.0  batch of 50 signals...\n",
      "Processing the  86.0  batch of 50 signals...\n",
      "Processing the  87.0  batch of 50 signals...\n",
      "Processing the  88.0  batch of 50 signals...\n",
      "Processing the  89.0  batch of 50 signals...\n",
      "Processing the  90.0  batch of 50 signals...\n",
      "Processing the  91.0  batch of 50 signals...\n",
      "Processing the  92.0  batch of 50 signals...\n",
      "Processing the  93.0  batch of 50 signals...\n",
      "Processing the  94.0  batch of 50 signals...\n",
      "Processing the  95.0  batch of 50 signals...\n",
      "Processing the  96.0  batch of 50 signals...\n",
      "Processing the  97.0  batch of 50 signals...\n",
      "Processing the  98.0  batch of 50 signals...\n",
      "Processing the  99.0  batch of 50 signals...\n",
      "Processing the  100.0  batch of 50 signals...\n",
      "Processing the  101.0  batch of 50 signals...\n",
      "Processing the  102.0  batch of 50 signals...\n",
      "Processing the  0.0  batch of 50 signals...\n",
      "Processing the  1.0  batch of 50 signals...\n",
      "Processing the  2.0  batch of 50 signals...\n",
      "Processing the  3.0  batch of 50 signals...\n",
      "Processing the  4.0  batch of 50 signals...\n",
      "Processing the  5.0  batch of 50 signals...\n",
      "Processing the  6.0  batch of 50 signals...\n",
      "Processing the  7.0  batch of 50 signals...\n",
      "Processing the  8.0  batch of 50 signals...\n",
      "Processing the  9.0  batch of 50 signals...\n",
      "Processing the  10.0  batch of 50 signals...\n",
      "Processing the  11.0  batch of 50 signals...\n",
      "Processing the  12.0  batch of 50 signals...\n",
      "Processing the  13.0  batch of 50 signals...\n",
      "Processing the  14.0  batch of 50 signals...\n",
      "Processing the  15.0  batch of 50 signals...\n",
      "Processing the  16.0  batch of 50 signals...\n",
      "Processing the  17.0  batch of 50 signals...\n",
      "Processing the  18.0  batch of 50 signals...\n",
      "Processing the  19.0  batch of 50 signals...\n",
      "Processing the  20.0  batch of 50 signals...\n",
      "Processing the  21.0  batch of 50 signals...\n",
      "Processing the  22.0  batch of 50 signals...\n",
      "Processing the  23.0  batch of 50 signals...\n",
      "Processing the  24.0  batch of 50 signals...\n",
      "Processing the  25.0  batch of 50 signals...\n",
      "Processing the  26.0  batch of 50 signals...\n",
      "Processing the  27.0  batch of 50 signals...\n",
      "Processing the  28.0  batch of 50 signals...\n",
      "Processing the  29.0  batch of 50 signals...\n",
      "Processing the  30.0  batch of 50 signals...\n",
      "Processing the  31.0  batch of 50 signals...\n",
      "Processing the  32.0  batch of 50 signals...\n",
      "Processing the  33.0  batch of 50 signals...\n",
      "Processing the  34.0  batch of 50 signals...\n",
      "Processing the  35.0  batch of 50 signals...\n",
      "Processing the  36.0  batch of 50 signals...\n",
      "Processing the  37.0  batch of 50 signals...\n",
      "Processing the  38.0  batch of 50 signals...\n",
      "Processing the  39.0  batch of 50 signals...\n",
      "Processing the  40.0  batch of 50 signals...\n",
      "Processing the  41.0  batch of 50 signals...\n",
      "Processing the  42.0  batch of 50 signals...\n",
      "Processing the  43.0  batch of 50 signals...\n",
      "Processing the  44.0  batch of 50 signals...\n",
      "Processing the  45.0  batch of 50 signals...\n",
      "Processing the  46.0  batch of 50 signals...\n",
      "Processing the  47.0  batch of 50 signals...\n",
      "Processing the  48.0  batch of 50 signals...\n",
      "Processing the  49.0  batch of 50 signals...\n",
      "Processing the  50.0  batch of 50 signals...\n",
      "Processing the  51.0  batch of 50 signals...\n",
      "Processing the  52.0  batch of 50 signals...\n",
      "Processing the  53.0  batch of 50 signals...\n",
      "Processing the  54.0  batch of 50 signals...\n",
      "Processing the  55.0  batch of 50 signals...\n",
      "Processing the  56.0  batch of 50 signals...\n",
      "Processing the  57.0  batch of 50 signals...\n",
      "Processing the  58.0  batch of 50 signals...\n",
      "Processing the  59.0  batch of 50 signals...\n",
      "Processing the  60.0  batch of 50 signals...\n",
      "Processing the  61.0  batch of 50 signals...\n",
      "Processing the  62.0  batch of 50 signals...\n",
      "Processing the  63.0  batch of 50 signals...\n",
      "Processing the  64.0  batch of 50 signals...\n",
      "Processing the  65.0  batch of 50 signals...\n",
      "Processing the  66.0  batch of 50 signals...\n",
      "Processing the  67.0  batch of 50 signals...\n",
      "Processing the  68.0  batch of 50 signals...\n"
     ]
    }
   ],
   "source": [
    "# Run this cell\n",
    "train_extra_features = ExtractWaveFeature(signals)\n",
    "test_extra_features = ExtractWaveFeature(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-379.71875,\n",
       " 168.45756779805856,\n",
       " 0.09375,\n",
       " -414.37931034482756,\n",
       " 32.619450293581131]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_extra_features['Q_Waves_Stat'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-379.71875,\n",
       " 168.45756779805856,\n",
       " 0.09375,\n",
       " -414.37931034482756,\n",
       " 32.619450293581131]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_extra_features['Q_Waves_Stat'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other Features\n",
    "f = open(\"otherfeature_simple.csv\", \"w\")\n",
    "f.write(\"id,qMean,qStd,tMean,tStd,pMean,pStd,\\\n",
    "        wholeMean,wholeStd,wholeDisnormal,wholeCorrectedMean,wholeCorrectedStd\\n\")\n",
    "for i in range(len(train_extra_features['whole_Stat'])):\n",
    "    f.write(\"{},{},{},{},{},{},{},{},{},{},{},{}\\n\".format(i, train_extra_features['Q_Waves_Stat'][i][0],train_extra_features['Q_Waves_Stat'][i][1],\\\n",
    "                                                        train_extra_features['T_Waves_Stat'][i][0],train_extra_features['T_Waves_Stat'][i][1],\\\n",
    "                                                        train_extra_features['P_Waves_Stat'][i][0],train_extra_features['P_Waves_Stat'][i][1],\\\n",
    "                                                        train_extra_features['whole_Stat'][i][0],train_extra_features['whole_Stat'][i][1],\\\n",
    "                                                        train_extra_features['whole_Stat'][i][2],train_extra_features['whole_Stat'][i][3],train_extra_features['whole_Stat'][i][4]))\n",
    "f.close()\n",
    "\n",
    "f = open(\"otherfeature_complete.csv\", \"w\")\n",
    "f.write(\"id,qMean,qStd,qDisnormal,qCMean,qCStd,\\\n",
    "        tMean,tStd,tDisnormal,tCMean,tCStd,\\\n",
    "        pMean,pStd,pDisnormal,pCMean,pCStd,\\\n",
    "        wholeMean,wholeStd,wholeDisnormal,wholeCorrectedMean,wholeCorrectedStd\\n\")\n",
    "for i in range(len(train_extra_features['whole_Stat'])):\n",
    "    f.write(\"{},{},{},{},{},{},\\\n",
    "            {},{},{},{},{},\\\n",
    "            {},{},{},{},{},\\\n",
    "            {},{},{},{},{}\\n\".format(i, train_extra_features['Q_Waves_Stat'][i][0],train_extra_features['Q_Waves_Stat'][i][1],train_extra_features['Q_Waves_Stat'][i][2],train_extra_features['Q_Waves_Stat'][i][3],train_extra_features['Q_Waves_Stat'][i][4],\\\n",
    "                                                        train_extra_features['T_Waves_Stat'][i][0],train_extra_features['T_Waves_Stat'][i][1],train_extra_features['T_Waves_Stat'][i][2],train_extra_features['T_Waves_Stat'][i][3],train_extra_features['T_Waves_Stat'][i][4],\\\n",
    "                                                        train_extra_features['P_Waves_Stat'][i][0],train_extra_features['P_Waves_Stat'][i][1],train_extra_features['P_Waves_Stat'][i][2],train_extra_features['P_Waves_Stat'][i][3],train_extra_features['P_Waves_Stat'][i][4],\\\n",
    "                                                        train_extra_features['whole_Stat'][i][0],train_extra_features['whole_Stat'][i][1],\\\n",
    "                                                        train_extra_features['whole_Stat'][i][2],train_extra_features['whole_Stat'][i][3],train_extra_features['whole_Stat'][i][4]))\n",
    "f.close()\n",
    "\n",
    "f = open(\"test_otherfeature_complete.csv\", \"w\")\n",
    "f.write(\"id,qMean,qStd,qDisnormal,qCMean,qCStd,\\\n",
    "        tMean,tStd,tDisnormal,tCMean,tCStd,\\\n",
    "        pMean,pStd,pDisnormal,pCMean,pCStd,\\\n",
    "        wholeMean,wholeStd,wholeDisnormal,wholeCorrectedMean,wholeCorrectedStd\\n\")\n",
    "for i in range(len(test_extra_features['whole_Stat'])):\n",
    "    f.write(\"{},{},{},{},{},{},\\\n",
    "            {},{},{},{},{},\\\n",
    "            {},{},{},{},{},\\\n",
    "            {},{},{},{},{}\\n\".format(i, test_extra_features['Q_Waves_Stat'][i][0],test_extra_features['Q_Waves_Stat'][i][1],test_extra_features['Q_Waves_Stat'][i][2],test_extra_features['Q_Waves_Stat'][i][3],test_extra_features['Q_Waves_Stat'][i][4],\\\n",
    "                                                        test_extra_features['T_Waves_Stat'][i][0],test_extra_features['T_Waves_Stat'][i][1],test_extra_features['T_Waves_Stat'][i][2],test_extra_features['T_Waves_Stat'][i][3],test_extra_features['T_Waves_Stat'][i][4],\\\n",
    "                                                        test_extra_features['P_Waves_Stat'][i][0],test_extra_features['P_Waves_Stat'][i][1],test_extra_features['P_Waves_Stat'][i][2],test_extra_features['P_Waves_Stat'][i][3],test_extra_features['P_Waves_Stat'][i][4],\\\n",
    "                                                        test_extra_features['whole_Stat'][i][0],test_extra_features['whole_Stat'][i][1],\\\n",
    "                                                        test_extra_features['whole_Stat'][i][2],test_extra_features['whole_Stat'][i][3],test_extra_features['whole_Stat'][i][4]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "x_train = pd.read_csv(\"rpeakfeature.csv\", header =0,index_col=0)\n",
    "x_train.describe()\n",
    "\n",
    "print(\"Spleating the dataset...\")\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(x_train,y,test_size=0.2)\n",
    "Y_train_t0 = Y_train[Y_train==0]\n",
    "Y_train_t1 = Y_train[Y_train==1]\n",
    "Y_train_t2 = Y_train[Y_train==2]\n",
    "Y_train_t3 = Y_train[Y_train==3]\n",
    "print(\"The number of type0 is \",len(Y_train_t0),\n",
    "     \"\\n The number of type1 is \",len(Y_train_t1),\n",
    "     \"\\n The number of type2 is \",len(Y_train_t2),\n",
    "     \"\\n The number of type3 is \",len(Y_train_t3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, log_loss \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier \n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis \n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis \n",
    "\n",
    "\n",
    "def ModelsOnDatasets(datasets, x_train,x_test,y_train,y_test):\n",
    "    clfs = [ KNeighborsClassifier(4), SVC(kernel=\"rbf\", C=0.025, probability=True), \n",
    "                DecisionTreeClassifier(), RandomForestClassifier(),\n",
    "               AdaBoostClassifier(), GradientBoostingClassifier(), GaussianNB(), \n",
    "               LinearDiscriminantAnalysis(), QuadraticDiscriminantAnalysis()]\n",
    "    print(\"The Datasets are: \",datasets)\n",
    "    log_cols=[\"Classifier\", \"Accuracy\", \"Log Loss\"]\n",
    "    log = pd.DataFrame(columns=log_cols) \n",
    "    for clf in clfs: \n",
    "        clf.fit(x_train, y_train) \n",
    "        name = clf.__class__.__name__ \n",
    "        print(\"=\"*30,'\\n', name)\n",
    "    \n",
    "        train_predictions = clf.predict(x_test) \n",
    "        cross_val_score(clf,x_train,y_train,scoring='recall_macro', cv=5)\n",
    "        acc = accuracy_score(y_test, train_predictions) \n",
    "        \n",
    "        train_predictions = clf.predict_proba(x_test) \n",
    "        ll = log_loss(y_test, train_predictions) \n",
    "        \n",
    "        # write the item in the log\n",
    "        #log_entry = pd.DataFrame([[name, acc*100, ll, BMAC]], columns=log_cols) \n",
    "        log_entry = pd.DataFrame([[name, acc*100, ll]], columns=log_cols) \n",
    "        log = log.append(log_entry) \n",
    "        \n",
    "    \n",
    "        print('****Results****') \n",
    "        print(\"Accuracy: {:.4%}\".format(acc)) \n",
    "        print(\"Log Loss: {}\".format(ll)) \n",
    "        print(\"=\"*30)\n",
    "    return log, clfs\n",
    "    \n",
    "log=ModelsOnDatasets(\"Original Datasets\",X_train, X_val, Y_train, Y_val)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def plotLog(log):\n",
    "    sns.set_color_codes(\"muted\") \n",
    "    sns.barplot(x='Accuracy', y='Classifier', data=log, color=\"b\") \n",
    "\n",
    "    plt.xlabel('Accuracy %') \n",
    "    plt.title('Classifier Accuracy') \n",
    "    plt.show() \n",
    "\n",
    "    sns.set_color_codes(\"muted\") \n",
    "    sns.barplot(x='Log Loss', y='Classifier', data=log, color=\"g\") \n",
    "\n",
    "    plt.xlabel('Log Loss') \n",
    "    plt.title('Classifier Log Loss') \n",
    "    plt.show()\n",
    "\n",
    "plotLog(log)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
