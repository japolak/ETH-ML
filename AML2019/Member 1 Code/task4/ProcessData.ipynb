{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import floor\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import periodogram, welch,iirfilter,filtfilt\n",
    "from scipy import integrate, fftpack\n",
    "from operator import itemgetter\n",
    "from biosppy.signals import eeg, emg\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "seed = 7\n",
    "numpy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n"
     ]
    }
   ],
   "source": [
    "print('loading data...')\n",
    "y_train = pd.read_csv('./data/train_labels.csv',header=0,index_col = None)\n",
    "x_train_eeg1 = pd.read_csv('./data/train_eeg1.csv', header=0, index_col = 0)\n",
    "x_train_eeg2 = pd.read_csv('./data/train_eeg2.csv', header=0, index_col = 0)\n",
    "x_train_emg = pd.read_csv('./data/train_emg.csv', header=0, index_col = 0)\n",
    "x_test_eeg1 = pd.read_csv('./data/test_eeg1.csv', header=0, index_col = 0)\n",
    "x_test_eeg2 = pd.read_csv('./data/test_eeg2.csv', header=0, index_col = 0)\n",
    "x_test_emg = pd.read_csv('./data/test_emg.csv', header=0, index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_train_eeg1=x_train_eeg1.iloc[0:21600,]\n",
    "x2_train_eeg1=x_train_eeg1.iloc[21600:43200,]\n",
    "x3_train_eeg1=x_train_eeg1.iloc[43200:64800,]\n",
    "x1_test_eeg1=x_test_eeg1.iloc[0:21600,]\n",
    "x2_test_eeg1=x_test_eeg1.iloc[21600:43200,]\n",
    "\n",
    "x1_train_eeg2=x_train_eeg2.iloc[0:21600,]\n",
    "x2_train_eeg2=x_train_eeg2.iloc[21600:43200,]\n",
    "x3_train_eeg2=x_train_eeg2.iloc[43200:64800,]\n",
    "x1_test_eeg2=x_test_eeg2.iloc[0:21600,]\n",
    "x2_test_eeg2=x_test_eeg2.iloc[21600:43200,]\n",
    "\n",
    "x1_train_emg=x_train_emg.iloc[0:21600,]\n",
    "x2_train_emg=x_train_emg.iloc[21600:43200,]\n",
    "x3_train_emg=x_train_emg.iloc[43200:64800,]\n",
    "x1_test_emg=x_test_emg.iloc[0:21600,]\n",
    "x2_test_emg=x_test_emg.iloc[21600:43200,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1=np.zeros((3,21600,512))\n",
    "x_1[0]=x1_train_eeg1.values\n",
    "x_1[1]=x1_train_eeg2.values\n",
    "x_1[2]=x1_train_emg.values\n",
    "\n",
    "x_2=np.zeros((3,21600,512))\n",
    "x_2[0]=x2_train_eeg1.values\n",
    "x_2[1]=x2_train_eeg2.values\n",
    "x_2[2]=x2_train_emg.values\n",
    "\n",
    "x_3=np.zeros((3,21600,512))\n",
    "x_3[0]=x3_train_eeg1.values\n",
    "x_3[1]=x3_train_eeg2.values\n",
    "x_3[2]=x3_train_emg.values\n",
    "\n",
    "x_1_test=np.zeros((3,21600,512))\n",
    "x_1_test[0]=x1_test_eeg1.values\n",
    "x_1_test[1]=x1_test_eeg2.values\n",
    "x_1_test[2]=x1_test_emg.values\n",
    "\n",
    "x_2_test=np.zeros((3,21600,512))\n",
    "x_2_test[0]=x2_test_eeg1.values\n",
    "x_2_test[1]=x2_test_eeg2.values\n",
    "x_2_test[2]=x2_test_emg.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1_new=np.zeros((3,512*21600))\n",
    "x_1_new[0]=x1_train_eeg1.values.reshape(1,512*21600)\n",
    "x_1_new[1]=x1_train_eeg2.values.reshape(1,512*21600)\n",
    "x_1_new[2]=x1_train_emg.values.reshape(1,512*21600)\n",
    "\n",
    "x_2_new=np.zeros((3,512*21600))\n",
    "x_2_new[0]=x2_train_eeg1.values.reshape(1,512*21600)\n",
    "x_2_new[1]=x2_train_eeg2.values.reshape(1,512*21600)\n",
    "x_2_new[2]=x2_train_emg.values.reshape(1,512*21600)\n",
    "\n",
    "x_3_new=np.zeros((3,512*21600))\n",
    "x_3_new[0]=x3_train_eeg1.values.reshape(1,512*21600)\n",
    "x_3_new[1]=x3_train_eeg2.values.reshape(1,512*21600)\n",
    "x_3_new[2]=x3_train_emg.values.reshape(1,512*21600)\n",
    "\n",
    "x_1_new_test=np.zeros((3,512*21600))\n",
    "x_1_new_test[0]=x1_test_eeg1.values.reshape(1,512*21600)\n",
    "x_1_new_test[1]=x1_test_eeg2.values.reshape(1,512*21600)\n",
    "x_1_new_test[2]=x1_test_emg.values.reshape(1,512*21600)\n",
    "\n",
    "x_2_new_test=np.zeros((3,512*21600))\n",
    "x_2_new_test[0]=x2_test_eeg1.values.reshape(1,512*21600)\n",
    "x_2_new_test[1]=x2_test_eeg2.values.reshape(1,512*21600)\n",
    "x_2_new_test[2]=x2_test_emg.values.reshape(1,512*21600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing the  0.0  batch of 150 signals...\n",
      "Processing the  1.0  batch of 150 signals...\n",
      "Processing the  2.0  batch of 150 signals...\n",
      "Processing the  3.0  batch of 150 signals...\n",
      "Processing the  4.0  batch of 150 signals...\n",
      "Processing the  5.0  batch of 150 signals...\n",
      "Processing the  6.0  batch of 150 signals...\n",
      "Processing the  7.0  batch of 150 signals...\n",
      "Processing the  8.0  batch of 150 signals...\n",
      "Processing the  9.0  batch of 150 signals...\n",
      "Processing the  10.0  batch of 150 signals...\n",
      "Processing the  11.0  batch of 150 signals...\n",
      "Processing the  12.0  batch of 150 signals...\n",
      "Processing the  13.0  batch of 150 signals...\n",
      "Processing the  14.0  batch of 150 signals...\n",
      "Processing the  15.0  batch of 150 signals...\n",
      "Processing the  16.0  batch of 150 signals...\n",
      "Processing the  17.0  batch of 150 signals...\n",
      "Processing the  18.0  batch of 150 signals...\n",
      "Processing the  19.0  batch of 150 signals...\n",
      "Processing the  20.0  batch of 150 signals...\n",
      "Processing the  21.0  batch of 150 signals...\n",
      "Processing the  22.0  batch of 150 signals...\n",
      "Processing the  23.0  batch of 150 signals...\n",
      "Processing the  24.0  batch of 150 signals...\n",
      "Processing the  25.0  batch of 150 signals...\n",
      "Processing the  26.0  batch of 150 signals...\n",
      "Processing the  27.0  batch of 150 signals...\n",
      "Processing the  28.0  batch of 150 signals...\n",
      "Processing the  29.0  batch of 150 signals...\n",
      "Processing the  30.0  batch of 150 signals...\n",
      "Processing the  31.0  batch of 150 signals...\n",
      "Processing the  32.0  batch of 150 signals...\n",
      "Processing the  33.0  batch of 150 signals...\n",
      "Processing the  34.0  batch of 150 signals...\n",
      "Processing the  35.0  batch of 150 signals...\n",
      "Processing the  36.0  batch of 150 signals...\n",
      "Processing the  37.0  batch of 150 signals...\n",
      "Processing the  38.0  batch of 150 signals...\n",
      "Processing the  39.0  batch of 150 signals...\n",
      "Processing the  40.0  batch of 150 signals...\n",
      "Processing the  41.0  batch of 150 signals...\n",
      "Processing the  42.0  batch of 150 signals...\n",
      "Processing the  43.0  batch of 150 signals...\n",
      "Processing the  44.0  batch of 150 signals...\n",
      "Processing the  45.0  batch of 150 signals...\n",
      "Processing the  46.0  batch of 150 signals...\n",
      "Processing the  47.0  batch of 150 signals...\n",
      "Processing the  48.0  batch of 150 signals...\n",
      "Processing the  49.0  batch of 150 signals...\n",
      "Processing the  50.0  batch of 150 signals...\n",
      "Processing the  51.0  batch of 150 signals...\n",
      "Processing the  52.0  batch of 150 signals...\n",
      "Processing the  53.0  batch of 150 signals...\n",
      "Processing the  54.0  batch of 150 signals...\n",
      "Processing the  55.0  batch of 150 signals...\n",
      "Processing the  56.0  batch of 150 signals...\n",
      "Processing the  57.0  batch of 150 signals...\n",
      "Processing the  58.0  batch of 150 signals...\n",
      "Processing the  59.0  batch of 150 signals...\n",
      "Processing the  60.0  batch of 150 signals...\n",
      "Processing the  61.0  batch of 150 signals...\n",
      "Processing the  62.0  batch of 150 signals...\n",
      "Processing the  63.0  batch of 150 signals...\n",
      "Processing the  64.0  batch of 150 signals...\n",
      "Processing the  65.0  batch of 150 signals...\n",
      "Processing the  66.0  batch of 150 signals...\n",
      "Processing the  67.0  batch of 150 signals...\n",
      "Processing the  68.0  batch of 150 signals...\n",
      "Processing the  69.0  batch of 150 signals...\n",
      "Processing the  70.0  batch of 150 signals...\n",
      "Processing the  71.0  batch of 150 signals...\n",
      "Processing the  72.0  batch of 150 signals...\n",
      "Processing the  73.0  batch of 150 signals...\n",
      "Processing the  74.0  batch of 150 signals...\n",
      "Processing the  75.0  batch of 150 signals...\n",
      "Processing the  76.0  batch of 150 signals...\n",
      "Processing the  77.0  batch of 150 signals...\n",
      "Processing the  78.0  batch of 150 signals...\n",
      "Processing the  79.0  batch of 150 signals...\n",
      "Processing the  80.0  batch of 150 signals...\n",
      "Processing the  81.0  batch of 150 signals...\n",
      "Processing the  82.0  batch of 150 signals...\n",
      "Processing the  83.0  batch of 150 signals...\n",
      "Processing the  84.0  batch of 150 signals...\n",
      "Processing the  85.0  batch of 150 signals...\n",
      "Processing the  86.0  batch of 150 signals...\n",
      "Processing the  87.0  batch of 150 signals...\n",
      "Processing the  88.0  batch of 150 signals...\n",
      "Processing the  89.0  batch of 150 signals...\n",
      "Processing the  90.0  batch of 150 signals...\n",
      "Processing the  91.0  batch of 150 signals...\n",
      "Processing the  92.0  batch of 150 signals...\n",
      "Processing the  93.0  batch of 150 signals...\n",
      "Processing the  94.0  batch of 150 signals...\n",
      "Processing the  95.0  batch of 150 signals...\n",
      "Processing the  96.0  batch of 150 signals...\n",
      "Processing the  97.0  batch of 150 signals...\n",
      "Processing the  98.0  batch of 150 signals...\n",
      "Processing the  99.0  batch of 150 signals...\n",
      "Processing the  100.0  batch of 150 signals...\n",
      "Processing the  101.0  batch of 150 signals...\n",
      "Processing the  102.0  batch of 150 signals...\n",
      "Processing the  103.0  batch of 150 signals...\n",
      "Processing the  104.0  batch of 150 signals...\n",
      "Processing the  105.0  batch of 150 signals...\n",
      "Processing the  106.0  batch of 150 signals...\n",
      "Processing the  107.0  batch of 150 signals...\n",
      "Processing the  108.0  batch of 150 signals...\n",
      "Processing the  109.0  batch of 150 signals...\n",
      "Processing the  110.0  batch of 150 signals...\n",
      "Processing the  111.0  batch of 150 signals...\n",
      "Processing the  112.0  batch of 150 signals...\n",
      "Processing the  113.0  batch of 150 signals...\n",
      "Processing the  114.0  batch of 150 signals...\n",
      "Processing the  115.0  batch of 150 signals...\n",
      "Processing the  116.0  batch of 150 signals...\n",
      "Processing the  117.0  batch of 150 signals...\n",
      "Processing the  118.0  batch of 150 signals...\n",
      "Processing the  119.0  batch of 150 signals...\n",
      "Processing the  120.0  batch of 150 signals...\n",
      "Processing the  121.0  batch of 150 signals...\n",
      "Processing the  122.0  batch of 150 signals...\n",
      "Processing the  123.0  batch of 150 signals...\n",
      "Processing the  124.0  batch of 150 signals...\n",
      "Processing the  125.0  batch of 150 signals...\n",
      "Processing the  126.0  batch of 150 signals...\n",
      "Processing the  127.0  batch of 150 signals...\n",
      "Processing the  128.0  batch of 150 signals...\n",
      "Processing the  129.0  batch of 150 signals...\n",
      "Processing the  130.0  batch of 150 signals...\n",
      "Processing the  131.0  batch of 150 signals...\n",
      "Processing the  132.0  batch of 150 signals...\n",
      "Processing the  133.0  batch of 150 signals...\n",
      "Processing the  134.0  batch of 150 signals...\n",
      "Processing the  135.0  batch of 150 signals...\n",
      "Processing the  136.0  batch of 150 signals...\n",
      "Processing the  137.0  batch of 150 signals...\n",
      "Processing the  138.0  batch of 150 signals...\n",
      "Processing the  139.0  batch of 150 signals...\n",
      "Processing the  140.0  batch of 150 signals...\n",
      "Processing the  141.0  batch of 150 signals...\n",
      "Processing the  142.0  batch of 150 signals...\n",
      "Processing the  143.0  batch of 150 signals...\n"
     ]
    }
   ],
   "source": [
    "import utilstask5 as utils\n",
    "x_1_features=[]\n",
    "    \n",
    "for i in range(21600):\n",
    "    if(i%200==0):\n",
    "            print(\"Processing the \",i/200,\" batch of 200 signals...\")\n",
    "    raw_signal = np.concatenate(([x_2[0][i]],[x_2[1][i]]))\n",
    "    feature0 = utils.ExtractFeatures(np.array(x_2[0][i]),np.array(x_2[1][i]),np.array(x_1[2][i]))\n",
    "    x_1_features.append(feature0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "write() argument must be str, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-18-3a879f04297d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"x_1_features_train.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_1_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_1_features\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: write() argument must be str, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "f = open(\"x_1_features_train.csv\", \"w\")\n",
    "for i in range(len(x_1_features)):\n",
    "    f.write(x_1_features[i])\n",
    "    f.write(\"\\n\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt(\"x_1_features_train.csv\", x_1_features, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
