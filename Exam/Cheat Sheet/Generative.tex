\section*{\normalsize{Discriminative vs. Generative Modeling}}
Discriminative est conditional$P(y|x)$\\
Generative esr joint $P(y,x)$\\
1. Est prior on labels $P(y)$\\
2. Est cond. dist $P(x|y)$ (for each class y)\\
3. Predictive dist. using Bayes' rule:\\
$P(y|x) = \frac{P(y) P(x|y)}{P(x)} = \frac{P(x,y)}{P(x)}$\\
$P(x) = \sum_y P(x,y)=\sum_y P(x|y)P(y)$

\subsection*{Naive Bayes}
Classes: $P(Y)=P(Y=y)=p_y$\\
Features: $P(X|Y)=\prod_{i}^n P(x_i|y)$ \\
Joint: $P(X,Y) = \prod_i^n P(x_i,y_i)=P(y) \prod_i^n P(x_i|y)$ \\
Ass: $X_{i:n}$ are conditionally independent given $Y$

\subsection*{MLE for P(y)}
Ass: $P(Y=1) = p, P(y=-1) = 1-p$ (Bernoulli)\\
MLE: $p^* = \prod_{i=1}^n p^{[y_i=+1]} (1-p)^{[y_i=-1]}=\frac{n_+}{n_+ + n_-}$

\subsection*{MLE for P=(x|y)}
Ass: $P(X=x_i|y) = \mathcal{N}(x_i;\mu_{i,y}, \sigma_{i,y}^2)$ (Gaussian)\\
MLE: $\hat{\mu}_{i,y} = \frac{1}{n_y} \sum_{{x_i|y}} x$;  
$\hat{\sigma}_{i,y}^2 = \frac{1}{n_y} \sum_{{x_i|y}} (x-\hat{\mu}_{i,y})^2$

\subsection*{Decision / Classification rule}
$P(y|x) = \frac{1}{Z} P(y)P(x|y)$, $Z = \sum_y P(y) P(x|y)$\\
$y^*=\arg\max_{y}P(y|x)=\log P(y)+\sum_{i}^d\log P(x_i|y)$

\subsection*{Gaussian Naive Bayes (different Var)}
MLE class prior: $\hat{P}(Y=y) = \hat{p}_y = \frac{n_y}{n}$\\
MLE feature dist.: $\hat{P}(x_i|y)=\mathcal{N}(x_i;\hat{\mu}_{y,i}, \sigma_{y,i}^2)$\\
$\hat{\mu}_{y,i} = \frac{1}{n_y} \sum_{j:y_j=y} x_{j,i}$,  
$\sigma_{y,i}^2 = \frac{1}{n_y} \sum_{j:y_j=y} (x_{j,i} - \hat{\mu}_{y,i})^2$\\
Pred: $y = \arg\max_{y'} \hat{P}(y'|x) = \text{sign}(f(x))$\\
Discriminant: $ f(x)=\log\frac{P(Y=1|x)}{P(Y=-1|x)}$

\subsection*{Gaussian Naive Bayes (common Var, c=2)}
Ass: $P(Y=1)=p_+$; $P(x|y)=\prod_i \mathcal{N}(x_i;\mu_{y,i},\sigma^2_i) $ \\
Discriminant: $f(x)=w^Tx + w_0$\\
$w_i=\frac{\mu_{+,i}-\mu_{-,i}}{\sigma^2_i}$;  
$w_0=\log \frac{\hat{p}_+}{1-\hat{p}_+}+\sum_{i=1}^d \frac{\hat{\mu}^2_{-,i}-\hat{\mu}^2_{+,i}}{2\hat{\sigma}^2_i}$\\
Class dist: $P(Y=1|x)=(1+\exp(-f(x)))^{-1}=\sigma(f(x))$

\subsection*{Quadratic Discriminant Analysis}
Classes: $P(Y=y)=p_y$ \\
Features: $P(X|Y)=\mathcal{N}(x;\mu_y,\Sigma_y)$\\
Ass: features generated by multivariate Normal\\
MLE class prior: $ \hat{P}(Y=y)=\hat{p}_y=\frac{n_y}{n}$\\
MLE feature dist: $ \hat{P}(x|y)=\mathcal{N}(x;\hat{\mu}_y,\hat{\Sigma}_y)$\\
$\hat{\mu}_y=\frac{1}{n_y} \sum_{i:y_i=y} x_i$;  
$\hat{\Sigma}_y=\frac{1}{n_y}\sum_{i:y_i=y}(x_i-\hat{\mu}_y)(x_i-\hat{\mu}_y)^2$\\
Discriminant: $f(x)=\log\frac{p}{1-p}+\frac{1}{2}
\big[
\log \frac{|\hat{\Sigma}_-|}{|\hat{\Sigma}_+|}  + $\\
$+(x-\hat{\mu}_-)^T\hat{\Sigma}_-^{-1}(x-\hat{\mu}_-) -
(x-\hat{\mu}_+)^T\hat{\Sigma}_+^{-1}(x-\hat{\mu}_+) 
\big]$

\subsection*{Linear Discriminant Analysis}
Ass: $p = 0.5$;   $\hat{\Sigma}_- = \hat{\Sigma}_+ = \hat{\Sigma}$\\
$f(x) = x^T\hat{\Sigma}^{-1}(\hat{\mu}_-+-\hat{\mu}_-)+
\frac{1}{2}(\hat{\mu}_-^T\hat{\Sigma}^{-1}\hat{\mu}_- - \hat{\mu}_+^T \hat{\Sigma}^{-1}\hat{\mu}_+  )$\\
Pred: $y = \text{sign}(f(x)) = \text{sign} (w^T x + w_0)$\\
$w = \hat{\Sigma}^{-1}(\hat{\mu}_+ - \hat{\mu}_-)$; $w_0 = \frac{1}{2}(\hat{\mu}_-^T\hat{\Sigma}^{-1}\hat{\mu}_- - \hat{\mu}_+^T \hat{\Sigma}^{-1}\hat{\mu}_+)$

\subsection*{Outlier Detection}
$P(x) = \sum_{y=1}^c P(y) P(x|y) = \sum_y \hat{p}_y \mathcal{N}(x|\hat{\mu}_y,\hat{\Sigma}_y) \leq \tau$

\subsection*{Categorical Naive Bayes Classifier}
MLE class prior: $\hat{P}(Y=y) = \hat{p}_y=\frac{n_y}{n}$\\
MLE feature dist: $\hat{P}(X_i = c|Y = y) = \theta_{c|y}^{(i)} = \frac{n_{c,y}}{n_y}$\\
Pred: $y^* = \arg\max_{y}\hat{P}(y|x)$

%\subsection*{Prior over parameters}
%Prior: $P(\theta)$;  Posterior: $P( \theta |Y)= P( \theta )P(Y| \theta )$\\
%MAP: $\hat{\theta}=\arg\max_\theta P(\theta|D)$\\
%Prior/Post+Like: Beta+Ber/Bin; $\mathcal{N}$ (fixed $\Sigma$)+$\mathcal{N}$

