This project was about multi-class classification. Our goal was to predict a discrete value y (0, 1, 2, 3 or 4) based on a vector x. We inspected the features but due to unknown origin of the data, no feature transformation or selection was done, besides standardising the data. The approach we only considered were Feed Forward Neural Networks and selected the best model among those. The available labeled data were split into training data (70%) and validation data (30%). We tested different configurations only on validation data as Cross-validation would be computationally more expensive. The following architecture performed the best: 4 fully connected dense layers with first having 960 nodes and the others had each reduced number of nodes by factor 2 to limit the total number of parameters of the NN ( hence 960/480/240/120 ). After each dense layer we applied Batch Normalisation, then ReLu activation function and dropout with probability 0.5. Final layer was just with 5 nodes and Soft-max activation function to obtain class probabilities.
To find the optimal stopping time we run a Cross-validation to obtain fairly a smooth validation loss and accuracy curve from which we inferred the optimal number of epochs (200) with batch-size of 32.
