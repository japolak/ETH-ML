Our task is to predict a value y as a linear function of a set of feature transformation which are given. The submission are weights of the linear predictor.
The solution to this task is similar to 1a with a slight modifications. The method performed the best was Lasso as it performed feature selection which was our goal due to the very high collinearity of features. The code looks similar to previous task, as it has an outer loop which goes over the range of lambdas and inner loop which goes over the folds of the CV.
The inner loop is a Repeated K Fold CV of 100 folds and repeated 100 times with different random state. This was crucial to reduce the variance of the error by repeatedly shuffling the data (100 times) and reduce the bias of cross validation by splitting it into more folds (100 folds).
The average over the shuffles and average over k folds is computed to get more stable estimate of RMSE.
This is then repeated in the outer loop for each lambda. We first considered a large range of of lambdas and were narrowing the search down. The final code is searching in the range from .35 to .5 and it gives an optimal lambda of 0.425 witch results in a good performance in validation (hold out set) and public test set. At last full model with optimal lambda was fitted and coefficients submitted
